## Contents

 * [EA-1: Connectivity of interval temporal networks](#ea-1-connectivity-of-interval-temporal-networks)
 * [EA-2: Exact and approximation algorithms for exploration of temporal stars and other dynamic graphs](#ea-2-exact-and-approximation-algorithms-for-exploration-of-temporal-stars-and-other-dynamic-graphs)
 * [EA-3: Binary search on graphs](#ea-3-binary-search-on-graphs)
 * [EA-4: Path and reachability problems in temporal graphs](#ea-4-path-and-reachability-problems-in-temporal-graphs)
 * [AA-1: Are Looks Deceiving? Exploring the Effects of Image Enhancement Techniques on the Performance of Convolutional Neural Networks](#aa-1-are-looks-deceiving-exploring-the-effects-of-image-enhancement-techniques-on-the-performance-of-convolutional-neural-networks)
 * [AA-2: Automatic Quality Control for the Evaluation of Deep Learning Algorithms Applied to Images of the Eye](#aa-2-automatic-quality-control-for-the-evaluation-of-deep-learning-algorithms-applied-to-images-of-the-eye)
 * [AA-3: Multi-Modal, Scale, and Class detection of ophthalmologic diseases through anomaly detection](#aa-3-multi-modal-scale-and-class-detection-of-ophthalmologic-diseases-through-anomaly-detection)
 * [AA-4: Revealing retinal changes in Alport syndrome with image processing and machine learning](#aa-4-revealing-retinal-changes-in-alport-syndrome-with-image-processing-and-machine-learning)
 * [AA-5: Why can't I find Wally? Exploring the effect of distractors on the performance of convolutional neural networks in cluttered scenes](#aa-5-why-cant-i-find-wally-exploring-the-effect-of-distractors-on-the-performance-of-convolutional-neural-networks-in-cluttered-scenes)
 * [AA-6: Can surgery revitalize the eyes?](#aa-6-can-surgery-revitalize-the-eyes)
 * [AA-7: Automatic detection of cell density in eyes using deep learning](#aa-7-automatic-detection-of-cell-density-in-eyes-using-deep-learning)
 * [GA-1: Carbon Intelligent Computing for for Control and Optimisation of Data Centres](#ga-1-carbon-intelligent-computing-for-for-control-and-optimisation-of-data-centres)
 * [GA-2: Electric Vehicle as a Service for Disaster-like Scenarios](#ga-2-electric-vehicle-as-a-service-for-disaster-like-scenarios)
 * [GA-3: Blockchain supported Privacy Aware Ecosystems](#ga-3-blockchain-supported-privacy-aware-ecosystems)
 * [GA-4: Blockchain framework for supply chain management](#ga-4-blockchain-framework-for-supply-chain-management)
 * [EB-1: Generative modelling of non-text handwritten document annotations](#eb-1-generative-modelling-of-non-text-handwritten-document-annotations)
 * [EB-2: Open project in code as primary source material in the <blink>history of computing</blink>](#eb-2-open-project-in-code-as-primary-source-material-in-the-blinkhistory-of-computingblink)
 * [EB-3: Analysing relevance, reliability, and information flow in user-generated comments on online music videos](#eb-3-analysing-relevance-reliability-and-information-flow-in-user-generated-comments-on-online-music-videos)
 * [EB-4: Tracking the production and circulation of MIDI files during the 1990s](#eb-4-tracking-the-production-and-circulation-of-midi-files-during-the-1990s)
 * [SC-1: Using NLP to understand political success based on party manifestos](#sc-1-using-nlp-to-understand-political-success-based-on-party-manifestos)
 * [SC-2: Debating what’s important to civic life: NLP and data analysis of political debates](#sc-2-debating-what’s-important-to-civic-life-nlp-and-data-analysis-of-political-debates)
 * [SC-3: Conspiracy theories: understanding and predicting conspiratorial content using natural language processing](#sc-3-conspiracy-theories-understanding-and-predicting-conspiratorial-content-using-natural-language-processing)
 * [RCr-1: Predicting student experiences based on their characteristics](#rcr-1-predicting-student-experiences-based-on-their-characteristics)
 * [RCr-2: Using Mermaid to Enhance Accessibility of Diagrams.](#rcr-2-using-mermaid-to-enhance-accessibility-of-diagrams)
 * [SSD-1: Machine Learning for Game Playing](#ssd-1-machine-learning-for-game-playing)
 * [SSD-2: Learning and Generating Graphs with Deep Neural Networks](#ssd-2-learning-and-generating-graphs-with-deep-neural-networks)
 * [SSD-3: Theorem Proving in Lean](#ssd-3-theorem-proving-in-lean)
 * [PD-1: Implementation and Visualisation of Distributed Graph Algorithms](#pd-1-implementation-and-visualisation-of-distributed-graph-algorithms)
 * [PD-2: Implementation of Algorithms for Massively Parallel Computation](#pd-2-implementation-of-algorithms-for-massively-parallel-computation)
 * [PD-3: Implementation of Discrete Logarithm Algorithms](#pd-3-implementation-of-discrete-logarithm-algorithms)
 * [PD-4: Implementation of Factoring Algorithms](#pd-4-implementation-of-factoring-algorithms)
 * [PD-5: Implementation of Algorithms with Predictions](#pd-5-implementation-of-algorithms-with-predictions)
 * [TE-1: Learning-Augmented Algorithms for Minimum Spanning Trees under Uncertainty](#te-1-learning-augmented-algorithms-for-minimum-spanning-trees-under-uncertainty)
 * [TE-2: Query-based algorithms for Computing with Stochastic Uncertainty](#te-2-query-based-algorithms-for-computing-with-stochastic-uncertainty)
 * [TE-3: Actively Reconfigurable Networks](#te-3-actively-reconfigurable-networks)
 * [TE-4: Automatic Generation of Conference Programmes](#te-4-automatic-generation-of-conference-programmes)
 * [TE-5: Automatic allocation of group projects](#te-5-automatic-allocation-of-group-projects)
 * [TE-6: Exploration of dynamic networks](#te-6-exploration-of-dynamic-networks)
 * [TE-7: Algorithms for Matching with Uncertain Preferences and Queries](#te-7-algorithms-for-matching-with-uncertain-preferences-and-queries)
 * [TE-8: Scheduling with Testing](#te-8-scheduling-with-testing)
 * [YF-1: Anomaly Detection and Segmentation in Image and Pixel Level on X-ray Security Imagery](#yf-1-anomaly-detection-and-segmentation-in-image-and-pixel-level-on-x-ray-security-imagery)
 * [YF-2: Thats looks Weird! Finding anomaly from Eye in the Sky.](#yf-2-thats-looks-weird-finding-anomaly-from-eye-in-the-sky)
 * [MGo-1: Surprise! “Uniform Information Density” may not be so uniform after all…](#mgo-1-surprise-“uniform-information-density”-may-not-be-so-uniform-after-all…)
 * [MGo-2: Quantifying musical complexity](#mgo-2-quantifying-musical-complexity)
 * [MGo-3: Musical corpus building and data analysis](#mgo-3-musical-corpus-building-and-data-analysis)
 * [MGo-4: Optical _Music_ Recognition](#mgo-4-optical-music-recognition)
 * [MGo-5: Never mind the playlist, here’s the setlist](#mgo-5-never-mind-the-playlist-here’s-the-setlist)
 * [MGo-6: New algorithms for the development of Open Source Software MuseScore and/or Audacity](#mgo-6-new-algorithms-for-the-development-of-open-source-software-musescore-andor-audacity)
 * [SH-1: Deep learning in recommender systems](#sh-1-deep-learning-in-recommender-systems)
 * [SH-2: Affect- and personality-aware recommender systems](#sh-2-affect--and-personality-aware-recommender-systems)
 * [SH-3: Affective Human-Computer Interaction: Intelligent system adaptation for emotion regulation](#sh-3-affective-human-computer-interaction-intelligent-system-adaptation-for-emotion-regulation)
 * [SH-4: Responsible AI: Explainability, fairness, trust in Recommender Systems](#sh-4-responsible-ai-explainability-fairness-trust-in-recommender-systems)
 * [SH-5: Personal Stylist: Recommender Systems in Fashion](#sh-5-personal-stylist-recommender-systems-in-fashion)
 * [SH-6: Machine learning detection and prediction in mental health](#sh-6-machine-learning-detection-and-prediction-in-mental-health)
 * [BIM-1: Real-time automatic surveillance photosphere](#bim-1-real-time-automatic-surveillance-photosphere)
 * [II-1: Thomson problem](#ii-1-thomson-problem)
 * [II-2: Cryptocurrencies - bitcoin](#ii-2-cryptocurrencies---bitcoin)
 * [II-3: Liveness tests for face recognition](#ii-3-liveness-tests-for-face-recognition)
 * [II-4: Watermarking 3D printed objects](#ii-4-watermarking-3d-printed-objects)
 * [II-5: A blockchain based system for the secure handling of research data](#ii-5-a-blockchain-based-system-for-the-secure-handling-of-research-data)
 * [AJ-1: Smart energy management in homes, industries or commercial sectors](#aj-1-smart-energy-management-in-homes-industries-or-commercial-sectors)
 * [AJ-2: Machine learning applications in Internet of things (IoT)](#aj-2-machine-learning-applications-in-internet-of-things-iot)
 * [AJ-3: Data analytics for improving healthcare systems](#aj-3-data-analytics-for-improving-healthcare-systems)
 * [AJ-4: Network resource management for service provisioning in wireless sensor networks](#aj-4-network-resource-management-for-service-provisioning-in-wireless-sensor-networks)
 * [AJ-5: Cyber-security applications in Internet of things (IoT)](#aj-5-cyber-security-applications-in-internet-of-things-iot)
 * [SK-1: A comparative study of the effect of various data augmentation techniques on the performance of CNN-based image classification](#sk-1-a-comparative-study-of-the-effect-of-various-data-augmentation-techniques-on-the-performance-of-cnn-based-image-classification)
 * [SK-2: Smart white cane for vision impaired and blind people](#sk-2-smart-white-cane-for-vision-impaired-and-blind-people)
 * [SK-3: Using chest X-ray images and deep learning for automated detection of pathologies](#sk-3-using-chest-x-ray-images-and-deep-learning-for-automated-detection-of-pathologies)
 * [SK-4: Electroencephalography (EEG)-based biometrics](#sk-4-electroencephalography-eeg-based-biometrics)
 * [SK-5: Single camera-based UAV-to-UAV detection and tracking](#sk-5-single-camera-based-uav-to-uav-detection-and-tracking)
 * [GK-1: Automatic Projector Calibration](#gk-1-automatic-projector-calibration)
 * [GK-2: Wearable Haptics](#gk-2-wearable-haptics)
 * [GK-3: Enhancing Dark Video Features via Inverse Tone Mapping](#gk-3-enhancing-dark-video-features-via-inverse-tone-mapping)
 * [GK-4: A 3D Rendering Pipeline on FPGA](#gk-4-a-3d-rendering-pipeline-on-fpga)
 * [GK-5: Psychophysics research using PsychoPy](#gk-5-psychophysics-research-using-psychopy)
 * [AK-1: Backgammon with variable luck](#ak-1-backgammon-with-variable-luck)
 * [AK-2: Research tool for AI search in graphs](#ak-2-research-tool-for-ai-search-in-graphs)
 * [AK-3: Steganography](#ak-3-steganography)
 * [AK-4: Matching under preferences](#ak-4-matching-under-preferences)
 * [AK-5: Solving edge-matching problems with SAT solvers](#ak-5-solving-edge-matching-problems-with-sat-solvers)
 * [AK-6: Integer factorisation algorithms](#ak-6-integer-factorisation-algorithms)
 * [FL-1: Developing a Deep Learning Architecture for Accurate Human-Object Interaction Recognition](#fl-1-developing-a-deep-learning-architecture-for-accurate-human-object-interaction-recognition)
 * [FL-2: Real-Time Hand Gesture Recognition in Cluttered Environments using Deep Learning](#fl-2-real-time-hand-gesture-recognition-in-cluttered-environments-using-deep-learning)
 * [RL-1: Music Generation and/or Analysis](#rl-1-music-generation-andor-analysis)
 * [RL-2: Learning Embeddings by Simulating Communication](#rl-2-learning-embeddings-by-simulating-communication)
 * [RL-3: Interactive Music Visualisation](#rl-3-interactive-music-visualisation)
 * [RL-4: Meta-learning the kernel structure for Gaussian processes](#rl-4-meta-learning-the-kernel-structure-for-gaussian-processes)
 * [RL-5: Sonification of High-Dimensional Data](#rl-5-sonification-of-high-dimensional-data)
 * [RL-6: Variational Autoencoders are Reinforcement Learning Agents](#rl-6-variational-autoencoders-are-reinforcement-learning-agents)
 * [RL-7: Solving Long-Term Dependencies with Hierarchical Memory](#rl-7-solving-long-term-dependencies-with-hierarchical-memory)
 * [RL-8: A PyTorch implementation of the UMAP embedding method](#rl-8-a-pytorch-implementation-of-the-umap-embedding-method)
 * [YL-1: AI-pedia](#yl-1-ai-pedia)
 * [CM-1: Fast machines, racing heartbeats: Numerical Cardiac Modelling](#cm-1-fast-machines-racing-heartbeats-numerical-cardiac-modelling)
 * [CM-2: ML and Statistical modelling of excitable media](#cm-2-ml-and-statistical-modelling-of-excitable-media)
 * [CM-3: ur-ML: Applications for Data Assimilation](#cm-3-ur-ml-applications-for-data-assimilation)
 * [CM-4: Adaptive Simulation Strategies for Excitable and Oscillatory Media](#cm-4-adaptive-simulation-strategies-for-excitable-and-oscillatory-media)
 * [CM-5: Birdwatching: Counting and tracking birds for fun and profit with Machine Learning](#cm-5-birdwatching-counting-and-tracking-birds-for-fun-and-profit-with-machine-learning)
 * [BM-1: The Student-Project Allocation problem](#bm-1-the-student-project-allocation-problem)
 * [BM-2: Arithmetic constraint satisfaction](#bm-2-arithmetic-constraint-satisfaction)
 * [BM-3: Solving Quantified Constraints](#bm-3-solving-quantified-constraints)
 * [BM-4: Solving problems with Satisfiability](#bm-4-solving-problems-with-satisfiability)
 * [BM-5: Verification](#bm-5-verification)
 * [BM-6: Social Network Analysis](#bm-6-social-network-analysis)
 * [GM-1: Coloring a graph via a game](#gm-1-coloring-a-graph-via-a-game)
 * [GM-2: Influence spreading in networks](#gm-2-influence-spreading-in-networks)
 * [GM-3: Temporal Networks](#gm-3-temporal-networks)
 * [GM-4: Blockchain tokens](#gm-4-blockchain-tokens)
 * [GM-5: Mutating Networks](#gm-5-mutating-networks)
 * [LMo-1: SYCL-based Parallelization of HPCCG](#lmo-1-sycl-based-parallelization-of-hpccg)
 * [LMo-2: Enabling Fine-Grained Task-Parallelism on Massively Parallel Hardware with SYCL](#lmo-2-enabling-fine-grained-task-parallelism-on-massively-parallel-hardware-with-sycl)
 * [BMo-1: Dispersion of mobile robots on a dynamic graph with fault tolerance](#bmo-1-dispersion-of-mobile-robots-on-a-dynamic-graph-with-fault-tolerance)
 * [BMo-2: Dispersion of mobile robots on a dynamic graph in the semi-synchronous setting](#bmo-2-dispersion-of-mobile-robots-on-a-dynamic-graph-in-the-semi-synchronous-setting)
 * [BMo-3: Dispersion of mobile robots on a dynamic graph with partial vision](#bmo-3-dispersion-of-mobile-robots-on-a-dynamic-graph-with-partial-vision)
 * [BMo-4: Leader election in programmable matter with fault tolerance](#bmo-4-leader-election-in-programmable-matter-with-fault-tolerance)
 * [RP-1: Implementing efficient hash tables on GPUs](#rp-1-implementing-efficient-hash-tables-on-gpus)
 * [RP-2: Exploring Aliquot Sequences with Markov Chains](#rp-2-exploring-aliquot-sequences-with-markov-chains)
 * [RP-3: Reinforcement Learning for Team Based Card Games](#rp-3-reinforcement-learning-for-team-based-card-games)
 * [RP-4: Reinforcement Learning - Looking for new Backgammon Strategies](#rp-4-reinforcement-learning---looking-for-new-backgammon-strategies)
 * [AR-1: Seismic Risk Assessment](#ar-1-seismic-risk-assessment)
 * [AR-2: Containerised UQ](#ar-2-containerised-uq)
 * [AR-3: Stress Recovery Methods](#ar-3-stress-recovery-methods)
 * [AR-4: Higher-order Visualisation in Paraview](#ar-4-higher-order-visualisation-in-paraview)
 * [PR-1: Classification of typical plants for assessment of the health of a natural habitat](#pr-1-classification-of-typical-plants-for-assessment-of-the-health-of-a-natural-habitat)
 * [PR-2: Thorough Comparison of Deep Networks](#pr-2-thorough-comparison-of-deep-networks)
 * [PR-3: Machine Learning for storage and summarisation of large data](#pr-3-machine-learning-for-storage-and-summarisation-of-large-data)
 * [PR-4: How much information can be removed from an image while preserving what it wishes to convey?](#pr-4-how-much-information-can-be-removed-from-an-image-while-preserving-what-it-wishes-to-convey)
 * [HS-1: People Movement Trajectory Analysis and Prediction with Deep Learning](#hs-1-people-movement-trajectory-analysis-and-prediction-with-deep-learning)
 * [HS-2: Synthesizing 3D Human Motion for Games and Animation with Deep Learning](#hs-2-synthesizing-3d-human-motion-for-games-and-animation-with-deep-learning)
 * [HS-3: Vision-based Drones/UAVs Tracking with Deep Learning](#hs-3-vision-based-dronesuavs-tracking-with-deep-learning)
 * [HS-4: Human Activity Recognition from Skeletal Data with Deep Learning](#hs-4-human-activity-recognition-from-skeletal-data-with-deep-learning)
 * [HS-5: Recognising People in Artworks with Computer Vision and Deep Learning](#hs-5-recognising-people-in-artworks-with-computer-vision-and-deep-learning)
 * [HS-6: Hand-object Interaction Detection in Egocentric Video with Deep Learning](#hs-6-hand-object-interaction-detection-in-egocentric-video-with-deep-learning)
 * [HS-7: Deep Learning Based Machine Vision for Space Imagery](#hs-7-deep-learning-based-machine-vision-for-space-imagery)
 * [CS-1: An Enhanced Tutor](#cs-1-an-enhanced-tutor)
 * [CS-2: Developing a collaborative intelligence with the EThOS collection of the British Library - HCI focus](#cs-2-developing-a-collaborative-intelligence-with-the-ethos-collection-of-the-british-library---hci-focus)
 * [CS-3: VR Knowledge village](#cs-3-vr-knowledge-village)
 * [CS-4: Tamagotchi: from egg to avatar](#cs-4-tamagotchi-from-egg-to-avatar)
 * [CS-5: Cultural Artefacts in eLearning](#cs-5-cultural-artefacts-in-elearning)
 * [IAS-1: Meta-heuristics for colouring graphs and colouring decentralized networks](#ias-1-meta-heuristics-for-colouring-graphs-and-colouring-decentralized-networks)
 * [IAS-2: Meta-heuristics for computing dominating sets in graphs](#ias-2-meta-heuristics-for-computing-dominating-sets-in-graphs)
 * [IAS-3: Programming matter to shape-shift](#ias-3-programming-matter-to-shape-shift)
 * [IAS-4: Solving reconfiguration problems using meta-heuristic methods](#ias-4-solving-reconfiguration-problems-using-meta-heuristic-methods)
 * [IAS-5: Community detection in large-scale social networks](#ias-5-community-detection-in-large-scale-social-networks)
 * [IAS-6: Embedding virtual machines in data centre networks](#ias-6-embedding-virtual-machines-in-data-centre-networks)
 * [IAS-7: Solving the Travelling Salesperson Problem using meta-heuristics](#ias-7-solving-the-travelling-salesperson-problem-using-meta-heuristics)
 * [IAS-8: Applying meta-heuristic methods to solve hard problems](#ias-8-applying-meta-heuristic-methods-to-solve-hard-problems)
 * [DS-1: Named Entity Disambiguation using Knowledge Graphs](#ds-1-named-entity-disambiguation-using-knowledge-graphs)
 * [DS-2: OCR Post-correction through Text Reuse Identification](#ds-2-ocr-post-correction-through-text-reuse-identification)
 * [DS-3: Interactive analysis and visualisation of TEI documents](#ds-3-interactive-analysis-and-visualisation-of-tei-documents)
 * [DS-4: Using character compositionality to improve Chinese NER](#ds-4-using-character-compositionality-to-improve-chinese-ner)
 * [DS-5: Unsupervised authorship clustering](#ds-5-unsupervised-authorship-clustering)
 * [AT-1: Exploring and Simulating Network  Distributed Algorithms](#at-1-exploring-and-simulating-network--distributed-algorithms)
 * [AT-2: Improving Project Allocations: Software or Theory for the Matching Problem](#at-2-improving-project-allocations-software-or-theory-for-the-matching-problem)
 * [AT-3: Designing and Testing Self-healing Distributed and/or Compact routing Algorithms](#at-3-designing-and-testing-self-healing-distributed-andor-compact-routing-algorithms)
 * [AT-4: Characterising Equilibria of the EU Grant Games](#at-4-characterising-equilibria-of-the-eu-grant-games)
 * [WT-1: Wireless Multicast at the MAC Layer](#wt-1-wireless-multicast-at-the-mac-layer)
 * [TV-1: Near-Insensitivity of occupancy-based load distribution policies in multi-server homogeneous systems](#tv-1-near-insensitivity-of-occupancy-based-load-distribution-policies-in-multi-server-homogeneous-systems)
 * [TV-2: An optimal load distribution policy for heterogeneous service systems](#tv-2-an-optimal-load-distribution-policy-for-heterogeneous-service-systems)
 * [TV-3: Finding Optimal Entanglement Distribution Policies for Quantum Networks Using MDPs](#tv-3-finding-optimal-entanglement-distribution-policies-for-quantum-networks-using-mdps)
 * [TV-4: Achieving Distance Independent Entanglement Rates in Quantum Networks](#tv-4-achieving-distance-independent-entanglement-rates-in-quantum-networks)
 * [TV-5: Energy Efficient Counting Rule for Detecting Adversaries in Wireless Sensor Networks](#tv-5-energy-efficient-counting-rule-for-detecting-adversaries-in-wireless-sensor-networks)
 * [TV-6: Robustness of the Counting Rule for Detecting Adversaries in Wireless Sensor Networks](#tv-6-robustness-of-the-counting-rule-for-detecting-adversaries-in-wireless-sensor-networks)
<hr>

### EA-1: Connectivity of interval temporal networks

| Description | An interval temporal network is a network whose edges are active for one or more time intervals and inactive the rest of the time. Work has been done previously on instantaneous connectivity of interval temporal networks, where the network is considered to be connected during a period of time [x,y], if it is connected for all time instances within the continuous time interval [x,y]. This project will look at the implementation of existing and possible development of new approaches to preserve connectivity of an interval temporal network over time (by maintaining a 'bank' of extra edges, available during certain time intervals, which can reconnect the network in case it becomes disconnected). |
| - | - |
| Reference URLs | https://www.worldscientific.com/doi/pdf/10.1142/S0129626419500099 |
| Anticipated Outcomes | Implementation and evaluation of existing algorithms with possible development of new approaches. |
| Requirements | An interest and background knowledge in graph theory and graph algorithms |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | temporal graph, graph connectivity, algorithm |
| Interview Required | No |

### EA-2: Exact and approximation algorithms for exploration of temporal stars and other dynamic graphs

| Description | Exploration of temporal stars (i.e. star graphs whose edges appear and disappear over time) can model travelling salesman scenarios where the salesman has to follow particular timetables for his routes and always returns to the origin after visiting a new vertex. The aim of the project is to look at existing exact and approximation algorithms, their implementation and evaluation of their performance compared to the theoretically predicted performance. Special cases will also be considered to examine possible improvement of already known algorithms. Other classes of graphs with meaningful definitions of exploration may also be considered, with relevant algorithms implemented and evaluated empirically. |
| - | - |
| Reference URLs | https://arxiv.org/pdf/1805.04713.pdf |
| Anticipated Outcomes | Implementation and evaluation of existing algorithms with possible development of new approaches. |
| Requirements | An interest and background knowledge in graph theory and graph algorithms, and good programming skills |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | temporal graph, graph exploration, approximation algorithm |
| Interview Required | No |

### EA-3: Binary search on graphs

| Description | The goal of this project is to understand and implement a search for a hidden treasure in a connected graph. It is assumed that the search algorithm queries some selected vertices and then a 'help' returns either (a) that the treasure is in this vertex or (b) an edge in a shortest path to the treasure. The student must implement the search in some simple classes of graphs such as lines and trees, and some general graphs. The implementation requires good understanding of shortest path algorithms. |
| - | - |
| Reference URLs | https://arxiv.org/abs/1503.00805 |
| Anticipated Outcomes | Implementation of a way to input the graph and the hidden treasure location and then implementation of the search on such an input.<br><br>The student shall implement both the search procedure and the 'help' given to the search procedure. The student should at least implement and test the search process on trees of arbitrary size. |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | binary search, graph algorithms |
| Interview Required | No |

### EA-4: Path and reachability problems in temporal graphs

| Description | Paths are fundamental concepts in graph theory and path finding algorithms have long been developed for static graphs, notably used in applications such as routing (e.g. packets over the Internet) or navigation. With temporal graphs, i.e. graphs that change over time, one needs to revisit the notion of a path and may in fact develop various temporal analogues of a static path. This project will focus on the implementation and development of path finding algorithms for temporal graphs. The basis of the project will involve familiarising yourself and implementing existing work for computing shortest, fastest and foremost temporal paths. You will then progress to studying and exploring reachability problems in temporal graphs, such as Minimizing Reachability Times on Temporal Graphs via Shifting Labels (see work by Deligkas et al.) or Deleting edges to restrict the size of an epidemic in temporal networks (see work by Enright et al.). |
| - | - |
| Reference URLs | https://www-apr.lip6.fr/~buixuan/files/BFJ03.pdf<br>https://arxiv.org/pdf/2112.08797.pdf<br>https://www.sciencedirect.com/science/article/pii/S0022000021000155 |
| Anticipated Outcomes | Implementation and evaluation of existing algorithms with possible development of new approaches. |
| Requirements | An interest in temporal graphs and background knowledge in graph theory and graph algorithms. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | temporal graphs; paths; graphs; algorithms |
| Interview Required | No |

### AA-1: Are Looks Deceiving? Exploring the Effects of Image Enhancement Techniques on the Performance of Convolutional Neural Networks

| Description | Image enhancement techniques (e.g. Transforms, Filters, Operators, etc.) have been used for decades to improve the quality of images to enable better human analysis. This project intends to investigate the effects of such enhancement techniques on learning-based computer vision methods. We know that image processing techniques used to enhance the visual quality of the images do not actually add more information to the images and can only produce more visually pleasing results or extract specific features from images by manipulating information that is already contained within the image. Modern learning-based computer vision techniques such as Convolutional Neural Networks (CNNs), however, receive raw images as their input and given enough training data should be able to learn their way around any visual changes in the image. As a result, it would make sense that image processing techniques, while used as data augmentation methods, should not make much of a difference in the actual performance of the neural network but besides intuition, there is little evidence of this in the literature. The parameters of the project will be decided by the student, but the overall goal is to identify how if at all image enhancement techniques can effect the performance of CNNs over various tasks. Experiments are required to identify performance with different image processing methods, different neural network architecture, transfer learning, pre-trained models, training from scratch, etc. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | Report outlining results of the research into effects of image enhancement techniques on the performance of neural networks. The outcome will include results of experimentation and analysis, software artifacts and potential publication. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image Processing, Computer Vision, Convolutional Neural Networks, Image Enhancement |
| Interview Required | No |

### AA-2: Automatic Quality Control for the Evaluation of Deep Learning Algorithms Applied to Images of the Eye

| Description | Optical Coherence Tomography (OCT) is a non-invasive image acquisition modality that uses low-coherence light to generate images at micrometer resolution [1]. Retinal OCT captures three-dimensional volumetric data with cross-sectional images (B-scans) to show the details of cellular layers in the retina [2]. Since manual annotation of retinal boundaries is time-consuming, subjective, and prone to error, automatic cell layer segmentation has been an active area of research in recent years [3,4]. However, even the most promising segmentation methods fail in some cases. The main problem is that 3D OCT of each patient consists of 100 to 500 B-scans and failing in correct segmentation of some images leads to problematic 3D reconstruction of the retinal cell layers, needed in subsequent treatment or diagnosis applications. The parameters of the project will be decided by the student but the overall aim of this project is to develop a learning-based supervised classification algorithm capable of categorising each segmented image as either correct or incorrect. The labelled data is available for this task and the performance of the network will be compared against an expert ophthalmologist. |
| - | - |
| Reference URLs | [1]    D. Huang, E.A. Swanson, C.P. Lin, J.S. Schuman, W.G. Stinson, W. Chang, M.R. Hee, T. Flotte, K. Gregory, C.A. Puliafito, J.G. Fujimoto, Optical Coherence Tomography, Science (80-. ). 254 (1991) 1178â€“1181. https://doi.org/10.1126/science.1957169.<br>[2]    W. Drexler, J.G. Fujimoto, State-of-the-art retinal optical coherence tomography., Prog. Retin. Eye Res. 27 (2008) 45â€“88. https://doi.org/10.1016/j.preteyeres.2007.07.005.<br>[3]    Kafieh, R., Rakhshani, S., Hogg, J., Lawson, R. A., Pavese, N., Innes, W., ... & Hurlbert, A. (2022). A robust, flexible retinal segmentation algorithm designed to handle neuro-degenerative disease pathology (NDD-SEG). Investigative Ophthalmology & Visual Science, 63(7), 2080-F0069.<br>[4]    Yadav, S. K., Kafieh, R., Zimmermann, H. G., Kauer-Bonin, J., Nouri-Mahdavi, K., Mohammadzadeh, V., ... & Brandt, A. U. (2022). Intraretinal Layer Segmentation Using Cascaded Compressed U-Nets. Journal of Imaging, 8(5), 139. |
| Anticipated Outcomes | Report outlining results and conclusions of the research. The outcome will include results of experimentation and analysis, software artifacts and potential publication. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks and libraries needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image Processing, Computer Vision, Medical Imaging, OCT, Deep Learning |
| Interview Required | No |

### AA-3: Multi-Modal, Scale, and Class detection of ophthalmologic diseases through anomaly detection

| Description | With development of AI methods, successful applications are introduced for retinal disease detection. Diagnosis of retinal abnormalities is essentially dependant on multimodal data, including 2D and 3D images with basic clinical information. However, current learning-based approaches often relies on large scale labelled data for training, which is oftentimes challenging especially for disease with low occurrence. Moreover, a model trained from dataset with one or a few diseases is unable to detect other unseen diseases, which limits the practical usage of the system in disease screening. This project focuses on a multimodal and multiscale solution for the identification of different diseases through anomaly detection. Different anomaly detection methods can be explored to help identify unseen and unknown diseases by taking advantage of healthy patient data only. |
| - | - |
| Reference URLs | [1] Zhou, K., Gao, S., Cheng, J., Gu, Z., Fu, H., Tu, Z., ... & Liu, J. (2020, April). Sparse-gan: Sparsity-constrained generative adversarial network for anomaly detection in retinal oct image. In 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI) (pp. 1227-1231). IEEE.<br><br>[2] Akcay, S., Atapour-Abarghouei, A., & Breckon, T. P. (2019). Ganomaly: Semi-supervised anomaly detection via adversarial training. In Computer Vision–ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2–6, 2018, Revised Selected Papers, Part III 14 (pp. 622-637). Springer International Publishing.<br><br>[3] https://arxiv.org/pdf/2007.02500.pdf<br><br>[4] https://github.com/openvinotoolkit/anomalib |
| Anticipated Outcomes | Report outlining results and conclusions of the research. The outcome will include results of experimentation and analysis, software artifacts and potential publication. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks and libraries needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image Processing, Computer Vision, Medical Imaging, Deep Learning, Anomaly Detection |
| Interview Required | No |

### AA-4: Revealing retinal changes in Alport syndrome with image processing and machine learning

| Description | This project focuses on the Alport syndrome (AS) and its retinal implications, where we aim to unravel the intricate relationship between this rare genetic disorder, the kidneys, and the eyes. AS poses significant threats to vision, making it crucial to understand its impact on the retina. Using state-of-the-art automatic segmentation techniques on in vivo 3D retinal imaging in one of the largest AS cohorts to date, we seek to uncover the full spectrum of retinal alterations in this condition with aid of deep learning algorithms. By uncovering the link between retinal cell rarefaction, foveal morphology, genetic factors, and systemic disease, we hope to shed light on the development of AS in the eye and kidney. This knowledge will have a profound impact on early detection, monitoring, and treatment planning for AS, ultimately improving patient care and outcomes. This project has the potential to contribute to advancements in medical data analysis, machine learning, and image processing. External collaborators will be involved in this work. |
| - | - |
| Reference URLs | [1] W. Drexler, J.G. Fujimoto, State-of-the-art retinal optical coherence tomography., Prog. Retin. Eye Res. 27 (2008) 45–88. https://doi.org/10.1016/j.preteyeres.2007.07.005.  <br>[2] Kafieh, R., Rakhshani, S., Hogg, J., Lawson, R. A., Pavese, N., Innes, W., ... & Hurlbert, A. (2022). A robust, flexible retinal segmentation algorithm designed to handle neuro-degenerative disease pathology (NDD-SEG). Investigative Ophthalmology & Visual Science, 63(7), 2080-F0069. <br>[3] Ghadiri, N. J., Stanojcic, N., Raja, M. S. A., & Burton, B. J. (2019). A triad of retinal signs in Alport syndrome: the ‘stair-case’fovea, choroidal thinning and peripheral schisis. European Journal of Ophthalmology, 29(1_suppl), 10-14. |
| Anticipated Outcomes | Report outlining results and conclusions of the research. The outcome will include results of experimentation and analysis, software artifacts and potential publication. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks and libraries needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image Processing, Computer Vision, Medical Imaging, Deep Learning |
| Interview Required | No |

### AA-5: Why can't I find Wally? Exploring the effect of distractors on the performance of convolutional neural networks in cluttered scenes

| Description | Convolutional Neural Networks (CNN) show impressive performance when it comes to object detection, localisation and classification. However, these problems become extremely challenging when the scene is cluttered and contains irrelevant information that distracts the neural network. This is even true for humans, as evidenced by puzzle games such as "Where's Wally?", where the goal is to find the target in a cluttered scene. The objective of this project is to explore the effects of distractors on the performance of CNNs when attempting tasks such as object detection or semantic segmentation. The parameters of the project will be decided by the student, but the overall goal is to identify how if at all clutter hinders performance. Data can be generated on the fly by artificially introducing clutter into otherwise simple scenes. Where's Wally data can also be used as part of the analysis by identifying which part of the cluttered scene the CNN is paying attention to in presence of distractors. |
| - | - |
| Reference URLs | https://en.wikipedia.org/wiki/Where's_Wally<br>https://github.com/vc1492a/Hey-Waldo<br>https://arxiv.org/pdf/1610.02391.pdf |
| Anticipated Outcomes | Report outlining results of the research into effects of clutter on the performance of neural networks. The outcome will include results of experimentation and analysis and software artifacts. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | Convolutional Neural Network, Object Detection, Semantic Segmentation, Cluttered Scenes |
| Interview Required | No |

### AA-6: Can surgery revitalize the eyes?

| Description | The macula is a specialised region of the eye in which there is a very high packing density of cones, particularly in its centre, the fovea. The formation of the fovea is characterised by a migration, largely after birth, of the inner retinal layers away from the centre to form a pit with concurrent migration of cone photoreceptors inwards. The inward migration during childhood increases the cone packing density affording good visual acuity through adulthood. The process has been termed foveation and has not thought to be possible other than in development.<br><br>A variety of disease and injuries can affect the centre of the fovea, including macular holes.  Full-thickness macular holes (FTMHs) are defects in the foveal centre involving all neural retinal layers. Their estimated prevalence is approximately 3 per 1000.  FTMHs reduce visual acuity and have a significant impact on quality of life. Surgical management with pars plana vitrectomy (PPV) is successful in closing macular holes and improving vision.  The mechanism of visual restoration has always been thought to be due to simple cone re-apposition but careful observation of macular hole patients after surgery suggest that a process analogous to foveation seen earlier in life may be an important process in the healing of macular holes. These findings may have significance in the potential restoration of acuity in other disorders involving the macula and may be amenable to therapeutic interventions.<br><br>This project will use deep learning and image processing methods to examine images pre and postoperatively of patients undergoing macular hole surgery to detect its occurrence and will also look at the association of preoperative and postoperative variables including visual acuity and RPE health, thought to be an important determinant of foveation in utero. External collaborators will be involved in this work. |
| - | - |
| Reference URLs | [1] W. Drexler, J.G. Fujimoto, State-of-the-art retinal optical coherence tomography., Prog. Retin. Eye Res. 27 (2008) 45–88. https://doi.org/10.1016/j.preteyeres.2007.07.005.  <br>[2] Kafieh, R., Rakhshani, S., Hogg, J., Lawson, R. A., Pavese, N., Innes, W., ... & Hurlbert, A. (2022). A robust, flexible retinal segmentation algorithm designed to handle neuro-degenerative disease pathology (NDD-SEG). Investigative Ophthalmology & Visual Science, 63(7), 2080-F0069. <br>[3] Spaide, R. F. (2022). Healing Mechanisms after Macular Hole Repair Suggests Process of Foveation. RETINA, 10-1097. |
| Anticipated Outcomes | Report outlining results and conclusions of the research. The outcome will include results of experimentation and analysis, software artifacts and potential publication. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks and libraries needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image Processing, Computer Vision, Medical Imaging, OCT, Deep Learning |
| Interview Required | No |

### AA-7: Automatic detection of cell density in eyes using deep learning

| Description | Using advanced imaging techniques, we can capture cellular-resolution images of the living human retina, which is the light-sensitive tissue at the back of the eye. This is not possible with the ‘standard’ instruments you may have seen at the optometrist and there are very few research labs with this capability. We can use the images captured by this instrument in a number of important clinical and non-clinical applications, from studying disease to investigating the workings of the human visual system. An important measurement that we need to make is the density of photoreceptor cells, as this is altered in many retinal diseases, having a devastating impact on a person’s sight. Making these measurements accurately can help us understand these diseases better and possibly detect them earlier. But, labelling the large number of cells visible in these images is challenging. Doing this manually is time-consuming and prone to error, and the accuracy of automated approaches is variable and often needs a manual check of the output. This project will investigate two automated methods using neural networks, but unlike other published studies, it will use images from human participants and images generated via simulation [1] both to produce large training datasets and to properly characterise algorithm performance. This will help us to derive better metrics of cell density and arrangement that we can use to analyse images collected from patients with retinal disease. External collaborators will be involved in this work. |
| - | - |
| Reference URLs | [1] Young; Smithson. Emulated retinal image capture (ERICA) to test, train and validate processing of retinal images. Scientific Reports, 11, 11225 (2021). |
| Anticipated Outcomes | Report outlining results and conclusions of the research. The outcome will include results of experimentation and analysis, software artifacts and potential publication. |
| Requirements | The student should be familiar with the principles of machine learning, deep learning, image processing, computer vision and the frameworks and libraries needed for implementation (e.g. PyTorch, TensorFlow / Keras, etc.) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image Processing, Computer Vision, Medical Imaging, Deep Learning |
| Interview Required | No |

### GA-1: Carbon Intelligent Computing for for Control and Optimisation of Data Centres

| Description | Cloud computing (CC) is one of the most popular technologies which provides on-demand ubiquitous services to the geo-located end users. Such services are hosted by physical infrastructure deployed at massive data centers (DCs) at various geographic locations. For handling millions of service requests, DCs consume a large amount of energy which increases the overall operational expenditure, grid load, and carbon footprints. So, to handle these issues, the integration of DCs with renewable energy sources is one of the solutions used by the research community from past many years. Regional carbon-free energy includes both a variable sources of energy such as solar and wind, with cloud service providers shifting compute to the nearest data center with available renewable sources. Carbon-intelligent computing platform uses day-ahead predictions of how heavily a given grid will be relying on carbon-intensive energy in order to shift computing across the globe, favoring regions where thereâ€™s more carbon-free electricity. |
| - | - |
| Reference URLs | https://ieeexplore.ieee.org/abstract/document/7949095<br>https://ieeexplore.ieee.org/abstract/document/8278252<br>https://www.sciencedirect.com/science/article/pii/S0167739X17321581<br>https://www.sciencedirect.com/science/article/pii/S0743731517302149 |
| Anticipated Outcomes | This project will aim to realise a sustainable mechanism to handle the energy demands of cloud data centres using renewable energy sources based on carbon intelligent computing. This project will help to prioritise cleaner grids, and maximise the proportion of carbon-free energy that powers their applications by choosing regions with better carbon-free energy scores. |
| Requirements | A little knowledge or interest in a) Cloud Computing, b) Machine/deep learning, and c) MATLAB, will be sufficient. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Carbon Intelligent Computing, Cloud Computing, Artificial Intelligence, Cloud Data Centres |
| Interview Required | No |

### GA-2: Electric Vehicle as a Service for Disaster-like Scenarios

| Description | Urban Areas or Cities are largely dependent on infrastructure specifically critical infrastructures (CIs) to provide a quality living standard, public services, economic development and good governance to the society. In emergency situations or in the case of disaster, Electric Vehicles (EVs) can act as mobile service providers wherein they can perform multifaceted roles as energy stores (can be used for charging and discharging of energy to/fro grid), data stores, edge nodes (for computation and processing), roadside communication units (can act as communication devices for data transmission) and many more. EVs can move around the urban areas to supply power to CIs and even act as mobile communication nodes which can provide connectivity. But, before deploying EVs in urban areas for handling emergency services and sustaining basic functionalities for CIs, there are many challenges which must be tackled or some novel solutions are required for the same. This project aims to develop a new framework and novel IoT data management techniques to support the development of next generation applications for restoring power to CIs during disaster situations. In case of disruption of cloud or even edge connectivity, the usage of EVs as an alternative edge-computing infrastructure and roadside units (RSU) as an alternative communication media needs will be investigated.  In this project, EVs can act as such computational chips, which can be utilised for data collection, storage and even processing if required. However, developing an integrated IoT-Edge-Cloud data processing framework and techniques for restoring power supply to CIs, specifically in disaster scenario, are faced with following hard research and technical questions: <br>â€¢    What are the core data types, which need to integrate for achieving dynamic decision making as regards to EV mobilization and placement for protecting CIs during disaster situations?<br>â€¢    How  to constantly monitor and handle the velocity, volume, and variety of IoT data from multiple sensor types (smart meters, temperature, humidity, appliances, light)  and roof-top photovoltaic farms (micro-grids) connected to CIs for building energy demand profiles? <br>â€¢    How to exploit combined edge-cloud infrastructures for data collection, processing and storage in disaster as well as normal scenarios?<br>â€¢    How to schedule and coordinate the spatial-temporal movement of EVs in the urban areas for service provisioning and energy supply to CIs considering limited connectivity to cloud and communication network? |
| - | - |
| Reference URLs | https://www.sciencedirect.com/science/article/pii/S1389128618304900<br>https://www.sciencedirect.com/science/article/abs/pii/S138912861831106X |
| Anticipated Outcomes | This project aims to design a hybrid IoT-Edge-Cloud data management framework to support real-time sensing, collection, transmission of energy-use data of CIs and energy-production data of EVs. We foresee that such data sets will be monitored via IoT sensors connected to: (i) CIs including smart meters, rooftop micro grids, phasor management units, humidity, temperature, and lighting and (ii) EVs including battery unit monitoring sensors, state of charge sensors, and tyre pressure sensors. This project also aims to develop (IoT-Edge-Cloud) resource capacity-aware learning algorithms and computational models for deriving the context and the real-time energy-consumption behavioural patterns of (CIs) and energy-production patterns of EVs. Finally, using the above to outcomes, this project aims at a larger goal to develop data-driven, energy-consumption (CIs) and energy-production (EVs), real-time time decision making techniques for scheduling and coordination of EVs movement in order to restore energy to CIs during disasters. |
| Requirements | Basic knowledge about IoT, Edge and Cloud paradigms is necessary. Moreover, some experience on working with energy problems, data management algorithms, machine/deep learning is also preferable. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Electric Vehicles, Edge Computing, Cloud Computing, Critical Infrastructures, Internet of Things |
| Interview Required | No |

### GA-3: Blockchain supported Privacy Aware Ecosystems

| Description | The COVID19 Pandemic has highlighted our dependence on online services (from government, e-commerce/retail, and entertainment), often hosted over external cloud computing infrastructure. The users of these services interact with a web interface rather than the larger distributed service provisioning chain that can involve an interlinked group of providers. The data and identity of users are often provided to service provider who may share it (or have automatic sharing agreement) with backend services (such as advertising and analytics). This project aims to the development of compliance-aware cloud application engineering, which can improve transparency of personal data use â€“ particularly with reference to the European GDPR regulation. Compliance refers to an act of obeying, i.e., any conduct that is based or bounded on (by) a specific rule, policy, order, or request. It is based on different principles, for example, the GDPR legislation sets out seven key principles: Lawfulness, fairness and transparency, purpose limitation, data minimisation, accuracy, storage limitation, integrity and confidentiality (security), and accountability. Although cloud providers continue to provide mitigation strategies to limit/avoid data loss, significant challenges still remain, especially when multiple providers need to work together. The liabilities of any unauthorised access or usage of personal data can have a significant impact on cloud provider revenue, and more importantly cloud provider market reputation (and perception). One of the biggest questions for cloud providers is to understand the sensitivity of the data entrusted upon them by users. Another problem lies with the varied compliance guidelines across different geographic locations. This makes it hard to understand any applicable laws and monitor data flows across different geographic boundaries. Users often entrust their privacy to an organisation, but when the organisation relies on different cloud providers located across different locations, then different privacy and compliance conditions arise. Here lies the risk of data leakage. |
| - | - |
| Reference URLs | https://ieeexplore.ieee.org/abstract/document/9250321 |
| Anticipated Outcomes | The outcomes of the project are focussed on the design of a compliance-aware cloud application engineering covering, three dimensions, namely, compliance provsioning, compliance monitoring, compliance verification and logging using blockchain. |
| Requirements | Basic knowledge related to multi-cloud environment, virtualisation or docker environment, and blockchain (ethereum or hyper ledger fabric). |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### GA-4: Blockchain framework for supply chain management

| Description | In the past decade, global market is heavily linked to and affected by supply chains (SCs). An SC is defined as a system comprising various activities involving people, technology, resources, manufacturing, and selling goods to the consumers. SC management plays a crucial role in the oversight and management of SC activities. In the past SC systems have faced several challenges as a result of conventional SC management options such as (ERP) enterprise resource planning and financial ledgers. Blockchain is a newer technology that has the potential to provide SC systems with many benefits because of its powerful properties. Many existing proposals have adopted blockchain for SCs. However, there are still some critical gaps in the research. Thus, this work aims to overcome the incompetency of the existing frameworks by designing a scalable blockchain framework for the circular SC ecosystem. |
| - | - |
| Reference URLs | 1. Chang, Shuchih E., and Yichian Chen. "When blockchain meets supply chain: A systematic literature review on current development and potential applications." IEEE Access 8 (2020): 62478-62494.â€ <br>2. Kshetri, Nir. "1 Blockchainâ€™s roles in meeting key supply chain management objectives." International Journal of information management 39 (2018): 80-89. |
| Anticipated Outcomes | 1. A scalable blockchain framework to control and coordinate the data and decision flow in the circular SC ecosystem.<br>2. Implement and validate the circular SC ecosystem using a realistic use case scenario based on various performance indicators |
| Requirements | Knowledge about blockchain, smart contracts, solidity (would be useful), python. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### EB-1: Generative modelling of non-text handwritten document annotations

| Description | Handwritten annotations enrich documents with extra information, not least text. While there is considerable interest in handwritten text recognition (HTR) for commercial, government, and cultural applications there is less focus on non-text annotations: underlines, editorial marks, deletions, doodles, and so on. This applied machine learning project, in the area of document analysis, will explore the use of generative models of raster (image) and/or vector graphic representations of non-text handwritten annotations. Generative models of this data are useful, since they may be used to generate synthetic training data used in other downstream document analysis tasks, including semantic document layout analysis (semantic segmentation of document images). Solutions to this problem have applications in information management and to the digital humanities, particularly in the field of digitized cultural heritage. |
| - | - |
| Reference URLs | Carlier, Alexandre, Martin Danelljan, Alexandre Alahi, and Radu Timofte. "DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation". In Advances in Neural Information Processing Systems, 33:16351-61. 2020. https://proceedings.neurips.cc/paper/2020/hash/bcf9d6bd14a2095866ce8c950b702341-Abstract.html<br>Carter, et al., "Experiments in Handwriting with a Neural Network", Distill, 2016. http://doi.org/10.23915/distill.00004<br><br> |
| Anticipated Outcomes | The student will be expected to identify, collect, create or otherwise curate a dataset of handwritten non-text annotations, choose and implement a suitable generative model, and evaluate its performance using standard techniques. |
| Requirements | COMP3527 Computer Vision OR COMP3547 Deep Learning |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | computer vision, document analysis, semantic segmentation, handwriting, generative modelling |
| Interview Required | No |

### EB-2: Open project in code as primary source material in the <blink>history of computing</blink>

| Description | Histories of computing help us identify the mistakes of the past and to prepare us for the future of computation. Though the documents stored in traditional historical archives provide ample information about the social and economic setting for innovation, computer histories can only be strengthened by the analysis of passages of source code as a primary source: a task that requires technical competence as well as historical literacy. Project students will - with the support of the supervisor - be expected to identify the source code relating to one or more historical examples of applied or theoretical computer science, to understand and critically analyse the historical significance of this code, and to report on their findings in an extended piece of academic writing. This can relate to any aspect of the history of computing, including scientific, industrial, cultural, governmental, or creative applications of computers in society. Project students who are interested in exploring some part of the history of computing relating to backgrounds and perspectives currently underrepresented in the field are especially welcome to propose a project in this area. Students are strongly encouraged to contact the project supervisor well in advance of choosing this option to discuss their suitability for this project. |
| - | - |
| Reference URLs | <br>Haigh, Thomas, and Paul E. Ceruzzi. A New History of Modern Computing. History of Computing. Cambridge, Mass.: The MIT Press, 2021.<br>Marino, Mark C. Critical Code Studies. Cambridge, Mass.: MIT Press, 2020.<br>Montfort, Nick, Patsy Baudoin, John Bell, Ian Bogost, Jeremy Douglass, Mark C. Marino, Michael Mateas, Casey Reas, Mark Sample, and Noah Vawter. 10 PRINT CHR$(205.5+RND(1));: GOTO 10. Cambridge, Mass.: MIT Press, 2012.<br> |
| Anticipated Outcomes | An extended piece of written work deriving from the quantitative and/or qualitative analysis of technical primary sources (i.e. source code listings) identified by the project student, with the support of the supervisor. Students are welcome to prepare interactive supporting material for this project, including but not limited to online digital exhibitions, blog posts, and/or screencasted walkthroughs. |
| Requirements | No formal prerequisites but project students must have excellent written expression and attention to detail in report-writing, curiosity about the history of computing, as well as a capacity to interpret and analyse code examples written in obsolete, unfamiliar, and often poorly documented programming languages. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | history of computing, critical code studies, digital humanities |
| Interview Required | Yes |

### EB-3: Analysing relevance, reliability, and information flow in user-generated comments on online music videos

| Description | The comment sections for online music videos in sites like YouTube are often chaotic, but sometimes rich in user-generated insights about music, video, popular culture, and contemporary aesthetics at large. This project theme investigates how to identify the most meaningful user-generated comments on a dataset of music videos in order to extract insight into the target multimedia to which they are related. Possible research goals within this theme include any or all of the following: (a) designing and testing a measure of the relevance of a specific comment to its target music video; (b) identifying the reliability of information about music videos and musical tracks relative to other data sources; (c) quantifying the lag between such reliable information in user-generated comments and other data sources; (d) characterising the reliability and flow of information within the social graph of commenting users. |
| - | - |
| Reference URLs | <br>Vliegendhart, Raynor, Martha Larson, Babak Loni, and Alan Hanjalic. ‘Exploiting the Deep-Link Commentsphere to Support Non-Linear Video Access’. IEEE Transactions on Multimedia 17, no. 8 (August 2015): 1372–84. https://doi.org/10.1109/TMM.2015.2449086.<br>Yarmand, Matin, Dongwook Yoon, Samuel Dodson, Ido Roll, and Sidney S. Fels. ‘“Can You Believe [1:21]?!”: Content and Time-Based Reference Patterns in Video Comments’. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, 1–12. CHI ’19. New York, NY, USA: Association for Computing Machinery, 2019. https://doi.org/10.1145/3290605.3300719.<br> |
| Anticipated Outcomes | To be discussed with supervisor |
| Requirements | (COMP2271 Data Science OR COMP2261 Artificial Intelligence). Desirable (for L3 project students, as co-requisite): COMP3517 Computational Modelling in the Humanities and Social Sciences. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | online multimedia, comments, NLP, digital humanities |
| Interview Required | No |

### EB-4: Tracking the production and circulation of MIDI files during the 1990s

| Description | MIDI files are a compact representation of music data, designed to be consumed by sequencers and synthesizers (both hardware and software). A new archive of approximately 400,000 MIDI files dating from the 1990s has been distilled from a large set of CD images (.iso files) that have been available online from the Internet Archive (archive.org). This project requires a set of tools for the analysis of MIDI files at scale, as well as their relations to each other, based on shared content, metadata, and co-occurence on the same CD image. Research questions include: (a) the design of an efficient and scalable software pipeline information extraction (IE) and other knowledge mining techniques to extract structured data from the plaintext metadata that these files include; (b) the production of temporal dynamic graphs that model historically interesting relations between files, as well as an evaluation of the suitability of standard and non-standard graph metrics for deriving insight from these graphs; (c) the design and implementation of a user interface, using standard data analysis frameworks, for the effective and user-friendly analysis of large volumes of MIDI files. |
| - | - |
| Reference URLs | <br>Lisena, Pasquale, Albert Meroño-Peñuela, and Raphaël Troncy. ‘MIDI2vec: Learning MIDI Embeddings for Reliable Prediction of Symbolic Music Metadata’. Semantic Web 13, no. 3 (2022): 357–77. https://doi.org/10.3233/SW-210446.<br>Raffel, Colin, and Daniel P. W. Ellis. ‘Extracting Ground-Truth Information from MIDI Files: A MIDIfesto.’ Proceedings of the 17th International Society for Music Information Retrieval Conference. New York City, United States, August 2016. https://doi.org/10.5281/zenodo.1418233.<br> |
| Anticipated Outcomes | To be discussed with supervisor |
| Requirements | (COMP2271 Data Science OR COMP2261 Artificial Intelligence). <br><br>Desirable (either as pre-requisite or co-requisite): COMP3517 Computational Modelling in the Humanities and Social Sciences OR COMP3717 Introduction to Music Processing |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | MIDI, music processing |
| Interview Required | No |

### SC-1: Using NLP to understand political success based on party manifestos

| Description | Apply NLP and data analysis techniques to the manifesto project dataset to examine how political manifestos relate to voting practices or wider societal events and trends.  <br><br>One option would be to look at the relationships (via NLP) between these manifestos and the outcomes of elections, or how they reflect wider historical or social trends, or relate to specific social issues, or examine how different issues are covered at different time periods in different countries. |
| - | - |
| Reference URLs | <br>https://manifesto-project.wzb.eu/datasets <br> https://manifesto-project.wzb.eu/publications/all <br> https://www.pnas.org/doi/10.1073/pnas.1720347115  <br> https://aclanthology.org/K19-1024.pdf <br> |
| Anticipated Outcomes | Potential outcomes may include: descriptive, predictive and/or explanatory data analytics; building prediction models based the manifestos and or related open datasets (e.g. government, news, google ngrams, ParlaSpeech Corpus, Hansard Speeches and Sentiment dataset); exploring political and other forms of bias in word embeddings trained on the manifestos data; visualisation of the data for a user-facing system. |
| Requirements | Some understanding of data analytics and NLP; some level of experience with pandas, Matplotlib, Seaborn, R, PyTorch, Keras or similar is useful. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | data analytics, NLP, visualisation, politics, bias, visualisation |
| Interview Required | No |

### SC-2: Debating what’s important to civic life: NLP and data analysis of political debates

| Description | In this project you will apply techniques from NLP, data analytics and potentially data visualization to look at patterns and trends in the data to help interpret the wider socio-political issues. <br><br>In this project you will apply NLP, data analysis and potentially data visualization techniques to political debates datasets to examine what topics are most prevalent, dominant, contested or divisive and how this relates to wider socio-historical trends. Working with datasets that document political debates and decision-making processes that impact on public life, such as The Hansard Speeches dataset and ParlaSpeech Corpus. These datasets records parliamentary debates, where elected MPs set the agenda for public priorities, but how have different topics been defined and ascribed value in political speeches and how has this changed over time? For example, in 1980 only 3% of MPs in the UK were women. How did the increasing participation of women influence what items made it onto the agenda or how they were talked about? Did the participation of women MPs change as numbers increased and what impact did this have on agenda setting / topic discussed? <br><br>Particularly when working with textual data, finding ways to discover, summarise and visualise is important in supporting sensemaking processes – this could be an exploratory data analysis project or a more user-centered project that looks at how text can be summarised and visualised. |
| - | - |
| Reference URLs | <br>Hansard Speeches and Sentiment V3.0.1 -https://zenodo.org/record/4843485#.YgVcG33P3_Q <br>ParlaSpeech Corpus  - https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN <br>ParlaSpeech Corpus notes - https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/L4OAKN/C2TWCZ&version=1.0 <br>https://www.tandfonline.com/doi/pdf/10.1080/10584609.2020.1833121?<br>https://www-sciencedirect-com.ezphost.dur.ac.uk/science/article/pii/S246869642200012X <br>https://www.cambridge.org/core/journals/political-analysis/article/creating-and-comparing-dictionary-word-embedding-and-transformerbased-models-to-measure-discrete-emotions-in-german-political-text/2DA41C0F09DE1CA600B3DCC647302637 <br> https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651887 <\li><br> |
| Anticipated Outcomes | Potential outcomes may include:  <br><br> descriptive, predictive and/or explanatory data analytics; <br> building prediction models based on the debate datasets and related open datasets (e.g. party manifestos, news, google books corpus); <br> measuring emotion in political debate; <br>political view point analysis; <br> a diachronic lexical analysis; <br> a visualisation of the data for a user-facing system, e.g. a visualisation of sentiment and topic composition of the data; representing the changing participation of women in British politics, including points in time where the number of women MPs suddenly increased (e.g. 1997 election); a geographical representation of the prominent concerns in different regions; a visualisation of the coverage and narrative strategies used in relation to one more topic (e.g. climate change or art vs science) or comparing different countries. <br> an interface to facilitate argument exploration, or for exploring the use of subjective versus objective language in the debates. <br> |
| Requirements | Some understanding of data analytics and NLP; some level of experience with Seaborn, R, PyTorch, Keras or similar is useful. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | NLP, data analysis, politics, debates, computational social science |
| Interview Required | No |

### SC-3: Conspiracy theories: understanding and predicting conspiratorial content using natural language processing

| Description | In this project you will conduct an analysis of the LOCO conspiracy theory dataset to identify commonalities and features common across different topics. You may produce a comparative analysis of online rumour, misinformation and conspiracy data to explore commonalities and differences between different types of harmful content or train a classifier to identify if a given article is conspiratorial or not. |
| - | - |
| Reference URLs | <br>https://aclanthology.org/2022.law-1.14.pdf <\li><br>https://osf.io/snpcg/ <\li><br>https://onlinelibrary.wiley.com/doi/pdf/10.1002/ejsp.2903 <\li><br>https://dl-acm-org.ezphost.dur.ac.uk/doi/abs/10.1145/3543873.3587534 <\li><br><\ul> |
| Anticipated Outcomes |  |
| Requirements | Some understanding of data analytics and NLP; some level of experience with Seaborn, R, PyTorch, Keras or similar is useful. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### RCr-1: Predicting student experiences based on their characteristics

| Description | Students should process and analyse existing data using machine learning techniques to predict the impact of student characteristics (such as gender, race or economic status) on their degree choices and university choices. Example data has been provided. Students should use multiple machine learning techniques to identify the most useful model. Finally, the student should build an interface for which this data can be displayed. Additionally students could identify the factor with the highest weighting / impact on the final choice. |
| - | - |
| Reference URLs | https://www.hesa.ac.uk/data-and-analysis/students USA Based Data https://data.world/nces/postsecondary-programs-courses/workspace/project-summary?agentid=nces&datasetid=postsecondary-programs-courses <br>https://data.world/nces/postsecondary-programs-courses/workspace/project-summary?agentid=nces&datasetid=postsecondary-programs-courses <br> <br>https://link.springer.com/article/10.1007/s10639-018-9828-x <br>https://ieeexplore.ieee.org/document/9497185 |
| Anticipated Outcomes | An understanding of the equality issues faced by potential students and an implementation of an interface to display said data. |
| Requirements | An understanding of machine learning techniques |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Machine Learning, Education |
| Interview Required | No |

### RCr-2: Using Mermaid to Enhance Accessibility of Diagrams.

| Description | Mermaid is a tool which allows a user to create and modify a variety of diagrams using JavaScript and Markdown inspired text definitions. While this has many benefits, mermaid can be beneficial for users with additional accessibility needs, such as those using screen readers to understand diagrams.  For this project students would be required to create a project which translated existing diagrams into a mermaid mark down form. Example projects could be turning C# Classes into Mermaid style class diagrams. Or using Machine Learning for image recognition to identify objects in hand drawn diagrams so a user can turn them into markdown. Students will have freedom to choose which diagrams they use and how they translate said diagrams. Students could also complete a usability / accessibility evaluation between mermaid and other systems of a similar make. |
| - | - |
| Reference URLs | https://mermaid-js.github.io/mermaid/#/ <br>https://ieeexplore.ieee.org/document/4634384  |
| Anticipated Outcomes | An understanding of the equality issues faced by potential students and the benefits of accessible classes. An understanding of Machine learning classification techniques. A product which outputs Mermaid style markdown. |
| Requirements | An understanding of machine learning techniques and the ability to use pre-existing APIs |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Machine Learning, API, Image Processing |
| Interview Required | No |

### SSD-1: Machine Learning for Game Playing

| Description | Reinforcement Learning (RL) is a machine-learning paradigm according to which an agent ought to take actions in an environment so as to maximize some notion of cumulative reward. When applied to games, a computer player gradually learns a good strategy by repeatedly playing against another player or against itself. For a number of games most notably Go, RL has produced not only the strongest AI players known up to now but also a player that can easily beat the best humans. The purpose of this project is to develop an RL algorithm for a game of the student's choice, to implement it, and to evaluate its competitiveness. |
| - | - |
| Reference URLs | https://www.nature.com/articles/nature24270<br>https://arxiv.org/abs/1712.01815 |
| Anticipated Outcomes | An implementation of one or more computer players for a game chosen by the student. |
| Requirements | Interest in Machine Learning. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Machine Learning, Reinforcement Learning, Neural Networks, Monte Carlo Tree Search, Alpha Go Zero, Deep Q Learning |
| Interview Required | No |

### SSD-2: Learning and Generating Graphs with Deep Neural Networks

| Description | Modelling and generating graphs is fundamental for studying networks in many areas of science and engineering. However, modelling complex distributions over graphs and being able to efficiently sample from them is challenging due to the high-dimensional nature of graphs and the non-local dependencies between edges. Recently, GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure, has been proposed. The main aim of this project is to implement (a modification of) the method and evaluate it on real-world data as well as on synthetic data. |
| - | - |
| Reference URLs | https://cs.stanford.edu/people/jure/pubs/graphrnn-icml18.pdf |
| Anticipated Outcomes | An implementation of (a modification of) the GraphRNN model. |
| Requirements | Interest in Machine Learning and Graph Theory. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Machine Learning, Graph Theory. |
| Interview Required | No |

### SSD-3: Theorem Proving in Lean

| Description | Lean is a theorem prover and programming language based on the calculus of constructions with inductive types. This project aims to pick a small yet non-nontrivial area of Theoretical Computer Science or Mathematics and formalise it in Lean. |
| - | - |
| Reference URLs | https://leanprover.github.io/theorem_proving_in_lean/<br>http://wwwf.imperial.ac.uk/~buzzard/xena/natural_number_game/ |
| Anticipated Outcomes | Lean code that constitutes valid proofs of certain theorems in TCS or Maths. |
| Requirements | Interest in Mathematics or Theoretical Computer Science, and formal proofs in particular. Willingness to learn a new programming language. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Automated Theorem Proving, Lean Theorem Prover |
| Interview Required | No |

### PD-1: Implementation and Visualisation of Distributed Graph Algorithms

| Description | Distributed graph algorithms is an area of study focusing on representing computer networks as graphs, and solving graph problems on these networks. Recent advances have seen a host of fast algorithms for fundamental graph problems such as maximal independent set, maximal matching, and graph colouring. These algorithms also lend themselves to visualisation, which would be valuable for building intuition both for teaching and research. However, to my knowledge, there is no existing implementation of most of these algorithms, and no suitable visualisation tool.<br><br>The aim of this project would be to build a framework on which to implement some classic algorithms in the LOCAL and CONGEST models, and potentially to visualise the progress of these algorithms. |
| - | - |
| Reference URLs | This project will be strongly related to the content of COMP4227 Distributed Network Computing and Algorithms. For background reading on LOCAL/CONGEST algorithms, see the textbook by Juho Hirvonen and Jukka Suomela (available free online at https://jukkasuomela.fi/da2020/da2020.pdf) |
| Anticipated Outcomes | Implement a framework on which CONGEST and LOCAL algorithms can be simulated.<br>Implement some classic CONGEST and LOCAL algorithms (e.g. Luby's MIS algorithm, simple randomized coloring).<br>(Extension) Implement some more advanced algorithms, and compare performance (e.g. Ghaffari's MIS algorithm, sublogarithmic coloring algorithms).<br>(Extension) Implement a system for visualising distributed graph algorithms in progress. |
| Requirements | COMP4227 Distributed Network Computing and Algorithms |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Distributed Graph Algorithms, Simulation, Visualisation |
| Interview Required | No |

### PD-2: Implementation of Algorithms for Massively Parallel Computation

| Description | With the rise of parallel programming paradigms such as MapReduce designed to handle massive datasets, the Massively Parallel Computation (MPC) model was developed as a theoretical model of such systems. In the past years, many efficient algorithms have been developed for MPC, for basic primitives such as sorting as well as for graph problems. However, most of these theoretical algorithms have not (at least publicly) been implemented and tested in practice. The aim of this project would be to conduct these implementations in MapReduce, and evaluate performance on massive graphs. |
| - | - |
| Reference URLs | See here for the paper that introduced MPC to model MapReduce: https://theory.stanford.edu/~sergei/papers/soda10-mrc.pdf |
| Anticipated Outcomes | Implement algorithms designed for MPC within MapReduce, including (potentially) sorting, maximal independent set, and graph coloring algorithms.<br><br>Evaluate the performance of these algorithms, on massive graphs and highly parallel systems. |
| Requirements | COMP3557 Design of Algorithms and Data Structures would be helpful but not essential. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | MapReduce, Massively Parallel Computation, Graph Algorithms |
| Interview Required | No |

### PD-3: Implementation of Discrete Logarithm Algorithms

| Description | The security of several public-key cryptosystems is based on the hardness of the discrete logarithm problem. While the problem is conjectured to require exponential computation to solve on a conventional computer, there are an array of algorithms that improve over a naive brute-force approach in many cases. The aim of this project would be to explore these techniques and empirically compare their performance. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | Implement some algorithms for discrete logarithm (Shank's algorithm, Pollard Rho, Pohlig Hellman, Index Calculus).<br>Compare the performance of these algorithms over inputs with a variety of sizes and characteristics. |
| Requirements | COMP 3697 Cryptography |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Cryptography, Discrete Logarithm |
| Interview Required | No |

### PD-4: Implementation of Factoring Algorithms

| Description | The well-known RSA cryptosystems is based on the hardness of factoring products of large primes (semiprimes). This problem is widely thought to require exponential computation to solve on a conventional computer (though there exists a polynomial-time quantum algorithm). However, algorithms and heuristics are still studied to factor larger inputs, with the RSA Factoring Challenge offering rewards for factoring a list of semiprimes of increasing size (though the challenge ended in 2007, many of the semiprimes remain unsolved and efforts are still ongoing). The aim of this project would be to explore the techniques used for factoring, and empirically compare performance. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | Implement some algorithms for factoring, e.g. Pollard p-1, Pollard Rho, Quadratic Sieve, Galois Field Number Sieve). Compare the performance of these algorithms over inputs with a variety of sizes and characteristics. Potentially propose and test novel heuristics. |
| Requirements | COMP 3697 Cryptography |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Cryptography, Factoring, RSA |
| Interview Required | No |

### PD-5: Implementation of Algorithms with Predictions

| Description | "Algorithms with Predictions" is an area of algorithms research which has emerged fairly recently as a  way to marry the theoretical study of algorithms with the prominence of machine learning algorithms (that produce predictions without any theoretical guarantees). The idea is that, for some classical algorithmic problem, we are provided with predictions about the input that may or may not be accurate. The aim is an algorithm for the problem that provably performs better if it receives good predictions, but is still no worse than the existing worse-case bound if it receives bad predictions.<br><br>Algorithms with predictions have been developed for a variety of problems. The aim of this project would be to evaluate the performance of the algorithms for a particular problem, and compare to existing techniques. |
| - | - |
| Reference URLs | See here for an article introducing the concept: https://dl.acm.org/doi/pdf/10.1145/3528087. A list of papers about algorithms with predictions is here: https://algorithms-with-predictions.github.io/ |
| Anticipated Outcomes | Implement algorithms with predictions for a problem (or problems) of your choice. Compare the performance of these algorithms against existing techniques, for a range of inputs and prediction qualities. |
| Requirements | COMP3557 Design of Algorithms and Data Structures would be helpful but not essential. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Algorithms with Predictions, Implementation |
| Interview Required | No |

### TE-1: Learning-Augmented Algorithms for Minimum Spanning Trees under Uncertainty

| Description | Computing with explorable uncertainty studies problems where some input values are uncertain (represented as intervals), but queries can be made to obtain the precise values. The goal is usually to make as few queries as possible until sufficient information has been acquired to solve the problem. In this project (which is related to the EPSRC-funded project ACUTE - Algorithms for Computing with Uncertainty: Theory and Experiments) we consider the minimum spanning tree problem with uncertain edge weights. Furthermore, we assume that predictions for the precise edge weights are available (these could have been obtained via machine learning, for example), and we are interested in query algorithms that benefit if the predictions are accurate but do not get misled too much if the predictions are of poor quality. The project involves implementing and experimentally evaluating such algorithms, with the possibility to design new variations of such algorithms and to prove results about them. |
| - | - |
| Reference URLs | https://arxiv.org/abs/0802.2855<br>https://arxiv.org/abs/2206.15201 |
| Anticipated Outcomes | Implementation and experimental evaluation of the performance of one or several algorithms for the problem;<br>Presentation of experimental results using suitable plots and tables |
| Requirements | Programming skills in Python, java, C++ or another suitable language; basic understanding of graph theory (minimum spanning trees) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | graph algorithms, query strategies, implementation and evaluation of algorithms |
| Interview Required | No |

### TE-2: Query-based algorithms for Computing with Stochastic Uncertainty

| Description | Computing with explorable stochastic uncertainty studies problems where some input values are uncertain (represented as intervals with probability distributions over them), but queries can be made to obtain the precise values. The goal is usually to make as few queries as possible until sufficient information has been acquired to solve the problem. In this project (which is related to the EPSRC-funded project ACUTE - Algorithms for Computing with Uncertainty: Theory and Experiments) we consider variations of the minimum and sorting problems for uncertain data. We are interested in query algorithms that minimise the expected number of queries, compared to the expected optimal number of queries for the given problem instance. The project involves implementing and experimentally evaluating such algorithms, with the possibility to design new variations of such algorithms and to prove results about them. |
| - | - |
| Reference URLs | https://arxiv.org/abs/2305.09245 |
| Anticipated Outcomes | Implementation and experimental evaluation of the performance of one or several algorithms for the problem; Presentation of experimental results using suitable plots and tables |
| Requirements | Programming skills in Python, java, C++ or another suitable language; basic understanding of probability |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | computing with uncertain data, algorithm implementation, algorithm evaluation |
| Interview Required | No |

### TE-3: Actively Reconfigurable Networks

| Description | Recent developments in networking technology (e.g., free-space optical networks and optical circuit switching) make it possible for computer networks to undergo frequent, controlled topology changes. While the traditional view has been that a network topology that changes as little as possible is ideal, we can now explore network designs that involve frequent, deliberate changes to how the nodes of the network are connected to each other. For example, a node could have just 2 ports, but the 2 other nodes to which it is connected by direct links could change frequently. Topology changes could be made in response to current traffic demands or periodic. Current research investigates the use of such changing topologies in cloud data centres. The goal of the project is to explore and evaluate (by simulations and/or theoretical analysis) how the performance of such ever-changing networks compares to that of static networks. |
| - | - |
| Reference URLs | https://dl.acm.org/doi/10.1145/3098822.3098838 |
| Anticipated Outcomes | Implementation of a tool to simulate and evaluate actively reconfigurable networks;<br>Evaluation of different approaches to the design of reconfigurable network topologies |
| Requirements | Programming experience in python, java, C++ or another suitable programming language; basic knowledge of graphs and networks. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | networking, graphs, time-varying networks |
| Interview Required | No |

### TE-4: Automatic Generation of Conference Programmes

| Description | The schedule for a scientific conference typically consists of a number of parallel sessions (where contributed papers are presented) and plenary sessions (where invited speakers give plenary talks). In a good schedule, the talks scheduled in the same session should normally be on related topics. One also wants to avoid the situation where participants want to attend two talks but these talks are scheduled at the same time in parallel sessions. The goal of this project is to design, implement and evaluate a software system that can be used to assist the creation of a good schedule for a conference. It should allow participants to submit information about which talks they wish to attend and then arrange the sessions in such a way that conflicts are minimised.<br><br>The paper "Conference Scheduling - A Personalized Approach" (PATAT 2016) presents an approach to solving this problem for a medium-sized conference. This paper can serve as inspiration for the software to be developed in this project. |
| - | - |
| Reference URLs | https://www.patatconference.org/patat2016/files/proceedings/paper_30.pdf |
| Anticipated Outcomes | A web application that allows the conference organizers to enter information about the schedule and the accepted papers, and that allows conference participants to enter their preferences regarding which talks they wish to attend. The application should then generate a conference schedule that minimizes conflicts and possibly also optimizes other suitable criteria. |
| Requirements | Interest in applying combinatorial optimization techniques to a real-world problem. Ability to implement a web application with an automatic schedule generation method in a suitable programming language. A report presenting the design and evaluation of the automatic schedule generation method. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | optimisation, algorithms, scheduling |
| Interview Required | No |

### TE-5: Automatic allocation of group projects

| Description | There are many educational settings where students need to be allocated into groups in such a way that each group can be assigned a topic and a group supervisor. Typically, students have preferences over the topics that are available, and each available supervisor can only cover certain topics and supervise a limited number of groups. The goal of this project is to design, implement and evaluate a software system (for example, a web application) into which all the relevant information can be entered and that can then automatically produce a group allocation that respects the students' preferences as much as possible. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | A software system that implements the automatic generation of a good group allocation. A report describing the design and implementation of the software as well as a suitable experimental evaluation. |
| Requirements | Interest in algorithms for allocation problems with preferences. Programming skills in a suitable programming language. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Matching under preferences |
| Interview Required | No |

### TE-6: Exploration of dynamic networks

| Description | A dynamic network can be modelled by a temporal graph: A graph with a fixed set of nodes whose edge set may change in every time step. One fundamental problem in temporal graphs is to find temporal journeys along which an agent can visit all vertices of the graph as quickly as possible. This is called the temporal exploration problem. In this project, the goal is to study temporal graph exploration in the setting where the agent can move over an arbitrary number of edges in each time step. Of particular interest is the case where the graph in each time step consists of a small number of connected components. |
| - | - |
| Reference URLs | https://doi.org/10.1007/978-3-030-54921-3_8 |
| Anticipated Outcomes | Design, implementation and experiments with algorithms for temporal graph exploration.<br>Possibly also theoretical results about the exploration time in different settings, or about the computational complexity for different special cases. |
| Requirements | Interest in graph algorithms.<br>Familiarity with at least one suitable programming language (for example, Python). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | temporal graph, temporal exploration, graph algorithms |
| Interview Required | No |

### TE-7: Algorithms for Matching with Uncertain Preferences and Queries

| Description | Many allocation problems involve matching agents to each other in such a way that their preferences are respected. A classical example is the Stable Marriage problem where n women and n men each have a preference list among the members of the other gender, and the goal is to compute a stable matching. This problem can be solved by the classical Gale-Shapley (1962) algorithm. Matching problems with preferences occur in many other settings (e.g. stable roommates, hospital/residents problem, student-project allocation problem, etc.).<br><br>In this project, you will study settings of matching with preferences where some of the preferences are uncertain (unknown or only partially known) and it is possible to make queries to find out information about the uncertain preferences. The goal is then to use as few queries as possible until a stable allocation can be computed. One can also consider making queries in rounds (where some number of queries can be made in parallel), and the goal is to minimise the number of rounds. For example, a query could mean asking one agent a question such as "among potential partners a and b, which of the two do you prefer"? |
| - | - |
| Reference URLs | https://www.worldscientific.com/worldscibooks/10.1142/8591#t=aboutBook |
| Anticipated Outcomes | Design, implementation and experimental (and/or theoretical) evaluation of algorithms for selecting queries in a suitable matching problem with uncertain preferences.<br><br>Report including literature survey, problem formulation, and results obtained. |
| Requirements | Interest in algorithms and combinatorial problems<br>Implementation skills in a suitable programming language (e.g. python, java, C++) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | stable marriage, matching with preferences, explorable uncertainty |
| Interview Required | No |

### TE-8: Scheduling with Testing

| Description | This project is about scheduling problems where each job consists of two operations: a test whose duration is known in advance, and a main part whose duration becomes known only after the test. The problem can be considered for a single processor that can execute at most one test or main part at any time. The goal is to minimize the average completion time of the jobs. To evaluate an algorithm, it is compared with the optimal offline schedule, which could be computed if all processing times of the jobs' main parts were known in advance. The difficulty for an algorithm lies in deciding in which order to test the jobs and whether to execute next the main part of a tested job or the test of an untested job.<br>Problem extensions that could be considered involve scheduling on multiple machines or scheduling jobs with release times (i.e. jobs that become available to be scheduled only at a certain time). For jobs with release times, the sum of response times can be considered as objective function. |
| - | - |
| Reference URLs | https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2017.2973<br>https://arxiv.org/abs/1709.02592 |
| Anticipated Outcomes | Design, implementation and experimental evaluation of scheduling algorithms.<br>Potential to obtain theoretical results regarding upper and lower bounds on the best achieveable performance guarantees for a scheduling algorithm in this setting.<br>Report including literature survey, problem definition, algorithm descriptions, and results of experimental evaluation. |
| Requirements | Interest in algorithms and scheduling.<br>Programming skills in a suitable programming language (e.g. python, java, C++). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | explorable uncertainty, scheduling with sum of completion times |
| Interview Required | No |

### YF-1: Anomaly Detection and Segmentation in Image and Pixel Level on X-ray Security Imagery

| Description | Reliably detecting anomalies in a given set of images is a<br>task of high practical relevance for visual quality inspection, surveillance,<br>or medical image analysis. In many of the<br>real world problems, however, samples from the more unusual classes of interest<br>are of insufficient sizes to be effectively modelled.<br>For example is<br>X-ray screening for aviation or border security where anomalous items posing a security threat are not commonly encountered, exemplary data of such<br>can be difficult to obtain in any quantity, and the nature of any anomaly posing a potential threat may evolve due to a range of external factors. However,<br>within this challenging context, human security operators are still competent<br>and adaptable anomaly detectors against new and emerging anomalous threat<br>signatures. Motivated by finding the abnormality in a large datasets, particularly in real world application such as X-ray security screening, we leverage existing anomaly detection  deep learning architecture in readily available X-ray image security screening such as SIXRay and OPIXRay. It is hopeful that the <br>experimentation over established anomaly detection benchmarks and challenging real-world<br>datasets, within the context of X-ray security screening, may shows the unique promise of such a proposed approach. |
| - | - |
| Reference URLs | Akcay, S., Ameln, D., Vaidya, A., Lakshmanan, B., Ahuja, N. and Genc, U., 2022. Anomalib: A Deep Learning Library for Anomaly Detection. arXiv preprint arXiv:2202.08341.<br><br>Zavrtanik, V., Kristan, M. and SkoÄaj, D., 2021. Draem-a discriminatively trained reconstruction embedding for surface anomaly detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 8330-8339).<br><br>Yu, J., Zheng, Y., Wang, X., Li, W., Wu, Y., Zhao, R. and Wu, L., 2021. Fastflow: Unsupervised anomaly detection and localization via 2d normalizing flows. arXiv preprint arXiv:2111.07677. |
| Anticipated Outcomes | A working software demonstrator, open source contribution and technical evaluation of anomaly detecion using deep CNN architectures via X-ray Security Imagery |
| Requirements | Students must have taken or be taking Image Processing, Computer Vision and ideally Machine Learning / Deep Learning and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the Linux operating system is of benefit. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | computer vision, image processing, machine learning , deep learning, convolutional neural networks, object detection, anomaly detection |
| Interview Required | No |

### YF-2: Thats looks Weird! Finding anomaly from Eye in the Sky.

| Description | Unmanned aerial vehicles (UAVs) are widely applied<br>for purposes of inspection, search, and rescue operations by the<br>virtue of low-cost, large-coverage, real-time, and high-resolution<br>data acquisition capacities. Massive volumes of aerial videos are<br>produced in these processes, in which normal events often account<br>for an overwhelming proportion. It is extremely difficult to localize and extract abnormal events containing potentially valuable<br>information from long video streams manually. Therefore in this project <br>we want to detect and track abnormal object from drone point of view (eye in the sky) in different scenario<br>from various location and various weather condition. It is hopeful that the <br>experimentation over established anomaly detection benchmarks and  challenging real-world drone datasets<br>may shows the unique promise of such a proposed approach. |
| - | - |
| Reference URLs | Chen, Kai, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun et al. "MMDetection: Open mmlab detection toolbox and benchmark." arXiv preprint arXiv:1906.07155 (2019).<br><br>Zhu, Pengfei, Longyin Wen, Dawei Du, Xiao Bian, Heng Fan, Qinghua Hu, and Haibin Ling. "Detection and tracking meet drones challenge." IEEE Transactions on Pattern Analysis and Machine Intelligence 44, no. 11 (2021): 7380-7399.<br><br>Akcay, Samet, Dick Ameln, Ashwin Vaidya, Barath Lakshmanan, Nilesh Ahuja, and Utku Genc. "Anomalib: A deep learning library for anomaly detection." In 2022 IEEE International Conference on Image Processing (ICIP), pp. 1706-1710. IEEE, 2022. |
| Anticipated Outcomes | A working software demonstrator, open source contribution and technical evaluation of anomaly detecion using deep CNN architectures via drone imagery. |
| Requirements | Students must have taken or be taking Image Processing, Computer Vision and ideally Machine Learning / Deep Learning and be comfortable with (or able to readily pickup) python/C++ to be able to leverage existing implementations. A familiarity with OpenCV, modern machine learning tools and the Linux operating system is of benefit. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | computer vision, image processing, machine learning , deep learning, convolutional neural networks, object detection, anomaly detection |
| Interview Required | No |

### MGo-1: Surprise! “Uniform Information Density” may not be so uniform after all…

| Description | “Uniform Information Density” suggests that communication works best when information is evenly distributed over time. This is a familiar, relatively well-established notion in language; in music is it is hardly known (URL below notwithstanding).<br><br>Does UID apply only to the direct communication of information? What about more artistic settings? I.e., do texts communicating information (e.g., newspaper prose) differ from those that are more playful and elusive (e.g., poetry)? What about information density in music? And what about the combination of music and text in songs?<br><br>This comparative study of prose, poetry, texted music, non-texted music seeks insights into those large questions, framing them in relation to “surprise”. One ambitious student an take this all on, or else multiple students can divide the parts between them. |
| - | - |
| Reference URLs | https://mtosmt.org/issues/mto.19.25.2/mto.19.25.2.temperley.html |
| Anticipated Outcomes | Build on existing neural network working (LSTM);<br>Apply new models;<br>Tests hypotheses in one or more domains (music, prose, ...);<br>Produce publishable write-up. |
| Requirements | Solid machine learning experience;<br>Familiarity with & interest in  music and/or language (preferably both) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Uniform Information Density, language, music, NLP, surprisal |
| Interview Required | Yes |

### MGo-2: Quantifying musical complexity

| Description | How complex is:<br>1.    a musical source (audio, symbolic, or score)?<br>2.    a given system for describing (parts of) that source (e.g., harmonic analysis?)<br>3.    a specific analysis of 1 using 2.<br>Like many domains, the analysis of musical places value on parsimony … within reason. Do the “best” analyses achieve a suitable balance of explanatory power, with parsimonious means?<br><br>Data is available for a wide range of project, both corpus-level and smaller-scale (more exploratory, proof-of-concept). |
| - | - |
| Reference URLs | Many. E.g., if working with harmonic analyses:<br>http://github.com/MarkGotham/When-in-Rome/ |
| Anticipated Outcomes |  |
| Requirements | Basic complexity theory; entropy. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Music, complexity, entropy, analysis |
| Interview Required | No |

### MGo-3: Musical corpus building and data analysis

| Description | While “computer music” has been around for a long time in contexts like electronic composition, “music information retrieval” for the analysis of musical sources is a field in its relative infancy, especially as applied to symbolic sources (like musical scores) and particularly human-generated analysis data (commentary on those sources). As such there is a great deal of uncharted territory and endless project possibilities in the creation and analysis of data sets, as well as the definitions of syntaxes and best practice they depend on. In addition to clear cases lie harmony and form, especially under-studied examples include musical texture and rhythmic analysis. There is also a large gap between all of this and the practice of (for example) live-coding. I bring a great many specific project ideas on  all of the above, and am open to student suggestions for the musical repertoires and parameters that interest you. |
| - | - |
| Reference URLs | Many. E.g., if working with harmonic analyses: http://github.com/MarkGotham/When-in-Rome/ |
| Anticipated Outcomes |  |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### MGo-4: Optical _Music_ Recognition

| Description | While the technology for Optical _character_ recognition has attracted major industrial fire power and achieved extremely good result (at least on modern, printed, English), the same cannot be said for the equivalent task for printed music: optical _music_ recognition. Recent developments in machine learning may help unlock this.<br><br>For this project, I suggest use of the “Open Score Lieder Corpus” dataset: 1,300 songs released under a CC0 (public domain) licence explicitly linked to PDF source material that’s already online. While usage as training data for OMR was among the explicit intensions in creating this dataset, that study has yet to take place. We will attempt to train SOTA improvements. There may be scope for industry collaboration here too.<br><br>Lieder:<br>VoR:<br>https://musescore.com/openscore-lieder-corpus<br>Repo ('Mirror'):<br>https://github.com/OpenScore/Lieder<br>Papers:<br>Gotham et al. 2018,<br>https://doi.org/10.17613/1my2-dm23<br>Gotham and Jonas 2021<br>https://doi.org/10.1145/3273024.3273026 |
| - | - |
| Reference URLs | https://github.com/OpenScore/Lieder |
| Anticipated Outcomes |  |
| Requirements | Solid machine learning experience;<br>Familiarity with & interest in  music and/or language (preferably both) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | Yes |

### MGo-5: Never mind the playlist, here’s the setlist

| Description | Streaming platforms like Spotify have changed the way we experience music. One consequence has been the lionisation of the “playlist” as a way of framing music.<br><br>While there’s clearly scope for creativity in this curation of music, many playlists actually seem to be relatively anodyne collections of music that’s “similar” in either genre (e.g., “ballads”), or mood (e.g., “chillout”), or both.<br><br>What they typically lack is a shape: there’s no need to have a clear start, end, or even sense of climax. Contrast that with the set lists of _live_ gigs. For instance, how often have you sat down and listened to a playlist end-to-end, without doing something else. But you surely notice if you go to a live gig and there isn’t a big (or otherwise satisfying) conclusion.<br><br>This varies by genre and style. The “big finish” I mention is typical for many kinds of fix-length sets (jazz, pop, classical alike), but clearly not so applicable to night clubs, where climaxes may come in several waves during specific parts of the night. Yet there too the setlist (equivalent) is given a meaningful shape.<br><br>Much music information retrieval (MIR) research has chased this new(ish) concept of the playslist as well as related matters of recommender systems that likewise groups “similar” items together. Much less attention has been given to the (arguably more interesting) setlist.<br><br>Example research questions include:<br>-    within set questions: which songs were played, in what order, and what are their relative popularity, tempo, length etc.<br>-    between set questions: how does artist X’s set list change over time (this can be on the few-month horizon of an album tour or on the 150 year entire history of certain orchestras).<br>-    genre-specific questions: which instrument solos where in a given jazz standards.<br><br>The data available includes:<br>- Simple lists at wiki sites like https://www.setlist.fm/ (> 6 million sets)<br>- full concert recordings can be found on sites like youtube (cf. Yi-Hsuan Yang et al. 2014).<br>- complete historical performance history of certain classical orchestras |
| - | - |
| Reference URLs | https://www.setlist.fm/<br>https://github.com/nyphilarchive/PerformanceHistory |
| Anticipated Outcomes |  |
| Requirements | Strong statistics |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | setlist, music, performance, live, gig |
| Interview Required | No |

### MGo-6: New algorithms for the development of Open Source Software MuseScore and/or Audacity

| Description | Music notation software like [MuseScore](https://musescore.org/en)<br>and audio editing tools like [Audacity](https://www.audacityteam.org/)<br>have matured to the point of covering basic functionality and<br>being ready for the introduction of entirely new algorithms that will<br>simultaneously advance the quality of these products and <br>also constitute an advance in the corresponding academic fields<br>(music information retrieval and audio signal processing respectively).<br>I bring many ideas for such projects and also direct connection to executives at both companies (who would effectively co-supervise).<br>At the same time, we are open to new suggestions.<br>Extremely successful projects can lead to job opportunities at "Muse Group" (the umbrella organisation that includes these companies).<br>Further details on request. |
| - | - |
| Reference URLs | https://musescore.org/en; https://www.audacityteam.org/ |
| Anticipated Outcomes | Design of research agenda;<br>Preparation of new code;<br>Successful PR. |
| Requirements | Essential: Strong C++ and Qt skills (the languages of these softwares) by the start of the project.<br>Essential: Strong domain knowledge (music notation for a project on MuseScore; audio signal processing for a project on Audacity).<br>Desirable: Experience in music information retrieval is an advantage. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Music notation, audio editing, open source, algorithms |
| Interview Required | Yes |

### SH-1: Deep learning in recommender systems

| Description | Recommender systems (RS) assist web users to filter through the staggering amount of online information. These are tools (algorithms, techniques) that combine machine learning, business and human-computer interaction fields to understand user preferences (at individual or group level) and produce recommendations of items that best match those preferences. <br><br><br>Deep learning  (DL) has gained significant attention in different fields due to its successful application. It employs neural architectures to learn deep representations from data. Research on DL application to RSs has been, as of recently, thriving, however, there are still multiple open questions. <br>The goal of this project would be to: <br>Explore the use of deep learning in recommender systems (in a selected domain), a) as a technique for learning/representing features (e.g. latent contexts) or, b) as a recommendation model; <br>Select existing dataset(s) for an offline experiment;<br>And to analyse and evaluate the performance of the proposed technique against alternative DL models and the traditionally used RS techniques.<br><br> |
| - | - |
| Reference URLs | https://dl.acm.org/doi/pdf/10.1145/3285029; https://www.sciencedirect.com/science/article/pii/S0950705116300727 |
| Anticipated Outcomes | Implementation of a DL-based Recommender System; <br>Evaluation of the proposed RS - against alternative models/techniques, and/or in alternative domains (different datasets). |
| Requirements | recommender systems, machine learning, deep learning, programming skills |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | recommender systems, deep learning, deep neural networks, machine learning |
| Interview Required | No |

### SH-2: Affect- and personality-aware recommender systems

| Description | Recommender systems (RS) assist web users to filter through the staggering amount of online information. These are tools (algorithms, techniques) that combine machine learning, business and human-computer interaction fields to understand user preferences (at individual or group level) and produce recommendations of items that best match those preferences. <br>Context-aware RS (CARS) aim to grasp a holistic picture of a user's condition (internal and external), in modelling her/his preferences and in using the contextual information to influence the resulting recommendations. Research has shown that expanding user profiles, beyond behaviour, with psychological models, such as emotions and/or personality, improves RS performance.<br>This project should, hence, aim to address a combination of the following: <br><br>1) Identify and evaluate tools/methods for acquiring affect and/or personality.; <br>2) Select/collect data: use existing dataset (limited annotation of psychological data - see references) for offline experiments; extract affect/personality features from implicit data (e.g., sentiment analysis on item reviews); or collect primary data via user studies (better quality data, smaller in size, requires more time, and ethical approval).;<br>3) Explore the use of multimodal data - and feature extraction methods in connection with automatic personality recognition (APR) methods and/or affect recognition methods.<br>4) Implement an affect-aware, or personality-aware, or an affect- and personality-aware recommender system - by considering advances in state-of-the-art (latest models/techniques) and/or feature extraction methods.;<br>5) Analyse and evaluate the performance of the proposed RS solution on suitable/relevant evaluation metrics, against alternative approaches (e.g., traditional 2D recommender, state-of-the-art models/techniques), and on alternative datasets (different domains) or affect/personality features.; <br>6) Analyse and address ethical issues stemming from collecting and using psychological data in CARS - privacy, bias, explainability, fairness.<br>7) Look into data issues, e.g. sparsity, dimensionality, imbalance; and methods to address these issues.<br><br> |
| - | - |
| Reference URLs | https://link.springer.com/chapter/10.1007/978-0-387-85820-3_7; https://ieeexplore.ieee.org/abstract/document/8374807; <br>https://link.springer.com/chapter/10.1007/978-1-4939-0530-0_6; https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7904698;<br>https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_21;<br>https://grouplens.org/datasets/personality-2018/;<br>https://zenodo.org/record/3248543#.Xhjy385zyM8;<br>http://www.cp.jku.at/datasets/musicmicro/index.html;<br>https://github.com/irecsys/CARSKit/tree/master/context-aware_data_sets;<br>https://www.yelp.com/dataset |
| Anticipated Outcomes | Evaluation and selection of tools for affect/personality acquisition; <br>Performing an offline experiment (on existing datasets) and/or an online experiment (user study - requires obtaining ethical approval);<br>Implementation of affect- or personality-aware RS; <br>Evaluation of the proposed RS solution on suitable/relevant evaluation metrics, against state-of-the-art models/techniques, alternative datasets or affect/personality features. |
| Requirements | recommender systems, machine learning, programming |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | recommender system, context-aware recommender system, machine learning, psychology, HCI, personality, emotion, affect, affective computing, FFM |
| Interview Required | No |

### SH-3: Affective Human-Computer Interaction: Intelligent system adaptation for emotion regulation

| Description | Human-computer interaction  (HCI) links computer science, design, and cognitive/behavioural sciences to explore people's use of computing devices and approaches to improving the usefulness and usability of those devices for human users. Advances in fields such as machine learning, computer vision, psychology, have led to numerous new developments in HCI methods and applications, including affective HCI, thus bridging the gap between humans and technology.<br> <br>This project should particularly: consider loneliness, anger, depression or anxiety as affective states; explore user interactions in these states; explore intelligent agent adaptation methods for emotion regulation (i.e., calming). <br>The project should address a combination of the following: <br> Multimodal method (e.g., heart rate, body movement, facial expressions, social media posts, self-assessment, etc.) for affective state acquisition and recognition.; <br> Application and evaluation of state-of-the-art machine learning techniques for adapting intelligent systems in response to a user's affective state. Agent adaptation can be achieved via, e.g., user interface (colour pallet, button shapes, navigation style, etc.), content recommendations (e.g., images, sounds, guided meditation), intelligent multimodal feedback, etc.<br> Design and development of a GUI for an application/web-based system abiding by the relevant HCI principles (domain-, user- or problem-dependent).<br> System evaluation - selection and application of relevant ML performance metrics and HCI measures (e.g. usability).<br> Analysis of ethical issues stemming from collecting and using psychological data in affective HCI - e.g. privacy, bias, fairness.<br><br><br>The following should also be taken into account:<br>- domain of application and availability of data for that domain;<br>- if primary data collection is required, i.e. performing user studies or A/B testing, ethical approvals will have to be obtained, sufficient participants have to be available, and participants have to have access to the system (e.g. downloadable application or hosted web-based system). <br> |
| - | - |
| Reference URLs | https://dl.acm.org/doi/pdf/10.1145/641007.641038; https://www.sciencedirect.com/science/article/pii/S1071581903000478;<br>https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed;<br>https://dl.acm.org/doi/proceedings/10.1145/3411764#heading20;<br>https://www.sciencedirect.com/science/article/pii/B9780125587044500104;<br>https://www.sciencedirect.com/science/article/abs/pii/0005791694900639;<br>https://link.springer.com/chapter/10.1007/978-3-319-66790-4_1;<br>https://link.springer.com/article/10.3758/s13428-016-0715-3;<br>https://iui-lecture.org/<br>https://www.youtube.com/watch?v=NOazEIijXTo&list=PLsZdV05-bvLHcePpoXlIVFNfT7q2Y1kOx&index=34 |
| Anticipated Outcomes | Intelligent affect-adaptive system; Multimodal affect recognition method; System evaluation based on HCI principles |
| Requirements | machine learning, computer vision, human AI interaction, programming |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | human-computer interaction, HCI, affect, adaptation, affective user modelling, intelligent systems, adaptive agents, user interface design, usability testing, multimodal emotion recognition, privacy, bias, mental health, anxiety, depression |
| Interview Required | No |

### SH-4: Responsible AI: Explainability, fairness, trust in Recommender Systems

| Description | AI-related ethical concerns have, as of recently, frequently been in the headlines. Some effort from governments (e.g. GDPR) and companies (e.g., Google) has been directed to addressing this issue, however, explainability, accountability, and fairness (bias) in AI have been understudied.<br><br>Recommender systems (RS) assist web users to filter through the staggering amount of online information. These are tools aim to understand user preferences and produce recommendations of items that best match those preferences. However, due to the increasing complexity of algorithms and the variety of data gathered, there is a need for transparency as to why a specific item is recommended to a user. Recommendations based on responsible AI principles increase the system's transparency, and users' trust and decision-making ability. <br><br>Therefore, the goal of this project is to perform (a combination of):<br> Explore and implement state-of-the-art methods for explainable/fair recommendations in a selected domain;<br>Analyse the use of heterogeneous user/item data (explicit - ratings, reviews; implicit), its characteristics and impact on the responsible AI principles;<br>Explore HCI principles and approaches for presenting explanations to users (e.g., format/media of presentation, explanation styles, presenting and explaining the user model/profile to the user, etc.);<br>Perform offline experiments to evaluate the implemented models/techniques on fairness/explainability/privacy/trust. Consider:  baselines, alternative models, alternative datasets;<br>Carry out a user study to evaluate the RS explanations/fairness (e.g., usefulness, transparency, privacy, trust).<br><br><br>The following should also be taken into account: <br>domain of application and availability of data for that domain; <br>if primary data collection is required, i.e. performing user studies or A/B testing, ethical approvals will have to be obtained, sufficient participants have to be available, and participants have to have access to the system (e.g. downloadable application or hosted web-based system).<br><br> |
| - | - |
| Reference URLs | https://ieeexplore.ieee.org/abstract/document/8594883; <br>https://dl.acm.org/doi/abs/10.1145/3331184.3331211; <br>https://hcixaitutorial.github.io/;<br>https://interactivesystems.info/publications/ubo_mods_00161373;<br>http://ceur-ws.org/Vol-2682/paper2.pdf;<br>https://iui-lecture.org/lmu2021/IUI-2021-01-21-pub/IUI_Explainable_AI.mp4;<br>https://www.netflix.com/gb/title/81328723<br>https://dl.acm.org/doi/pdf/10.1145/3184558.3186949<br>https://link.springer.com/chapter/10.1007/978-1-0716-2197-4_18<br>https://www.sciencedirect.com/science/article/pii/S0306457321001503<br>https://arxiv.org/pdf/1910.10045.pdf |
| Anticipated Outcomes | Recommender system (RS) with explainable recommendations; RS evaluation via an offline experiment (preferably additionally a user study performed); RS to be evaluated from responsible AI perspective (metrics including explainability, fairness, trust, diversity) |
| Requirements | recommender systems, machine learning, deep learning, AI |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | recommender systems, explainability, transparency, fairness, trust, bias, machine learning, AI |
| Interview Required | No |

### SH-5: Personal Stylist: Recommender Systems in Fashion

| Description | Recommender systems (RS) assist web users to filter through the staggering amount of online information. These are tools (algorithms, techniques) that combine machine learning, business and human-computer interaction fields to understand user preferences (at individual or group level) and produce recommendations of items that best match those preferences. <br>Context-aware recommender systems (CARS) aim to grasp a holistic picture of a user's condition (internal and external). Research has shown that expanding user profiles with contextual features (e.g. mood, weather, location), improves RS performance.<br>Fashion domain offers a variety of RS applications, including online clothing stores, personalised clothing and outfits based on body shape or preferred fashion styles, sustainable clothing utilisation, etc.<br>The goal of this project is to develop a CARS that would recommend personalised, context-aware, outfits for an individual (e.g., from a collection of liked/wish-list clothing items from online fashion stores). <br>The project should therefore combine one or more of the following tasks:<br>Select/collect data: use existing datasets (limited annotation of relevant fashion and contextual features) for offline experiments; or collect primary data from a number of target users (i.e. wardrobe items and labelling of clothing items by fashion style, context suitability, etc.);<br>Explore the use of deep learning for features extraction from clothing item images or text descriptions;<br>Implement a CARS: by considering state-of-the-art models/techniques for the fashion domain (knowledge-based approaches, conversational/dialogue agents, machine learning or deep learning models, etc.); and model user style preferences and contextual information (occasion, mood, weather, etc.) to ease and streamline the selection of the best-fit outfit(s) for a specific occasion. <br>Design and develop a GUI for a fashion RS (or Personal Stylist application/web-based system) abiding by the relevant HCI principles (domain-, user- or problem-dependent).;<br>System evaluation - selection and application of relevant ML performance metrics (comparison against alternative approaches); and preferably HCI measures (user study or A/B testing for evaluating user satisfaction with recommended outfits).<br>Consider sustainable fashion principles, and applications of data science for sustainable fashion.<br><br><br><br>The following should also be taken into account: if primary data collection is required, i.e. performing user studies or A/B testing, ethical approvals will have to be obtained, target participants have to be available, and participants have to have access to the system (e.g. downloadable application or hosted web-based system).<br> |
| - | - |
| Reference URLs | https://dl.acm.org/doi/abs/10.1145/3240508.3240546; <br>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7985599/;<br>https://ojs.aaai.org/index.php/AAAI/article/view/10509;<br>https://ieeexplore.ieee.org/abstract/document/8215493;<br>https://ieeexplore.ieee.org/abstract/document/6608496;<br>https://dl.acm.org/doi/abs/10.1145/3173574.3174201;<br>https://iui-lecture.org/;<br>https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed |
| Anticipated Outcomes | Fashion recommender system OR Personal Stylist application with integrated CARS; Evaluation results for the proposed RS solution |
| Requirements | recommender systems, machine learning, deep learning, programming, Human-AI interaction |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | recommender system, context-aware recommendation, HCI, fashion, clothing, deep learning, machine learning, user interface design, user satisfaction |
| Interview Required | No |

### SH-6: Machine learning detection and prediction in mental health

| Description | The growing global population and awareness about mental health has increased the demand for mental health care. There is growing uptake of machine learning methods in this area, as these approaches offer faster screening on a broader scale that can assist mental health professional in diagnosis and treatment. Nevertheless, there are still multiple open questions where applications of machine learning can offer promising outcomes, including e.g.: identifying causes and risk factor; earlier detection; more accurate prediction in outcomes with overlapping symptoms; more relevant support and tailored treatment.<br><br>This project will focus on one or a combination of the following mental health challenges/outcomes: loneliness, attention deficit hyperactivity disorder (ADHD), borderline personality disorder (BPD), post-traumatic stress disorder (PTSD). The target population are, but not limited to: university students, romantic partners, elderly, adults (ADHD).<br><br><br>The project will entail:<br>searching for relevant public datasets (or publicly available data, e.g. social media)<br>data preparation and cleaning<br>reviewing, identifying and applying suitable predictive machine learning (and/or deep learning) methods AND/OR machine learning methods for detection of the aimed at mental health outcomes (e.g., from text, images, audio)<br>evaluating and comparing ML model performance on a number of relevant metrics (applied in prior studies and beyond)<br>detecting and/or predicting the mental health outcome based on available factors/features in a dataset<br>identify the significant factors that affect the studied mental health outcome (e.g. loneliness).<br><br><br><br>Some data sources to start with:<br>https://ukdataservice.ac.uk/<br>https://data.humdata.org/dataset<br>https://data.world/datasets/mental-health<br><br><br><br>BPD:<br>https://www.nature.com/articles/s41398-018-0334-0<br>https://www.frontiersin.org/articles/10.3389/fpsyt.2022.804440/full<br>https://doi.org/10.1016/j.jad.2021.03.082<br>https://ieeexplore.ieee.org/abstract/document/9447620<br>https://ieeexplore.ieee.org/abstract/document/10072886<br><br><br>Loneliness:<br>https://doi.org/10.1017/S0033291719003933<br>https://mhealth.jmir.org/2019/7/e13209<br>https://www.mdpi.com/2227-9032/11/10/1485<br>http://dx.doi.org/10.1136/bmjopen-2019-030355<br>https://www.sciencedirect.com/science/article/abs/pii/B9780323911962000119<br><br>ADHD:<br>https://www.nature.com/articles/tp2015221<br>https://www.medrxiv.org/content/medrxiv/early/2020/10/23/2020.10.20.20216390.full.pdf<br>https://link.springer.com/chapter/10.1007/978-981-15-2063-1_3<br>https://link.springer.com/article/10.1186/1753-4631-4-S1-S1<br><br>PTSD:<br><br>https://www.sciencedirect.com/science/article/abs/pii/S0165178122001032<br>https://mental.jmir.org/2022/4/e21111/<br>https://link.springer.com/article/10.1186/s12888-020-02933-1<br><br> |
| - | - |
| Reference URLs | https://doi.org/10.1017/S0033291719000151 |
| Anticipated Outcomes | The project should deliver:<br>a best performing machine learning model that predicts and/or detects the aimed at mental health outcome(s)<br>explanations/guidelines/rules/visualizations indicating key factors/predictors that can assist mental health professionals in detection or treatment<br>Project report<br> |
| Requirements | machine learning, programming in Python, data preparation and analysis |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | machine learning, predictive models, text analysis, mental health |
| Interview Required | No |

### BIM-1: Real-time automatic surveillance photosphere

| Description | We already know how to take a photosphere with a 360 camera or even our phones. We have seen them in Street View or in AR apps. But, what if we need to take a photosphere using a security camera? Or if we need to implement it in real time? Or what if we need to do it with a thermal camera? <br><br>In this project, we will look into creating photo spheres from a PTZ (pan-tilt-zoom) security camera that can be controlled by a manual operator or run using a predefined tour. The camera has two modalities: visible (RGB) and thermal. Ideally, a real-time photosphere will be created for each modality, which in the background is saved in a plain-image format. <br><br>Overall, this project involves:<br> - Image matching and Homography Estimation<br> - Image merging<br> - Camera Calibration<br> - Thermal Image Processing<br> - Automatic camera control using the ONVIF standard<br><br>This project is to be developed using Python and OpenCV. |
| - | - |
| Reference URLs | R. Szeliski. Computer Vision: Algorithms and Applications. Springer, 2010. Chapters: 4 (Feature detection and matching) and 9 (Image stitching). https://www.cs.ccu.edu.tw/~damon/tmp/SzeliskiBook_20100903_draft.pdf<br><br>Brown, M., & Lowe, D. G. (2007). Automatic panoramic image stitching using invariant features. International journal of computer vision, 74, 59-73. http://matthewalunbrown.com/papers/ijcv2007.pdf<br><br>https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect7.pdf |
| Anticipated Outcomes | A system that will run a program to form a high-quality spheric mosaic (photosphere) from a set of sequential images. This system should be able to both run from a live-streaming PTZ camera or from a set of input images taken from that camera. |
| Requirements | Computer Vision (COMP3527) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Image stitching, mosaicking, photosphere, |
| Interview Required | No |

### II-1: Thomson problem

| Description | The Thomson problem asks to find a spherical configuration of N points, representing electrons, with the minimum electrostatic energy. The electrostatic energy is just the sum of the inverse distances, taken over all possible pairs of points the between them.<br>Despite the elementary description of the Thomson problem, mathematical proofs that, for a given number of electrons, a certain configuration has minimum energy are very hard to find and as a result, computational methods based on simulations of the forces between the electrons have been used extensively. |
| - | - |
| Reference URLs | https://en.wikipedia.org/wiki/Thomson_problem |
| Anticipated Outcomes | Implementation and evaluation of existing iterative algorithms for simulations of the Thomson problem.<br>Possibility for further development and improvement of them. |
| Requirements | None. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Thomson problem, simulation, optimisation |
| Interview Required | No |

### II-2: Cryptocurrencies - bitcoin

| Description | A fundamental difference between money in the form of physical tokens, such as coins or banknotes, and any electronic payment system, is that the latter requires a form of book keeping to ensure the validity of each transaction, i.e. that you really own the money you spend. The most commonly used electronic payment systems are based on centralised book keeping done by the banks. Cryptocurrencies, such as bitcoin, employ peer to peer book keeping, using public key cryptography to protect the privacy of the transaction. |
| - | - |
| Reference URLs | https://dl.acm.org/doi/10.1145/228503.228512 |
| Anticipated Outcomes | Implementation of a cryptocurrency, based on one of the open source tools for developing blockchain applications. |
| Requirements | None. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Cryptocurrencies, bitcoin |
| Interview Required | No |

### II-3: Liveness tests for face recognition

| Description | Face recognition is a popular choice in the development of user verification applications, such as automatic login to a laptop or a mobile phone. One shortcoming of user verification systems based on such technology is their vulnerability against simple identity spoofing methods, such as gaining access to the system by placing in front of the camera a printed photo of the real user. Liveness tests are algorithms defending face recognition based security systems against such attacks by analysing the input images and distinguishing between those coming from real live faces and those coming from photographs. |
| - | - |
| Reference URLs | https://www.liveness.com |
| Anticipated Outcomes | Implementation of an existing liveness test algorithm.<br>Possibility for further development and improvement of the implemented algorithm. |
| Requirements | None. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Face recognition, liveness test, user verification |
| Interview Required | No |

### II-4: Watermarking 3D printed objects

| Description | The practice of embedding information on physical objects can be traced back to the beginnings of civilization; from the painted signatures and the engraved monograms used to authenticate handmade artifacts, to the unique serial numbers embossed on mass manufactured products. Currently, a very popular practice for embedding information in a physical environment uses QR-codes, usually in the form of a label, or a sticker, placed near or on top of an object of interest. This is a non-secure practice, since such labels can be easily removed, can be replaced by other labels carrying malicious information, or such a label can be maliciously placed in an area where there should not be one.<br>This project will use 3D printing to generate QR-code style watermarks that are an inseparable part of the physical object, and develop computer vision algorithms for reading the information they carry. |
| - | - |
| Reference URLs | https://arxiv.org/abs/2006.08819.pdf |
| Anticipated Outcomes | At a first stage, the student will use existing, flat, 3D printed objects, with QR-code style watermarks on them, and implement computer vision algorithms for extracting the watermarks.<br>At a second stage the project will develop methods for embedding similar watermarks on cylindrical or spherical objects, will 3D print the watermarked objects, and modify appropriately the computer vision algorithms for watermark extraction. |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | 3D printing, watermarking, computer vision |
| Interview Required | No |

### II-5: A blockchain based system for the secure handling of research data

| Description | According to the definition of the Office of Research Integrity of the US Department of Health and Human Services, data handling is the process of ensuring that research data is stored, archived or disposed off in a safe and secure manner during and after the conclusion of a research project.<br>This project will develop a system based on blockchain technology and smart contracts for the secure handling of research data. The objective of the project is to ensure data integrity, and address concerns related to confidentiality and ethical data usage, in ways that go beyond the most common current practice of implementing very tight data-access restrictions. |
| - | - |
| Reference URLs | https://ori.hhs.gov/education/products/n_illinois_u/datamanagement/dhtopic.html<br>https://www.ibm.com/uk-en/topics/what-is-blockchain |
| Anticipated Outcomes | A blockchain based system, using smart contract written in Solidity, for handling the data of a research project. |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Blockchain, smart contracts, Solidity, data handling, ethical data usage |
| Interview Required | No |

### AJ-1: Smart energy management in homes, industries or commercial sectors

| Description | Project aim (broad):<br>The project would aim to revamp the way energy is used in smart homes, industries or commercial sectors based on the known/forecasted usage patterns.<br><br>Techniques:<br>Effective learning techniques such as data analytics, machine learning, AI, game-theoretic approaches, multi-objective solutions, the combination of these or any other traditional (or out-of-the-box) approaches.<br><br>Desirable:<br>- Experience with programming languages or tools such as Python, R, MATLAB, Java.<br>- Any prior experience of working in the specified (or chosen) scheme is a plus. |
| - | - |
| Reference URLs | [1] A. Jindal, N. Kumar, and J. J. P. C. Rodrigues, \"A Heuristic-based Smart HVAC Energy Management Scheme for University Buildings,\'\' IEEE Transactions on Industrial Informatics, vol. 14, no. 11, pp. 5074-5086, 2018.<br>[2] A. Jindal, M. Singh, and N. Kumar, \"Consumption-Aware Data Analytical Demand Response Scheme for Peak Load Reduction in Smart Grid,\'\' IEEE Transactions on Industrial Electronics,vol. 65, no. 11, pp. 8993-9004, 2018. |
| Anticipated Outcomes | Anticipated outcomes include:<br>- Energy bill reduction for the consumer<br>- Energy optimisation for the utility provider<br>- Demand response management<br>- Load balancing at grid/distribution level<br>- Self-sustainable consumers/buildings |
| Requirements | There are no pre-requirements, however, one should have interest in the project and the willingness to learn the techniques. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Smart cities; smart energy management |
| Interview Required | No |

### AJ-2: Machine learning applications in Internet of things (IoT)

| Description | Project aim (broad):<br>The project would aim to use the machine learning/AI/data analytics to solve various issues pertaining to Internet of things (IoT) ecosystem ranging from (but not limited to) energy harvesting to effective resource (computation/communication) management. <br><br>Techniques:<br>- Combination of data analytics, machine learning, AI with the game-theoretic approaches, multi-objective solutions, or any other traditional (or out-of-the-box) approaches.<br>- Use of edge/fog/cloud computing paradigms in the above-mentioned scenario.<br><br>Desirable:<br>- Experience with programming languages or tools such as Python, R, MATLAB, Java.<br>- Any prior experience of working in the specified (or chosen) scheme is a plus.<br>- Use of edge/fog/cloud simulators (if using these). |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | Anticipated outcomes include:<br>- Machine learning/AI/data analytics models<br>- Internet of things (IoT) framework <br>- Energy harvesting/effective resource (computation/communication) utilisation. |
| Requirements | There are no pre-requirements, however, one should have interest in the project and the willingness to learn the techniques. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | machine learning; internet of things |
| Interview Required | No |

### AJ-3: Data analytics for improving healthcare systems

| Description | Project aim (broad):<br>The project would aim to leverage (or refine) various phases of the data analytics process such as data pre-processing, feature selection and feature modelling by incorporating (say) reinforcement learning, Bayesian networks or other ensemble schemes to improve the overall (prediction and accuracy) of machine learning models for providing healthcare-related services.<br> <br>Techniques:<br>- Reinforcement learning, Bayesian networks, Neural Network or other ensemble schemes.<br>- Techniques used in various phases such as PCA/SVM/RF/Regression.<br><br>Desirable:<br>- Experience with programming languages or tools such as Python, R, MATLAB, Java.<br>- Any prior experience of working in the specified (or chosen) scheme is a plus. |
| - | - |
| Reference URLs | [1] A. Jindal, A. Dua, N. Kumar, A. K. Das, A. V. Vasilakos, and J. J. P. C. Rodrigues, "Providing Healthcare-as-a-Service Using Fuzzy Rule-Based Big Data Analytics in Cloud Computing," IEEE Journal of Biomedical and Health Informatics, vol. 22, no. 5, pp. 1605-1618, 2018. |
| Anticipated Outcomes | - Improved healthcare services<br>- Prediction and prevention of diseases<br>- Improved accuracy of data analytical models |
| Requirements | - There are no pre-requirements, however, one should have interest in the project and the willingness to learn the techniques.<br>- Students are also encouraged to search for different healthcare related datasets on UCI ML repository or other similar datasets. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Healthcare; data analytics |
| Interview Required | No |

### AJ-4: Network resource management for service provisioning in wireless sensor networks

| Description | Project aim (broad):<br>The project would aim to effectively manage the underlying networking resources in traditional or advanced networking paradigms (such as SDNs) for improving the quality of service (QoS) while providing data exchange service in any smart ecosystem using wireless sensor networks.<br><br>Techniques:<br>- Effective learning techniques such as data analytics, machine learning, AI, game-theoretic approaches, multi-objective solutions, the combination of these or any other traditional (or out-of-the-box) approaches.<br>- Algorithms such as ACO/kNN/heuristics or similar.<br>- Advanced networking schemes such as control/data plane management, flow control management, etc. for software-defined networking. |
| - | - |
| Reference URLs | [1] A. Jindal, G. S. Aujla, N. Kumar, R. Chaudhary, M. S. Obaidat, and I. You, "SeDaTiVe: SDN-enabled Deep Learning Architecture for Network Traffic Control in Vehicular Cyber-Physical Systems," IEEE Network, vol. 32, no. 6, pp. 66-73, 2018. |
| Anticipated Outcomes | Anticipate outcomes inculde:<br>- Models for managing networking resources<br>- Use of advanced networking paradigms in sensor/IoT networks<br>- Improved quality of service of the network |
| Requirements | Pre-requisites:<br>- Prior knowledge of concepts involved in networking and communication.<br>- Interest in the project and the willingness to learn the techniques and tools.<br><br>Desirable:<br>- Experience with programming languages or tools such as Python, R, MATLAB, Java.<br>- Working knowledge of tools like Mininet/Omnet/NS2/NS3/SUMO/etc. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | IoT; wireless networks; resource management; network control |
| Interview Required | No |

### AJ-5: Cyber-security applications in Internet of things (IoT)

| Description | Project aim (broad):<br>The project would aim to use (and complement) the cyber-security techniques such as SSL/TLS, Blockchain, PKI (public key infrastructure) or any other security scheme for enhancing the (device level) security in IoT devices with or without the use of the edge-cloud paradigms.<br><br>Techniques:<br>SSL/TLS, Blockchain, PKI (public key infrastructure) or any other (variant of) traditional security scheme. |
| - | - |
| Reference URLs | [1] G. S Aujla and A. Jindal, "A Decoupled Blockchain Approach for Edge-envisioned IoT-based Healthcare Monitoring," IEEE Journal on Selected Areas in Communications, vol. 39, no. 2, pp. 491-499,  2021.<br>[2] A. Jindal, A. K. Marnerides, A. Scott, and D. Hutchison, "Identifying Security Challenges in Renewable Energy Systems: A Wind Turbine Case Study," in 10th ACM International Conference on Future Energy Systems (ACM e-Energy), Phoenix, AZ, USA, June 2019, pp. 370-372.<br>[3] A. Dua, R. Chaudhary, G. S. Aujla, A. Jindal, N. Kumar, and J. J.P.C. Rodrigues, "LEASE: Lattice and ECC-based Authentication and Integrity Verification Scheme in E-Healthcare," in IEEE Global Communications Conference (GLOBECOM), Abu Dhabi, UAE, Dec. 2018, pp. 1-6. |
| Anticipated Outcomes | Anticipated outcomes include:<br>- Complement existing cyber-security techniques <br>- Improved security<br>- Privacy preservation<br>- New cybersecurity models |
| Requirements | Pre-requisites:<br>- Experience with programming languages or tools such as Python, R, MATLAB, Java. <br>- Fundamental knowledge of data communication and computer security.<br>- Willingness to learn the tools as mentioned in the desirable.<br><br>Desirable:<br>- Working knowledge of security protocol validation tools such as AVISPA/Scyther/etc.<br>- Working knowledge of hyperledger(s) (for blockchain-related projects). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | cybersecurity; IoT; machine learning |
| Interview Required | No |

### SK-1: A comparative study of the effect of various data augmentation techniques on the performance of CNN-based image classification

| Description | Deep learning approaches based on convolutional neural networks (CNN) are currently among the state-of-the-art methods for image classification. However, such approaches rely on extremely large annotated datasets in order to efficiently train the developed classification models. In some cases, such large datasets are not available, and we have to rely on data augmentation techniques in order to artificially increase the size of the training datasets. This project will focus on examining various state-of-the-art data augmentation approaches and compare their performance using various state-of-the-art CNN architectures on various image datasets. |
| - | - |
| Reference URLs | https://doi.org/10.1186/s40537-019-0197-0 |
| Anticipated Outcomes | A comprehensive report on the performance and characteristics of various data augmentation techniques based on an experimental evaluation using various state-of-the-art CNN architectures on various image datasets. |
| Requirements | Interest in computer vision and image processing, basic knowledge of machine learning, knowledge of the Python programming language |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | Computer vision, image processing, machine learning, CNNs |
| Interview Required | No |

### SK-2: Smart white cane for vision impaired and blind people

| Description | A white cane is a device used by many people who are blind or visually impaired, and it primarily allows its user to scan their surroundings for obstacles or orientation marks. In this project, a smart white cane will be prototyped by attaching various sensors (e.g. camera, GPS, lidar, etc), as well as input/output devices (e.g. audio, touch sensors, vibration, etc.), in order to enhance the capability of the user to navigate everyday surroundings. Devices will be integrated using a microcontroller or microcomputer solution, and the required software will be developed. |
| - | - |
| Reference URLs | <br>https://doi.org/10.1080/17483107.2019.1615999<br>https://doi.org/10.1109/GHTC.2017.8239225<br>https://doi.org/10.1109/ICCAR.2019.8813508<br>https://en.wikipedia.org/wiki/White_cane<br>https://wewalk.io/en/<br> |
| Anticipated Outcomes | <br>A working prototype smart white cane, equipped with various sensors and input/output devices for monitoring the location of the user, detecting surrounding objects, providing alerts for potential obstacles or other dangers, and helping the user navigate in everyday surroundings.<br>The required software for accessing the sensors' data, processing them, and providing feedback to the user based on them.<br> |
| Requirements | Basic knowledge of hardware, electronics, machine learning. Knowledge of Python or equivalent programming language. Interest in prototyping platforms like Arduino and Raspberry Pi. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | IoT, handicapped aids, sensors, machine learning |
| Interview Required | No |

### SK-3: Using chest X-ray images and deep learning for automated detection of pathologies

| Description | In this project, chest x-rays associated with healthy individuals and other pathological conditions will be used to train machine learning models for the task of detecting pathologies. |
| - | - |
| Reference URLs | <br>https://doi.org/10.1109/ACCESS.2020.3010287<br>https://doi.org/10.1016/j.media.2020.101794<br>https://dx.doi.org/10.1016%2Fj.compbiomed.2020.103792<br>https://www.kaggle.com/datasets/nih-chest-xrays/data<br> |
| Anticipated Outcomes | <br>Trained machine learning models for automated diagnosis using chest x-rays.<br>A comparative evaluation of the designed models against the state of the art.<br>A piece of software for automated diagnosis using chest x-rays.<br> |
| Requirements | Interest in computer vision and image processing, basic knowledge of machine learning, knowledge of the Python programming language |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Computer vision, image processing, machine learning, deep learning |
| Interview Required | No |

### SK-4: Electroencephalography (EEG)-based biometrics

| Description | Various recent research works have focused on the use of electroencephalography (EEG) signals in the field of biometrics. EEG signals, i.e., the recording of the electrical activity of the brain, present some major advantages when compared to other biometrics modalities: they are resilient to physical injuries, extremely hard to reproduce, and cannot be furtively captured at a distance. In this project, you are going to use a publicly available dataset for EEG-based biometrics and develop machine learning models for subject identification or authentication based on their EEG signals. |
| - | - |
| Reference URLs | <br>https://doi.org/10.1109/JIOT.2021.3061727<br>https://doi.org/10.5281/zenodo.4309472<br>https://doi.org/10.1109/LSP.2016.2516043<br>https://doi.org/10.1109/LSP.2019.2906826<br> |
| Anticipated Outcomes | <br>Trained machine learning models for EEG-based subject identification or authentication.<br>A comparative evaluation of the designed models against the state of the art.<br>A piece of software to demonstrate a prototype EEG-based biometrics system.<br> |
| Requirements | Interest in signal processing and bioinformatics, basic knowledge of machine learning, knowledge of the Python programming language |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | signal processing, bioinformatics, electroencephalography, EEG, machine learning, deep learning |
| Interview Required | No |

### SK-5: Single camera-based UAV-to-UAV detection and tracking

| Description | Unmanned Aerial Vehicle (UAV) technology is being increasingly used in a wide variety of applications ranging from remote sensing to delivery and security. As the number of UAVs increases, there is a growing need for UAV-to-UAV detection and tracking systems for both collision avoidance and coordination. In this project you will develop an algorithm that is capable of robustly detecting and tracking target UAVs from cameras mounted on a flying UAV platform. |
| - | - |
| Reference URLs | <br>https://doi.org/10.1109/TETC.2021.3104555<br>https://engineering.purdue.edu/~bouman/UAV_Dataset/<br>https://doi.org/10.1109/IROS.2016.7759733<br>https://doi.org/10.2352/ISSN.2470-1173.2018.10.IMAWM-466<br> |
| Anticipated Outcomes | <br>Algorithms for detection and tracking of target UAVs from cameras mounted on flying UAV.<br>A comparative evaluation of the designed algorithms against the state of the art.<br>A piece of software to demonstrate the developed detection and tracking algorithms.<br> |
| Requirements | Interest in image and video processing, basic knowledge of machine learning, knowledge of the Python programming language |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | image processing, video processing, Unmanned Aerial Vehicles, UAV, machine learning, deep learning |
| Interview Required | No |

### GK-1: Automatic Projector Calibration

| Description | Setting up a projector takes time, as geometric distortions often appear and/or the image quality is degraded due to lighting conditions. Moving the projector around to correct for geometric distortions and/or fiddling with its geometry/brightness/contrast controls can be very laborious. Ideally, the user would like to aim the projector at the projection surface, define the desired display corners, and then an automatic method should align the display to the surface. In this project, a camera-projector pair and computer vision will be used to calibrate the projector automatically by appropriately pre-distorting the image content to account for perspective projection, lighting conditions and the material properties of the projection surface. |
| - | - |
| Reference URLs | https://ieeexplore.ieee.org/abstract/document/6375029<br>https://ieeexplore.ieee.org/abstract/document/1565423 |
| Anticipated Outcomes | A piece of software that can pre-correct images/slides for arbitrary projection surface geometries and environmental lighting conditions using a projector-camera pair. |
| Requirements | Interest in Computer Vision and Computer Graphics. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Camera/Projector calibration, Homographies |
| Interview Required | No |

### GK-2: Wearable Haptics

| Description | Haptic feedback for VR headsets is currently unavailable for commercial headsets. In this project we will develop a device that induces haptic feedback, i.e., the sense of force/touch and temperature among others. The device will be based on a custom-designed 3D printed frame with embedded Peltier elements to induce a thermal sensation and motors/voicecoils for vibrations. |
| - | - |
| Reference URLs | https://dl.acm.org/doi/10.1145/3275476.3275488<br>https://ieeexplore.ieee.org/abstract/document/7463168 |
| Anticipated Outcomes | A piece of hardware and an accompanying demo application in Unity 3D. |
| Requirements | An interest in Computer Graphics and Human Computer Interaction. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | Human-centred computing, Haptic devices |
| Interview Required | No |

### GK-3: Enhancing Dark Video Features via Inverse Tone Mapping

| Description | Inverse tone mapping operators strive to re-generate a High Dynamic Range (HDR) image from a single Low Dynamic Range (LDR) input image. These operators intelligently boost luminance in the bright parts of the scene in an attempt to "stretch" the LDR image luminance range for it to match to the output luminance range of a HDR display. However, these operators do not perform equally well in the -also suppressed- darker regions of LDR images, where block artefacts often appear and camera noise gets significantly amplified. A "dark-area" enhancement function would optimally suppress both noise and quantisation artefacts while boosting those dark features in a temporally coherent way. The clipped luminance values in the lower part of the luminance range could be estimated based on notions from image statistics. The theoretical framework could also get inspiration from Laplacian Pyramids and Bilateral Filtering for image processing, or Median Cuts for dark area estimation. |
| - | - |
| Reference URLs | https://forums.cs.tau.ac.il/~hezy/Vision%20Seminar/pyramid83.pdf<br>https://dl.acm.org/doi/10.1145/1186954.1187029<br>https://ieeexplore.ieee.org/abstract/document/710815 |
| Anticipated Outcomes | In this project a theoretical foundation for an inverse tone mapping operator will be devised that enhances dark scene regions in legacy LDR video sequences. The operator will generate a plausible HDR radiance map from a single-exposure video frame and then boost the luminance levels optimally in dark regions in order to improve perceived contrast and the appearance of details. |
| Requirements | An interest in Computer Graphics, Image Processing and Computer Vision. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Computer Graphics, Image Processing, Tone Mapping |
| Interview Required | No |

### GK-4: A 3D Rendering Pipeline on FPGA

| Description | FPGAs have gone from being simple glue logic chips to actually replacing custom application-specific integrated circuits (ASICs) and processors for signal processing and real-time applications. FPGAs are becoming more useful in areas where ASICs were used before. 3D graphics rendering is one such area, where research is underway as to how FPGAs can help to improve the performance of graphics processing units with less energy consumption. In this project an FPGA-based Graphic Processor for low power applications will be developed. |
| - | - |
| Reference URLs | http://advances.utc.sk/index.php/AEEE/article/view/1125 |
| Anticipated Outcomes | An FPGA-based Graphic Processor for low power applications will be developed on Vidor 4000. |
| Requirements | An interest in Computer Graphics and hardware. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | 3D Graphics Pipeline, FPGA |
| Interview Required | No |

### GK-5: Psychophysics research using PsychoPy

| Description | In this project, PsychoPy will be used to build an experimental platform for psychophysical experiments related to Vision Science. Stimulus presentation and response collection and data analysis such as psychometric function fitting will be supported using this framework. |
| - | - |
| Reference URLs | https://www.sciencedirect.com/science/article/pii/S0165027006005772 |
| Anticipated Outcomes | A piece of software that can be used to run a variety of experiments related to Vision Science. |
| Requirements | An interest in Human Computer Interaction. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Psychophysics, Human Computer Interaction |
| Interview Required | No |

### AK-1: Backgammon with variable luck

| Description | Backgammon is a game of skill and luck. This project is about developing and implementing a computer backgammon player whose luck can be adjusted to match the skill of a human opponent. While there are many successful AI-based backgammon players (the best ones can even beat human world champions), a good  implementation of variable luck remains a challenge. |
| - | - |
| Reference URLs | https://www.human-competitive.org/sites/default/files/sipper-gp-gammon-final.pdf<br>https://skatgame.net/mburo/ps/STAR-B.pdf |
| Anticipated Outcomes | Implementation of a computer backgammon player with adjustable luck |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | AI, games, backgammon |
| Interview Required | No |

### AK-2: Research tool for AI search in graphs

| Description | Graph homomorphisms generalise graph colourings, and there are many open problems about the complexity of graph colouring and graph homomorphisms. The complexity usually depends on the mathematical structure of problems. Understanding this structure can be quite hard, but it often depends on polymorphisms, i.e. edge-preserving functions. Thus, research into this topic can be guided by a computational tool that detects special polymorphisms, as this can provide intuition about the structure (or sometimes even completely resolve complexity questions). The difficulty is that finding such polymorphisms involves search in spaces that grow very fast. For example, one might look for a 6-ary edge-preserving function, with specific propertes, from a graph with 7 vertices to a graph with 13 vertices, and the number of such possible functions is too large for a naive search. Thus, a highly optimised software tool (in particular, utilising the inherent symmetry of the search space) is needed to cope with such search spaces. Such a tool can be built, for example, on top of a SAT solver (or another AI search engine). |
| - | - |
| Reference URLs | http://www.karlin.mff.cuni.cz/~stanovsk/math/gpoly.htm |
| Anticipated Outcomes | Implementation of a flexible and usable software tool to search for special graph polymorphisms. |
| Requirements | Interest in AI, strong maths background |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Graph theory, algorithms, AI search, automated reasoning |
| Interview Required | No |

### AK-3: Steganography

| Description | The goal of steganography is to embed a digital file into another digital file, such as a photo, an audio or a video file, or a 3D model, in ways that keep the existence of the embedded message hidden from third parties. Unlike cryptography, where a secret message can be conspicuous and yet protected by encryption, steganography protects not only the message, but also the sender and the receiver by concealing the very existence of the message. |
| - | - |
| Reference URLs | http://library.dur.ac.uk/record=b2846691~S1<br>https://www.sciencedirect.com/science/article/pii/S0165168409003648?via%3Dihub |
| Anticipated Outcomes | Implementation and evaluation of existing steganographic algorithms. Possibility for further development and improvement of them. |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Steganography, Watermarking, Steganalysis |
| Interview Required | No |

### AK-4: Matching under preferences

| Description | Matching theory studies how agents and/or objects from different sets can be matched with each other while taking agents\\\' preferences into account. This theory has been successfully applied to many real-world problems such as matching students to universities, doctors to hospitals, kidney transplant patients to donors, and tenants to houses. Many important variations of the matching problem are NP-hard. Hence appropriate algorithmic solutions (e.g. based on integer programming or on SAT solving) for them need to be explored. This project is about exploration and comparison of different algorithmic approaches to (hard) matching problems. |
| - | - |
| Reference URLs | http://www.unil.ch/de/files/live/sites/de/files/working-papers/14.07.pdf<br>http://eprints.gla.ac.uk/121248/7/121248.pdf |
| Anticipated Outcomes | Implementation and comparison of the performance of algorithmic approaches to variations of the Hospitals/Residents matching problems. |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | Matching problems, algorithms, heuristics |
| Interview Required | No |

### AK-5: Solving edge-matching problems with SAT solvers

| Description | Edge-matching problems are popular puzzles, that appeared first in the 1890\\\'s. Given a set of pieces and a grid, the goal is to place the pieces on the grid such that the edges of the connected pieces match. Such problems are known to be computationally hard. Famously, a prize of 2 million US dollars was offered in 2007 for solving the Eternity 2 edge-matching puzzle with 256 pieces - despite many computational attempts, the prize was left unclaimed. It is well-known that the way a problem is encoded into SAT may strongly affect the performance of SAT solvers on this problem. This project is about creatively using SAT solvers to solve various edge-matching problems. |
| - | - |
| Reference URLs | https://www.cs.utexas.edu/~marijn/publications/eternity.pdf |
| Anticipated Outcomes | Solutions of various edge-matching problems via encodings into SAT. |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | SAT solving, algorithms, heuristics |
| Interview Required | No |

### AK-6: Integer factorisation algorithms

| Description | A lot of computer security relies on the perceived computational hardness of the tasks such as integer factorisation. Yet there is little theoretical evidence (that is, no proof) that these tasks are computationally hard. Hence it is important to try to come up with algorithms for these problems (which are based on number theory, naturally). This project will investigate and evaluate the state-of-the-art in algorithms for one of these problems, and implement a selection of such algorithms. |
| - | - |
| Reference URLs | https://library.dur.ac.uk/record=b2906346~S1 |
| Anticipated Outcomes | Implementation of a selection of integer factorisation or discrete logarithm algorithms, evaluation of the state-of-art. |
| Requirements | Interest in cryptography, strong maths background |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Integer factorisation, algorithms, cryptography |
| Interview Required | No |

### FL-1: Developing a Deep Learning Architecture for Accurate Human-Object Interaction Recognition

| Description | Background:<br>Recognising human-object interaction is crucial for many applications, such as security surveillance and game interaction. Deep learning techniques, such as CNN, RNN, and LSTM, have demonstrated potential for recognising human motion and modelling the temporal dependencies of the interaction. However, accurately recognising human-object interaction is still challenging, particularly due to complex human-object relationships and occlusion issues.<br>Objective:<br>The objective of this project is to develop a deep learning architecture for accurate human-object interaction recognition. The proposed architecture will be designed to handle the complex human-object relationships and occlusion problems that occur in real-world scenarios. Instead of relying on specific deep learning techniques, such as CNN, RNN, and LSTM, the architecture will be designed to leverage appropriate techniques to recognise human motion and model the temporal dependencies of the interaction.<br>Methodology:<br>This project will follow the following methodology:<br><br>Literature review: A comprehensive review of the latest research in human-object interaction recognition using deep learning techniques will be conducted.<br>Data collection: Suitable datasets for human-object interaction recognition will be identified and collected.<br>Data preprocessing: The collected data will be preprocessed to remove noise, normalise data, and augment the data to create more training samples.<br>Architecture development: The deep learning architecture for human-object interaction recognition will be developed. The architecture will leverage appropriate deep learning techniques to recognise human motion and model the temporal dependencies of the interaction. The architecture will be designed to handle the complex human-object relationships and occlusion problems that occur in real-world scenarios.<br>Performance analysis: The proposed architecture will be evaluated on the collected dataset and compared against the state-of-the-art methods. Various performance metrics, such as accuracy, precision, recall, and F1-score, will be used to determine the applicability of the proposed architecture.<br><br>Conclusion:<br>This project aims to develop a deep learning architecture for accurate human-object interaction recognition. By leveraging appropriate deep learning techniques and designing an architecture to handle complex scenarios, the proposed architecture is expected to achieve higher accuracy. The project's outcomes could contribute to the development of more advanced artificial intelligence systems and facilitate the widespread adoption of human-object interaction recognition in various domains. |
| - | - |
| Reference URLs | Gkioxari, G., Girshick, R., and Malik, J. (2018). Detecting and recognizing human-object interactions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 8359-8367).<br>https://openaccess.thecvf.com/content_cvpr_2018/papers/Gkioxari_Detecting_and_Recognizing_CVPR_2018_paper.pdf<br>Li, Y., Li, Z., Song, Y., He, Y., & Ye, Q. (2020). Detailed 2D-3D Joint Representation for Human-Object Interaction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 8416-8425).<br>https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Detailed_2D-3D_Joint_Representation_for_Human-Object_Interaction_CVPR_2020_paper.pdf |
| Anticipated Outcomes | The expected outcome of this project is a deep learning architecture that can accurately recognise human-object interaction, particularly in complex scenarios. The architecture's performance will be compared against the state-of-the-art methods, and its strengths and limitations will be analysed. The proposed architecture could be applied in various real-world applications, such as security surveillance and game interaction, and it could contribute to the development of more advanced artificial intelligence systems. |
| Requirements | Programming in pyTorch, image processing, and computer vision |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Human activity analysis, deep learning, computer vision |
| Interview Required | Yes |

### FL-2: Real-Time Hand Gesture Recognition in Cluttered Environments using Deep Learning

| Description | Objective:<br>The objective of this project is to develop a deep learning network that can predict and recognize hand gestures in real-time, even in cluttered and complex environments. The system will extract hand features and analyze the hand movements to classify different gestures with high accuracy.<br><br>Background:<br>Hand gestures are widely used in various applications, such as virtual reality, gaming, sign language recognition, and human-computer interaction. However, recognizing hand gestures in real-life environments is a challenging task due to variations in lighting conditions, background clutter, and fast-changing hand movements. Traditional computer vision approaches have limitations in dealing with such complexities. Deep learning techniques have shown promising results in gesture recognition tasks, but they require large annotated datasets and computationally intensive models.<br><br>Methodology:<br>The proposed project will develop a deep learning network architecture to extract hand features and classify different gestures. The system will be trained on a large annotated dataset of hand gestures in cluttered environments. The system will be evaluated on a video dataset, which includes different backgrounds, lighting conditions, and clutter.<br><br>Project Evaluation:<br>To evaluate the performance of the proposed real-time hand gesture recognition system, the following metrics will be used:<br><br>Classification Accuracy: The classification accuracy will be calculated as the percentage of correctly classified hand gestures in the test dataset.<br>Inference Time: The time taken by the system to recognize and classify a hand gesture in real-time will be measured.<br>Robustness: The system will be tested under different lighting conditions, backgrounds, and cluttered environments to evaluate its robustness.<br>Comparison with State-of-the-Art: The performance of the proposed system will be compared with the state-of-the-art hand gesture recognition systems in terms of accuracy, inference time, and robustness.<br>User Feedback: The system will be tested by a group of users to collect feedback on the usability, ease of use, and accuracy of the system. |
| - | - |
| Reference URLs | https://paperswithcode.com/task/hand-gesture-recognition |
| Anticipated Outcomes | The proposed system is expected to achieve high accuracy in real-time hand gesture recognition in cluttered environments. The system can be used in various applications such as gaming and sign language recognition. The project will contribute to the development of robust and efficient hand gesture recognition systems using deep learning. |
| Requirements | Programming in Pytorch, deep learning, computer vision. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Real-time hand gesture recognition, Deep learning, Computer vision. |
| Interview Required | Yes |

### RL-1: Music Generation and/or Analysis

| Description | This theme is about using methods from artificial intelligence (AI) and machine learning (ML) to compose and/or analyse music. This is a relatively broad theme that can be approached in different ways. A specific project should typically pick a task from (a), a representation / level of description from (b) and a musical feature / dimension from (c).<br>(a) generation vs analysis: In music generation, the focus is on producing music of a particular style (e.g. Baroque piano music or Trip-Hop beats) or in a particular mood (happy/sad/energetic/...). It does not really matter if it was "composed in the right way" as long as the output sounds as desired. But it turns out to be quite difficult to generate interesting music without incorporating at least a little knowledge about how music works (see e.g. OpenAI Jukebox [1], Music Transformers [2], or Perceivers [3] for the current state of the art). Music analysis focuses on understanding and explaining the inner workings of music. One might e.g. want to transcribe a score from a given audio recording; identify the harmonies or chords being played in a piece; find the typical melodies, motifs, groove patterns etc; or segment a piece into different sections and sub(sub(...)) sections (see e.g. the Tonal Diffusion Model [4] or Pitch Scapes [5]). Of course, music analysis and generation are closely related but in most cases it makes sense to focus on one of them to keep things tractable.<br>(b) audio/MIDI/score: Music can be stored in different formats or representations, which makes a huge difference for the kind of methods that can be used and how difficult certain tasks are. In a raw audio recording, all the subtle information about timbre (how an instruments sounds) etc are preserved, but musical events, such as "a note" are only implicit and can be very hard to extract. A score, on the other hand, represents music on a more abstract level: all the musical events are explicitly listed (and some additional information, such as tempo or expressive information e.g. staccato/legato etc), which greatly simplifies some tasks. The MIDI representation is in between audio and score, events are explicitly represented (via note-on and note-off events) but time is quasi-continuous and other sub-symbolic information (e.g. velocity or pitch bend) can be represented. Other representations that are commonly used for modelling music are spectrograms (which are close to audio) or piano rolls (close to MIDI).<br>(c) rhythm/melody/harmony: Music is multifaceted, but can be roughly thought of as having three dimensions that are used to create the overall experience. Rhythm is about "structuring time": when does an event/beat/note occur and when not, how salient/loud is the event, how do they group to form larger patterns in time etc. Melody is about sequences of single notes, sounding one after the other – the thing that a human could (at least in principle) sing and what we might typically remember about a song. Harmony is about combining multiple notes to create more complex sounds and how these complex sounds change and evolve over time. Of course, these three dimensions interact strongly (a melody is embedded into a harmonic context and its notes form a specific rhythm) but it often makes sense to focus on one of them. |
| - | - |
| Reference URLs | [1] https://openai.com/blog/jukebox/<br>[2] https://openreview.net/pdf?id=rJe4ShAcF7<br>[3] https://arxiv.org/pdf/2202.07765.pdf<br>[4] https://robert-lieck.com/literature/pdfs/WIY8FM2Q/Lieck_et_al._-_2020_-_The_Tonal_Diffusion_Model_paper_with_appendix.pdf<br>[5] https://robert-lieck.com/literature/pdfs/8K8MJHK9/Lieck_and_Rohrmeier_-_2020_-_Modelling_Hierarchical_Key_Structure_With_Pitch_Sc.pdf |
| Anticipated Outcomes | A project in this theme may use methods from deep learning, reinforcement learning, data science, visualisation etc. to address a specific task. The focus may be more on achieving a certain result (an informative visualisation of the harmonic structure of a piece or a groove or beat that would make you want to dance to) or more on improving the methodology (e.g. how can Transformers be combined with models for musical structure to generate more interesting pieces). If you are interested in doing a project from this theme, please get in touch beforehand to discuss your ideas. |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | music; deep learning; reinforcement learning; artificial intelligence; machine learning; visualisation; data science |
| Interview Required | Yes |

### RL-2: Learning Embeddings by Simulating Communication

| Description | Dimensionality reduction (encoding/mapping data into a low-dimensional space) is a very common and important task for data visualisation and as a pre-processing step in machine learning. There are various algorithms to optimise such an embedding directly (e.g. UMAP, t-SNE, etc.) as well as encoder-decoder architectures in deep learning that learn a mapping function (e.g. variational/denoising/sparse autoencoders).<br>In this project, you will implement a novel embedding method that is different from these existing ones (but most closely related to autoencoders). It makes use of the analogy to human language. When we communicate with each other, we do something very similar to an autoencoder: we embed/encode the world of meanings into the space of words. This can be used to define a novel embedding method by simulating a communication process and training the model to communicate successfully. This has the advantage that it<br><br>makes optimal use of the embedding space (compared to e.g. UMAP or t-SNE)<br>generalises better for small datasets<br>is applicable to complex embedding spaces (e.g. a sphere or torus).<br> |
| - | - |
| Reference URLs | Not required to do the project but maybe interesting:<br><br>UMAP: https://arxiv.org/pdf/1802.03426.pdf<br>t-SNE: https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf<br>variational autoencoder: https://arxiv.org/pdf/1312.6114.pdf<br>topology and emergence of symbols in communication: https://www.sciencedirect.com/science/article/pii/S0010027721002067<br> |
| Anticipated Outcomes |  <br><br>[basic]: an algorithm that will learn to embed an input dataset into a low-dimensional space to produce nice visualisations<br>[advanced]: thorough comparison with other embedding algorithms<br>[genius]: a Python library that allows users to use that algorithm<br> |
| Requirements | deep learning (you have to be proficient in PyTorch to do this project) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | data visualisation; data embedding; autoencoder; deep learning; machine learning; artificial intelligence; communication |
| Interview Required | No |

### RL-3: Interactive Music Visualisation

| Description | Music visualisation is a diverse and fascinating field. This project theme covers different possibilities of how interactive music visualisations can be employed, for instance:<br><br>to enhance the listening experience with visual effects in an artistic way<br>to better understand music by visualising musical features (e.g. chord and key changes, rhythmic patterns, or melodic motifs)<br>to create intuitive user interfaces to analyse, annotate, or compose music.<br><br>If you have specific ideas about what you would like to do, please get in touch and discuss them beforehand. Otherwise, there are many interesting options available using an existing visualisation framework based on the https://plotly.com/python/ library. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | An interactive music visualisation that is artistically appealing, informative, or practically useful. |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | music; virtual reality; visualisation; artificial intelligence; machine learning |
| Interview Required | No |

### RL-4: Meta-learning the kernel structure for Gaussian processes

| Description | Gaussian processes (GPs) are a powerful non-parametric Bayesian approach in machine learning. The essential component that defines a GP is its kernel, which can have parameters that can be trained on the data. Different kernels can be combined to form new kernels with a complex internal structure. However, this structure of a complex kernel cannot be easily learned because the operation of combining multiple kernels is not differentiable. Therefore, currently, the only possibility is to test different structures in an expensive and time-consuming process.<br>The goal of this project is to overcome this problem by applying techniques from structure learning. Instead of testing one structure at a time, the operation of combining multiple kernels is relaxed to a continuous space, thus making it differentiable. The resulting meta-learning approach might provide ground-breaking improvements for the application of Gaussian processes in machine learning. |
| - | - |
| Reference URLs | http://proceedings.mlr.press/v28/duvenaud13.pdf |
| Anticipated Outcomes | <br>[basic]: a proof-of-concept implementation demonstrating that the structure of GP kernels can be learned via gradient descent<br>[advanced]: integrating existing libraries for GPs with standard kernel types and making the approach work with those libraries<br>[genius A]: releasing a package/pull-request to integrate the approach in existing libraries to make it available to all users<br>[genius B]: demonstrating the power of the approach on one or more machine learning benchmarks<br> |
| Requirements | deep learning |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | deep learning; Gaussian processes; non-parametric Bayesian; structure learning; kernel methods; meta-learning; machine learning; artificial intelligence |
| Interview Required | No |

### RL-5: Sonification of High-Dimensional Data

| Description | Data visualisation is a very common technique, but sonification – its acoustic counterpart i.e. transforming data into sound – is less common and has a large unexploited potential for making complex data more accessible.<br>Our ears are just as elaborate and sensitive as our eyes but with different strengths: within milliseconds, our inner ear is capable of performing a complete frequency analysis of a sound, enabling us to not only recognise a familiar voice amongst thousands of strangers but also pick up on the most subtle nuances in its tone that might reveal the speaker's emotions.<br>This project is about leveraging this astonishing capacity of our auditory system to make high-dimensional data – which are very hard to visualise – more intuitively accessible by transforming them into characteristic sounds. The data are first analysed using machine learning methods (e.g. a variational autoencoders or principle component analysis) and then sonified based on the natural overtone series (which also gives musical instruments or human voices their characteristic sound). With cognitive experiments, the effectiveness of the sonification technique will be empirically tested.<br>If you are interested in working on this topic, please get in touch beforehand to briefly discuss the project. If well implemented, this project may lead to a scientific publication. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | A Python library that can sonify data and is well tested and validated |
| Requirements | machine learning / artificial intelligence; ideally: deep learning (PyTorch) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | music; deep learning; machine learning; artificial intelligence; visualisation; data science |
| Interview Required | Yes |

### RL-6: Variational Autoencoders are Reinforcement Learning Agents

| Description | It can be shown that a variational autoencoder (VAE) is mathematically equivalent to a pair of reinforcement learning (RL) agents encoding/decoding data to/from a latent space – learning an embedding is then equivalent to the agents learning to communicate via the latent space. This opens up a plethora of new possibilities as the entire RL toolkit can now be used to further improve these RL-VAEs. In particular, we can tweak their properties so that the learned embeddings are best suited for visualisation and other downstream tasks.<br>If this project is well implemented, it is likely to result in a scientific publication. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | <br>[basic]: empirically demonstrate that VAEs and RL-VAEs produce the same results on simple example datasets<br>[intermediate]: compare the embeddings from RL-VAEs to those generated by other embedding algorithms (e.g. t-SNE, UMAP etc.)<br>[advanced]: perform a systematic analysis (theoretical and/or experimental) of RL-VAEs and their properties<br> |
| Requirements | deep learning (you have to be proficient in PyTorch to do this project); ideally: reinforcement learning |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | deep learning; machine learning; artificial intelligence; visualisation; data science |
| Interview Required | No |

### RL-7: Solving Long-Term Dependencies with Hierarchical Memory

| Description | Long-term dependencies are a major challenge in many domains, such as reinforcement learning and time-series modelling, as Transformers and other model architectures can only look back a finite number of time steps in history. This can be solved by compressing the entire history down to a fixed size while retaining only relevant information. As new observations are constantly coming in, this compression scheme has to be applied recursively/repeatedly resulting in a hierarchical memory "management system", which can be learned. The goal of the project is to experiment and evaluate different ways of implementing this memory management system.<br>This project is particularly interesting because this kind of hierarchical memory management system has not been employed before.  If well implemented, it might well result in a scientific publication.<br>The project is ideally suited as an L4 project after having attended the deep learning and reinforcement learning lectures, but it can also be chosen as an L3 project while attending these lectures in parallel (get in touch if you are unsure). |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | implementation and evaluation of a hierarchical memory management system that improves performance in reinforcement learning or other time-series modelling problems |
| Requirements | indispensable: deep learning; ideally: reinforcement learning |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | deep learning; reinforcement learning; machine learning; time series |
| Interview Required | No |

### RL-8: A PyTorch implementation of the UMAP embedding method

| Description | UMAP is a very efficient, popular, and versatile embedding method. Its current implementation is based on tensorflow, which is limitting UMAP's applicability. For instance, while UMAP allows for data to be embedded into spaces with unusual topologies (e.g. the surface of a sphere or a torus), parameters of the embedding spaces cannot be learned (such as the size of the sphere or torus). This would change when using a PyTorch backend, significantly extending the capabilities of the UMAP method and opening up entirely new possibilities.<br>This extension to PyTorch does not require a deep technical understanding of the UMAP method, but proficiency in PyTorch. The existing tensorflow implementation can be used as a template and ported to PyTorch. |
| - | - |
| Reference URLs | <br>http://arxiv.org/abs/1802.03426<br>https://umap-learn.readthedocs.io/en/latest/<br>https://github.com/lmcinnes/umap/issues/580<br> |
| Anticipated Outcomes | <br>[basic]: A port/extension of the existing UMAP implementation to the PyTorch backend.<br>[intermediate]: Proper documentation and pull request to the official UMAP library to make the PyTorch implementation available to all users.<br>[advanced]: Additional experiments demonstrating the advanced capabilities of the new implementation.<br> |
| Requirements | deep learning (you need to be proficient in PyTorch to do this project) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | artificial intelligence; machine learning; deep learning; data embedding; data visualisation |
| Interview Required | No |

### YL-1: AI-pedia

| Description | Are you interested in AI? Do you want to have a broad overview and solid foundation of AI knowledge? And do you want to make the study fun? If your answers to the above three questions are yes, you should choose this project. You will follow one of the best AI textbooks and enjoy learning. The AI topic can be tailored to your interest that ranges from traditional problem-solving agents to advanced machine learning, deep neural networks, computer vision, natural language processing, or even down-streaming applications, commercialisation and business models or up-streaming theories and philosophy of AI. And you will come up with novel ideas to make learning fun. And finally, you will implement your ideas on the web/app so that other people can learn AI as fast as you can. |
| - | - |
| Reference URLs | Artificial intelligence: a modern approach<br>Russell, Stuart ; Norvig, Peter<br>https://discover.durham.ac.uk/permalink/44DUR_INST/1oe7agi/cdi_askewsholts_vlebooks_9781292410074<br><br>Zichermann, Gabe, and Christopher Cunningham. Gamification by design: Implementing game mechanics in web and mobile apps. " O'Reilly Media, Inc.", 2011.<br>https://books.google.com/books?hl=en&lr=&id=zZcpuMRpAB8C&oi=fnd&pg=PR7&dq=gamification+web+design&ots=UvRa62w95f&sig=buVysik7pqI-BdER8ZDXPGqTki8 |
| Anticipated Outcomes | Extensive AI knowledge and skills; Gamification skills; Web/App Design; |
| Requirements | No technical requirements. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | AI, pedia, game, web/app design |
| Interview Required | No |

### CM-1: Fast machines, racing heartbeats: Numerical Cardiac Modelling

| Description | This project theme covers topics related to cardiac modelling and their numerical solution. Cardiac electrophysiology models are often highly stiff, discontinuous, and overspecified. These features often present difficulties for their reliable solution using automated methods. This theme will incorporate some biological motivation but focus on computational approaches first and foremost. This theme covers interesting problems in cardiac modelling, from low-precision acceleration, to sensitivity and accuracy for classical parameter estimation strategies, and fundamental problems for critical excitation with novel medium connectivity. |
| - | - |
| Reference URLs | www.scholarpedia.org/article/Excitable_media <br>www.scholarpedia.org/article/Models_of_cardiac_cell <br>chaos.gatech.edu/NGL2.0/2D-Beeler-Reuter/  |
| Anticipated Outcomes | Students will develop proficiency with the modelling of cardiac excitation, and the numerical solution of such models. They will develop a competence with some of the fundamental aspects of the field and develop insights into the methods and constraints when answering key questions. |
| Requirements | Experience solving ODEs and PDEs is desirable, and depending on specific topic may be necessary. Some mathematical sophistication may be necessary, depending on project topic; e.g., derivatives, matrices, and differential operators of varying complexity may arise. Neither of these are hard requirements. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Cardiac dynamics, modelling, numerical computing |
| Interview Required | No |

### CM-2: ML and Statistical modelling of excitable media

| Description | Excitable systems are ubiquitous in nature, fulfilling several roles in cells from communication to synchronization, foraging to thinking, spatial organization to temporal rhythms. Understanding these systems with detailed numerical models has been a continual project for computational science since the 1960s. A statistical approach to understanding these models and their limits is a much newer project, due to the more significant computational cost. Projects in this theme will look more closely at the uncertainties of some detailed excitable models, estimate the limits of confidence for experimental data from these processes, and make efforts toward testing some humble applications of machine learning for their suitability in reproducing the subtleties of these systems. |
| - | - |
| Reference URLs | www.scholarpedia.org/article/Excitable_media <br>www.scholarpedia.org/article/Models_of_cardiac_cell <br>chaos.gatech.edu/NGL2.0/2D-Beeler-Reuter/  |
| Anticipated Outcomes | Students will learn a great deal about this fundamental class of physical systems and the computational modeling thereof. Depending on the topic, we will also learn a great deal about some machine learning model structures, Bayesian Learning patterns, or more general uncertainty quantification methods alongside excitable systems modelling. Students will develop an appreciation for the broad applicability of excitable media in nature, and incorporate that appreciation into an understanding of computation that extends beyond silicon. |
| Requirements | Any experience with solving ODEs and PDEs is desirable, but not necessary. You will learn the basics of doing so in this project. Any experience with numerical programming and High-Performance Computing is desirable, but not necessary. For any machine-learning oriented projects, you must have some competence with Python specifically. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Excitable systems, statistical modelling, machine learning |
| Interview Required | No |

### CM-3: ur-ML: Applications for Data Assimilation

| Description | Project topics in this theme focus on the computational aspects of Data Assimilation, arguably the ur-machine learning approach. Data assimilation is a ‘missing link’ between the unstoppable advances of physical systems modelling and the uncertainties inherent to measurements of the real world. Data assimilation forms the backbone of weather and financial market forecasting. While Data Assimilation covers a large expanse of computational approaches, they broadly fall into two categories – ensemble methods and variational methods – the former is the focus of these projects as it requires only a simpler model specification. Topics in this theme will focus on the implementation and modification of data assimilation schemes, exploring the differences in data assimilation formulations, and applying data assimilation methods to existing problems in computational science. |
| - | - |
| Reference URLs | docs.dart.ucar.edu/en/latest/guide/introduction-ensemble-da.html <br>docs.dart.ucar.edu/en/latest/README.html <br>dart.ucar.edu/tutorials/dart-lab/  |
| Anticipated Outcomes | Students will learn a great deal about the fundamentals of data assimilation schemes, especially ensemble-based methods, and the impact of uncertainties in physical systems on our confidence about the future state of those systems. Students will gain an appreciation for the computational expertise required in modern forecasting systems, and be well-placed to proceed with further applications of data assimilation to real-world systems.<br>Students will develop an understanding of scientific machine learning. |
| Requirements | Most existing DA systems are written in Fortran, so some Fortran knowledge is desirable to work with them. However, if you are comfortable with Matlab or Python some alternative packages exist to manage the assimilation procedure for simpler experiments. You should have some experience with numerical computing in your preferred language. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Data assimilation, ensemble modelling, machine learning |
| Interview Required | No |

### CM-4: Adaptive Simulation Strategies for Excitable and Oscillatory Media

| Description | Excitable and oscillatory media cover a range of systems: neuronal signalling, cardiac excitation, vegetation growth in arid climes, social influence dynamics, whose study began in earnest with Turing and Zeldovich. Since these system models are closely tied to biological phenomena, we often find interactions across disparate spatial and temporal scales which requires careful computational techniques to address rigorously. Adaptivity seeks to put the computation effort where it makes the biggest difference, in accuracy and speed. In this project theme we will investigate adaptivity methods applied to excitable and oscillatory media models, understand how the properties of these models affect adaptivity strategies, and look for simple optimizations to consistently produce reliable solutions. |
| - | - |
| Reference URLs | https://mfem.org/features/<br>https://www.dealii.org/current/doxygen/deal.II/step_6.html<br>https://trixi-framework.github.io/Trixi.jl/stable/tutorials/adaptive_mesh_refinement/ |
| Anticipated Outcomes | Students will gain familiarity with one or more adaptive mesh refinement systems and excitable or oscillatory media models, and their application to real-world problems. Students will gain experience and expertise with numerical programming for scientific applications, and produce excellent documentation and development skills. |
| Requirements | Some experience with numerical computing is required. Some experience with C/C++ is highly desirable, but a determined student may find success without it. Some experience with differential equations and calculus is desirable, but not necessary. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | excitable media, adaptivity, numerical methods |
| Interview Required | No |

### CM-5: Birdwatching: Counting and tracking birds for fun and profit with Machine Learning

| Description | This project entails using publicly available data to count, track, and categorize bird movements over the oceans. Some birds flock in particular patterns, travel in stable annual migratory paths, or congregate over food sources. This project will investigate the use of machine learning to identify, count, and track birds through macroscale flock structure, optical sightings, and ornithological reports. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | Development of a concise machine learning application tuned to categorize the types and numbers of observed birds from historical data, including their flock structure. |
| Requirements | Some experience with data analysis and machine learning required. <br>Further, this project topic may require a non-disclosure agreement. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | machine learning, flocking, birds |
| Interview Required | Yes |

### BM-1: The Student-Project Allocation problem

| Description | The Student-Project Allocation problem with preferences<br>over Projects (SPA-P) involves sets of students, projects and lecturers,<br>where the students and lecturers each have preferences over the projects.<br>In this context, we typically seek a stable matching of students to projects<br>(and lecturers). However, these stable matchings can have different sizes,<br>and the problem of finding a maximum stable matching (MAX-SPA-P) is<br>NP-hard (description from [Manlove, Milne and Olaosebikan 2018]).<br><br>In this project we will try to solve this problem in various ways, potentially using Integer Programming. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | A working system to solve instances of the Student-Project Allocation problem with preferences<br>over Projects. |
| Requirements | Integer Programming, Algorithms, Complexity |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### BM-2: Arithmetic constraint satisfaction

| Description | Constraint satisfaction problems (CSPs) allow for a rich expressive framework especially in their infinite-domain generality over structures of arithmetic such as the rationals or integers. Recent work has exposed interesting hybrid algorithms for new tractable classes. In this project we would explore building a solver for certain class of infinite-domain CSPs. This project could also go in the direction of Satisfiability Modulo Theories which gives a powerful formalism for solving general arithmetic CSPs. |
| - | - |
| Reference URLs | https://arxiv.org/abs/1503.08572,https://arxiv.org/abs/1503.08572,https://people.eecs.berkeley.edu/~sseshia/pubdir/SMT-BookChapter.pdf |
| Anticipated Outcomes | A constraint solver for infinite-domain Constraint Satisfaction Problems. |
| Requirements | Basic mathematics, basic programming. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | CSP solving, Constraint programming, Satisfiability Modulo Theories |
| Interview Required | No |

### BM-3: Solving Quantified Constraints

| Description | Quantified constraint satisfaction problems (QCSPs) allow for a richer expressive framework than classical constraint satisfaction problems with computational complexity rising to Pspace. They are used in Artificial Intelligence to model non-monotonic reasoning and planning. Quantified Boolean Formulas (QBF) is the canonical extension of propositional Satisfiability from NP to Pspace by restoring universal quantification. In this project we would explore building a solver for QCSPs or certain classes of QCSPs that enjoy benign properties such as the so-called collapsibility or ability to be solved by local consistency methods. |
| - | - |
| Reference URLs | https://pn.host.cs.st-andrews.ac.uk/qcsp_aij_final_version.pdf,https://arxiv.org/abs/cs/0607106 |
| Anticipated Outcomes | The building of a QCSP solver |
| Requirements | Basic mathematics, basic logic, basic programming. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | QCSP solving, Quantified constraints, Constraint programming |
| Interview Required | No |

### BM-4: Solving problems with Satisfiability

| Description | Modern SAT-solvers are very efficient and many practitioners argue they make NP a tractable class. Additionally, they can be used to improve upper and lower bounds for many constants arising from combinatorial problems. This project would look at encodings of problems into propositional satisfiability in order to seek bounds for Ramsey numbers, van der Warden numbers, graph colouring numbers or similar. |
| - | - |
| Reference URLs | https://www7.in.tum.de/um/bibdb/kugele/kugele_diploma06.pdf,https://arxiv.org/abs/1510.02374,https://www.sciencedirect.com/science/article/pii/S0307904X14006556 |
| Anticipated Outcomes | A good encoding to propositional satifiability that yields improved bounds for combinatorial constants. |
| Requirements | Basic mathematics, basic programming |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | SAT-solving, Ramsey Theory, Combinatorics |
| Interview Required | No |

### BM-5: Verification

| Description | Verification is a powerful tool for proving certain desirable properties are satisfied in some system. In many critical processes, verification forms an invaluable dual procedure to testing. The aim of this project is to formally specify some chosen system of protocol in order that some desirable property might be verified to hold in it, though the use of a formal verifier such as SMC or SPIN. An alternative possibility is to add some functionality to these formal verifiers. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | The formal verification of some property on a specified system or protocol |
| Requirements | Basic mathematics, basic programming |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Verification, Temporal logics, Modal logics |
| Interview Required | No |

### BM-6: Social Network Analysis

| Description | Social Network Analysis is a powerful tool for understanding the dynamics and flow properties in social networks. For example, these could be in the form of friendship ties or knowledge flows in a network of people, or disease propagation in a network of animals. The aim of this project is to formulate and implement useful metrics for the analysis of social networks, which could be mined from the internet or come from some established data set. |
| - | - |
| Reference URLs | https://networkx.github.io/ |
| Anticipated Outcomes | The meaningful analysis of a social network |
| Requirements | Basic mathematics, basic programming |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Network Analysis, Graph Theory |
| Interview Required | No |

### GM-1: Coloring a graph via a game

| Description | A proper coloring of a graph is an assignment of colors to the vertices of the graph (one color for every vertex) such that any two adjacent vertices receive different colors. Computing the smallest number of colors that are needed to proper color a given graph is an NP-hard problem, i.e. most probably there does not exist any exact algorithm that runs in polynomial time in worst-case. However, as the proper coloring problem finds many applications in various contexts, it is important to deal with this problem with various algorithmic approaches, even if they do not always guarantee an optimum output. In this project we aim at implementing and experimentally evaluating a recently developed game-theoretic method for computing a proper coloring of a given graph, in which every vertex of the graph corresponds to a strategic player of the game. |
| - | - |
| Reference URLs | https://www.tandfonline.com/doi/abs/10.4169/amer.math.monthly.119.09.771 |
| Anticipated Outcomes | To implement and experimentally evaluate a recently developed game-theoretic method for computing a proper coloring of a given graph. |
| Requirements | none |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | proper coloring problem, graph, chromatic number, strategic game, equilibrium. |
| Interview Required | No |

### GM-2: Influence spreading in networks

| Description | The notion of influence spreading in a network is central in many modern applications, including social networks. There are two main types of influence propagation models, progressive and non-progressive. In a progressive model, once a node of the network becomes infected (i.e. influenced), it will remain forever; in contrast, in non-progressive models the nodes may become infected and uninfected many times. The goal of this project is to simulate and compare various influence spreading models, progressive and non-progressive, the performance of which will be analyzed and compared with the theoretical findings in the area. |
| - | - |
| Reference URLs | https://www.sciencedirect.com/science/article/pii/S0304397514005398 |
| Anticipated Outcomes | The implementation and simulation of influence spreading models and the comparison of the experimental findings with the theoretical ones. |
| Requirements | none |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | influence spreading, network, progressive model, non-progressive model, target set. |
| Interview Required | No |

### GM-3: Temporal Networks

| Description | Consider a network where every edge is assigned a set of natural numbers (its labels). The set of labels of an edge represent the different moments in time in which this specific edge is available. Such labeled networks are called temporal networks and they represent networks that are dynamically changing over time. Many problems in standard networks can be appropriately modified to make sense in the context of temporal networks. For instance, while to guarantee connectivity in standard networks we need to have a path between any pair of vertices, in the context of a temporal network we achieve connectivity if there exists a temporal path between any pair of vertices, i.e. a path in which the labels of the edges are increasing. Various further classical 'non-path' graph problems can be naturally extended to the temporal settings, such as Maximum Clique, Minimum Vertex Cover, Maximum Matching. The goal of this project is to implement and evaluate various algorithmic approaches to optimization problems in temporal networks. |
| - | - |
| Reference URLs | - https://arxiv.org/abs/1502.04382<br><br>- https://link.springer.com/article/10.1007/s00453-018-0478-6 |
| Anticipated Outcomes | To implement various algorithms on temporal networks and to compare their experimental performance with the theoretically predicted performance. |
| Requirements | A basic understanding of graph algorithms |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | algorithm, graph theory, temporal network, dynamic network, edge label, temporal path. |
| Interview Required | No |

### GM-4: Blockchain tokens

| Description | The blockchain paradigm when coupled with cryptographically-secured transactions has demonstrated its utility through a number of projects, not least Bitcoin. Extending on the Bitcoin, Ethereum revolutionized the blockchain technology by providing a platform on which arbitrary smart contracts can be implemented and executed. These smart contracts (ERC20 tokens) need to be implemented on a dedicated, Turing-complete programming language, called Solidity. At a later stage other blockchain platforms appeared, having the same â€“or in some cases even more enhancedâ€“ capabilities, such as the NEO platform (issuing NEP5 tokens). The aim of this project is to implement an ERC20 or a NEP5 token with smart contracts of a specific functionality and to explore the capabilities of such a token. |
| - | - |
| Reference URLs | http://blockchain.mit.edu/<br>https://www.ethereum.org/<br>https://solidity.readthedocs.io/en/develop/introduction-to-smart-contracts.html |
| Anticipated Outcomes | To implement an ERC20 or a NEP5 token with smart contracts of a specific functionality and to explore the capabilities of such a token. |
| Requirements | The student should be comfortable with learning a new programming language (e.g. Solidity) and have sufficient self-motivation to learn about the underlying technology of blockchain and its applications. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | blockchain, Ethereum, ERC20 token, algorithm, programming language. |
| Interview Required | No |

### GM-5: Mutating Networks

| Description | Consider a network with nodes and undirected edges, where the nodes are occupied by (at least two) different kinds of individuals. As time elapses, neighboring individuals in this network interact with each other. In that case, the color of two interacting individuals may change according to some fixed rule (which may be probabilistic or not). That is, individuals mutate, and thus the network itself mutates as well. In such 'mutating rules' that are interesting in practice, some colors are more 'aggressive' than others, in the sense that these colors mutate more rarely than others (they act as viruses). This project aims at implementing a platform for mutating networks, where different interaction rules/patterns can be experimentally tested against their theoretically predicted behavior. |
| - | - |
| Reference URLs | https://www.sciencedirect.com/science/article/pii/S0304397512010754?via%3Dihub |
| Anticipated Outcomes | The implementation of a platform for mutating networks, where different interaction rules/patterns can be experimentally tested. |
| Requirements | none |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | evolutionary dynamics, directed/undirected graphs, fixation probability, potential function, Markov chain, fitness, population structure. |
| Interview Required | No |

### LMo-1: SYCL-based Parallelization of HPCCG

| Description | There is a vast number of parallel programming approaches for shared and distributed memory systems and heterogeneous hardware, reaching from threading with OpenMP, std::threads or oneTBB right through to vectorization, message passing and GPU programming. However, it remains a challenge for software developers to decide which of these approaches is the best fit for an application in terms of performance and sustainability. Since applying these approaches to complex, production-ready applications in a trial-and-error manner is time-intensive and costly, it is advantageous to experiment with different parallelization approaches on qualitatively similar but less complex application prototypes first. This is what the ECP proxy app suite was invented for! The benchmarking suite consists of several mini applications that model typical scientific applications. For each of these mini applications, the suite provides a sequential base line implementation and several parallel implementations, e.g. with OpenMP, MPI or CUDA. The objective of this project is to provide a parallel implementation of the C++-based ECP proxy app HPCCG, a conjugate gradient code, with SYCL. SYCL is a parallel programming standard for unified software development on heterogeneous hardware. The SYCL-based implementation is subjected to a performance analysis. The project can be expanded in several ways, e.g., by a comparative performance analysis, by developing a distributed memory version with Celerity, or by conducting a sustainability evaluation in terms of maintainability metrics such as code size, cyclomatic complexity and performance portability. |
| - | - |
| Reference URLs | \\\\\\\"https://proxyapps.exascaleproject.org/app/\\\\\\\"<br>\\\\\\\"https://www.khronos.org/sycl/\\\\\\\"<br>\\\\\\\"https://celerity.github.io/\\\\\\\" |
| Anticipated Outcomes | Basic: <br><br> SYCL-based implementation of HPCCG <br> Performance Analysis<br><br><br>Advanced: <br><br> Comparative performance analysis against another parallel CPU/GPU implementation of HPCCG<br> Comparative evaluation of maintainability metrics<br> Distributed memory implementation with Celerity<br> |
| Requirements | C++, or a keen interest to learn it |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | C++, Parallel Programming, HPCCG, Performance Analysis, Benchmarking, Maintainability, Software Engineering, SYCL |
| Interview Required | No |

### LMo-2: Enabling Fine-Grained Task-Parallelism on Massively Parallel Hardware with SYCL

| Description | Many algorithms barely provide sufficient data-parallelism to efficiently use the high number of compute cores of today's processors. To tackle this challenge, several task-parallel programming technologies have been developed to allow for the flexible description of algorithms along their task graphs. For algorithms with dense task graphs, however, task-parallelism is still hard to exploit efficiently since it is programmatically complex to describe and imposes high task dependency resolution overheads during execution. This becomes especially challenging on GPUs since their architecture is not designed for synchronization-heavy applications. The research objective of this project is to port a task-parallel programming framework for GPUs from CUDA to SYCL to allow for its usage on CPUs and GPUs without having to rewrite application code. CUDA is the prevalent model for GPU computing in HPC, while SYCL is a novel parallel programming standard for unified software development on CPUs, GPUs, and FPGAs. |
| - | - |
| Reference URLs | https://code.fmsolvr.fz-juelich.de/ATML-SE/eventify-GPU<br><br>https://dl.acm.org/doi/abs/10.1145/3394277.3401858<br><br>https://www.khronos.org/sycl |
| Anticipated Outcomes | Basic: <br><br> Porting of queue data structure to SYCL <br> Porting of task producer-consumer mechanism to SYCL<br> Performance analysis with parallel efficiency as performance metric<\><br><br><br>Advanced: <br><br> Implementation of graph data structure for dependency resolution<br> Implementation of a tree-based accumulation as use case on top of the framework<br> |
| Requirements | C++, or a keen interest to learn it. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | C++, Parallel Programming, High Performance Computing, Software Engineering, GPU Computing, SYCL, CUDA |
| Interview Required | No |

### BMo-1: Dispersion of mobile robots on a dynamic graph with fault tolerance

| Description | In this project, we're going to look at the problem of dispersion, where there are k robots that must autonomously work together to spread out over a given graph so that no node has too many robots on it in the end. This problem can act as a theoretical abstraction for situations where entities (robots) must share resources (nodes). For example, consider a bunch of electric cars moving around a city, trying to find an electric charging station to use (among many present in the city). The charging stations  (nodes) are connected to each other by roads (edges) and the electric cars (robots) want to move around so that they are not waiting in line at the same charging station. <br><br>Now, with the problem and motivation out of the way, we're going to tweak things so life isn't so simple. What if the roads between stations changed with time and the robots didn't know about those changes in advance? What if some of the cars were actually faulty and didn't move around as expected. Well, we're going to study these things and come up with algorithms to still solve the problem despite these challenges. |
| - | - |
| Reference URLs | https://arxiv.org/abs/1707.06391 <br>You can use that URL to access a paper that solves this problem in the given setting minus fault tolerance. You can get a feel for the model and what algorithms might look like. |
| Anticipated Outcomes | Algorithm(s) that solve the given problem along with proofs about correctness and runtime of the algorithms. Depending on the interest and effort of the student, we may expand the scope of the project in a way that may lead to a publication. |
| Requirements | <br> Strong foundations in algorithms, including the ability to prove correctness and bounds on algorithms. <br> Decent level of comfort working with graphs. <br> Preferable if you have worked on distributed algorithms before but not necessary. <br> |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Dispersion, distributed computing, theory, algorithms, fault tolerance |
| Interview Required | No |

### BMo-2: Dispersion of mobile robots on a dynamic graph in the semi-synchronous setting

| Description | In this project, we're going to look at the problem of dispersion, where there are k robots that must autonomously work together to spread out over a given graph so that no node has too many robots on it in the end. This problem can act as a theoretical abstraction for situations where entities (robots) must share resources (nodes). For example, consider a bunch of electric cars moving around a city, trying to find an electric charging station to use (among many present in the city). The charging stations  (nodes) are connected to each other by roads (edges) and the electric cars (robots) want to move around so that they are not waiting in line at the same charging station. <br><br>Now, with the problem and motivation out of the way, we're going to tweak things so life isn't so simple. What if the roads between stations changed with time and the robots didn't know about those changes in advance? What if some of the cars periodically shut down for unknown amounts of time. Well, we're going to study these things and come up with algorithms to still solve the problem despite these challenges. |
| - | - |
| Reference URLs | <br> https://arxiv.org/abs/1707.06391 <br>You can use that URL to access a paper that solves this problem in a fully synchronous setting. You can get a feel for the model and what algorithms might look like. <br> https://arxiv.org/abs/1512.05306 <br>Have a look at page 3 and 4 to see what the semi-synchronous setting is all about. <br> |
| Anticipated Outcomes | Algorithm(s) that solve the given problem along with proofs about correctness and runtime of the algorithms. Depending on the interest and effort of the student, we may expand the scope of the project in a way that may lead to a publication. |
| Requirements | <br>Strong foundations in algorithms, including the ability to prove correctness and bounds on algorithms.<br>Decent level of comfort working with graphs. <br>Preferable if you have worked on distributed algorithms before but not necessary.<br> |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Dispersion, distributed computing, theory, algorithms, semi-synchronous time |
| Interview Required | No |

### BMo-3: Dispersion of mobile robots on a dynamic graph with partial vision

| Description | In this project, we're going to look at the problem of dispersion, where there are k robots that must autonomously work together to spread out over a given graph so that no node has too many robots on it in the end. This problem can act as a theoretical abstraction for situations where entities (robots) must share resources (nodes). For example, consider a bunch of electric cars moving around a city, trying to find an electric charging station to use (among many present in the city). The charging stations  (nodes) are connected to each other by roads (edges) and the electric cars (robots) want to move around so that they are not waiting in line at the same charging station. <br><br>Now, with the problem and motivation out of the way, we're going to tweak things so life isn't so simple. What if the roads between stations changed with time and the robots didn't know about those changes in advance? What if you didn't have a good idea of where all the other cars were but instead just a limited view of your immediate surroundings. Well, we're going to study these things and come up with algorithms to still solve the problem despite these challenges. |
| - | - |
| Reference URLs | https://arxiv.org/abs/1707.06391 <br>You can use that URL to access a paper that solves this problem in the given setting where robots have full vision instead of only partial vision. You can get a feel for the model and what algorithms might look like. |
| Anticipated Outcomes | Algorithm(s) that solve the given problem along with proofs about correctness and runtime of the algorithms. Depending on the interest and effort of the student, we may expand the scope of the project in a way that may lead to a publication. |
| Requirements | <br>Strong foundations in algorithms, including the ability to prove correctness and bounds on algorithms.<br>Decent level of comfort working with graphs. <br>Preferable if you have worked on distributed algorithms before but not necessary.<br> |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Dispersion, distributed computing, theory, algorithms, partial vision |
| Interview Required | No |

### BMo-4: Leader election in programmable matter with fault tolerance

| Description | Programmable matter involves the idea that you can individually program small robots to do simple things so that collectively they do something more complex. For an example, look at the MicroBots from the movie Big Hero 6.<br><br>So, when you want to work on an idea, you need to first model it and make it more concrete. For our purposes, we use the amoebot model as a concrete way to study programmable matter. In this model, we ask ourselves the fundamental question of "even if everyone looks the same, can I do something clever and get just one person to stand out" or more succinctly put, can we elect a leader. Well, that's what we're going to do here, only we're going to add in a complicating factor that the robots may be faulty in some way. |
| - | - |
| Reference URLs | <br> https://scholar.archive.org/work/2r5i3telhjbu5pklfgank42vfi/access/wayback/http://www-old.cs.uni-paderborn.de/fileadmin/Informatik/FG-TI/Publikationen/spaa0067-derakhshandeh.pdf <br>That link is to the initial paper that proposed the amoebot model. It is an easy-to-read paper that talks about the model in question as well as the powers of the individual particles. <br> https://arxiv.org/abs/2106.01108 <br>This paper gives a leader election algorithm. This gives you an idea of the complexity involved in performing a computation (electing a leader) when movement is allowed. <br> https://drops.dagstuhl.de/opus/volltexte/2022/16794/pdf/LIPIcs-DNA-28-9.pdf <br>One type of fault tolerance is mentioned here.<br> https://arxiv.org/abs/1707.05041 <br>Another type of fault tolerance is looked at here.<br> |
| Anticipated Outcomes | Algorithm(s) that solve the given problem along with proofs about correctness and runtime of the algorithms. Depending on the interest and effort of the student, we may expand the scope of the project in a way that may lead to a publication. |
| Requirements | <br>Strong foundations in algorithms, including the ability to prove correctness and bounds on algorithms. <br>Decent level of comfort working with graphs. <br>Preferable if you have worked on distributed algorithms before but not necessary.<br>Would be useful if you have previously worked on geometric problems.<br> |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Programmable matter, amoebot model, theory, distributed computing, fault tolerance |
| Interview Required | No |

### RP-1: Implementing efficient hash tables on GPUs

| Description | Modern GPUs from both Nvidia and AMD offer enormous amounts of processing power, yet a number of algorithms are deemed unsuitable for computation on GPUs as they require random memory accesses, such as those required to insert and retrieve entries in hash tables. Various probing schemes lead to divergence, where some GPU cores are forced to wait for the worst-case number of probes, and in high density hash tables this can cause significant slowdowns. The student working on this project will investigate and implement various hashing algorithms and analyse their performance on modern GPUs. |
| - | - |
| Reference URLs | https://www.researchgate.net/publication/211178395_Building_an_Efficient_Hash_Table_on_the_GPU |
| Anticipated Outcomes | Implement a number of various hashing algorithms in CUDA and/or OpenCL and compare performance with various constraints. Compare the results to those in the thesis of Alcantara, particularly considering updates in GPU architectures since 2011. |
| Requirements | C/C++/CUDA/OpenCL Programming. We have NVidia GPUs available on NCC, though having access to your own GPU would likely be an advantage. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | CUDA, OpenCL, Hash Tables, Optimisation |
| Interview Required | No |

### RP-2: Exploring Aliquot Sequences with Markov Chains

| Description | An aliquot sequence is a sequence of positive integers, where each term is the sum of the proper divisors of the previous term. The sequence ends when you reach the number 1 (or 0), or you reach a repeating sequence. E.g. Perfect numbers such as 6 - the proper divisors are 1,2 and 3, which sum to 6. It is still an open problem as to whether all aliquot sequences eventually terminate (with a 1 or a repeating sequence), or whether a sequence can continue infinitely. The growth of these sequence is controlled by mathematical objects called drivers and guides, which regularly mutate. These mutations can be modelled using Markov Chains, and we can analyse the underlying directed graph. The theoretical results can be compared against the practical results which can be scraped from the factor database (factordb.com), and an algorithm can be devised to predict which open aliquot sequences should be the easiest to terminate. |
| - | - |
| Reference URLs | https://www.ams.org/journals/mcom/1975-29-129/S0025-5718-1975-0384669-X/S0025-5718-1975-0384669-X.pdf |
| Anticipated Outcomes | Build a theoretical model of Aliquot driver and guide mutations, and compare this with experimental findings. Using the theoretical model we can implement algorithms to attempt to determine expected sequence lengths, the maximum size of numbers to be factorised, and which open sequences might be easiest/hardest to terminate. |
| Requirements | Strong interest in mathematics and graph theory, and likely a passing interest in Integer Factorisation. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | Aliquot Sequence, Catalan's Conjecture, Markov Chains, Directed Graphs, Probability |
| Interview Required | No |

### RP-3: Reinforcement Learning for Team Based Card Games

| Description | Reinforcement learning has been successfully used to learn to play board games such as backgammon through self-play. In this project we would like to apply a similar technique to card games, where players play in teams. AI has had much success in learning to play 2-player card game such as heads-up Texas hold'em, but there has been less research into card games such as Bridge and Cribbage which are generally played in pairs. |
| - | - |
| Reference URLs | https://www.ifaamas.org/Proceedings/aamas2019/pdfs/p16.pdf |
| Anticipated Outcomes | An implementation of an AI agent for playing a team based card game such as Cribbage or Bridge |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | AI, Machine Learning, Card Games, Bridge, Cribbage |
| Interview Required | No |

### RP-4: Reinforcement Learning - Looking for new Backgammon Strategies

| Description | Backgammon is a two player board game that involves a combination of strategy and luck. You may have an "unlucky" roll of the dice, but the player with the better strategy will win on average over a number of games. There are 5 well known backgammon strategies, but what has not been studied so well are hybrids of these strategies. Recent match analysis suggests that a hybrid of the Priming Game and the Back Game strategies may be interesting for example. Most of the well known AI software for playing backgammon only considers single games rather than match style play where Gammons, Backgammons and the doubling cube, so these would be interesting additions to a project. |
| - | - |
| Reference URLs | http://incompleteideas.net/book/bookdraft2018feb28.pdf <br>https://www.csd.uwo.ca/~xling/cs346a/extra/tdgammon.pdf |
| Anticipated Outcomes | An implementation of one or more AI agent players for backgammon to evaluate new strategy concepts. |
| Requirements | None |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | AI, Reinforcement Learning, Backgammon |
| Interview Required | No |

### AR-1: Seismic Risk Assessment

| Description | In earthquake modeling the earth's crust is modeled as an elastic solid.  <br>Within this crust are fault planes, zones of weakness along which earthquakes often occur.<br>We are interested in using data gathered during earthquakes to localise such faults. To do so <br>we plan to extend an existing interface between the MIT UQ library MUQ and the ExaHyPE<br>Engine and apply it to simulate Bayesian Inverse Problems for seismic applications. This requires<br>two levels of parallelism: firstly parallelism in the foward model and secondly in the Markov chain. |
| - | - |
| Reference URLs | Bonnet, Inverse problems in elasticity (iopscience.iop.org/article/10.1088/0266-5611/21/2/R01)<br>exahype.eu/<br>muq.mit.edu/ |
| Anticipated Outcomes | Extensions to a MUQ/ExaHyPE Interface, distribution of fault data |
| Requirements | Interest in numerical methods and statistics, some knowledge of C/C++ |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Inverse problems, HPC |
| Interview Required | No |

### AR-2: Containerised UQ

| Description | With increased computing power now available, many areas are beginning to explore the effect of uncertain paramters<br>on the outcome of simulations. This could be data with unknown measurement errors, missing data or even<br>unknown model parameters. In recent years there has been an explosion of new methods and algorithms for UQ.<br>As such there is increasing need for a common set of benchmark examples that new algorithms can be tested on.<br>Since the language/libraries each new algorithm is developed in differ widely, exploring containerised testing<br>for UQ algorithms would be interesting.<br><br>There are two potential project directions:<br>- Set up a Docker container with a new industrially relevant test example<br>- Test Singularity on one of Durhams HPC systems as an alternative to docker on GCP |
| - | - |
| Reference URLs | https://github.com/UQ-Containers/testing |
| Anticipated Outcomes | Additional benchmark tests added to the UQ Testing Suite |
| Requirements | none, experience with Kubernetes a plus |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | UQ, Docker, Singularity, GCP |
| Interview Required | No |

### AR-3: Stress Recovery Methods

| Description | Composite materials are now very widely used particularly in aerospace applications (they make up >50% of some recent airplane designs) due to their excellent strength to weight ratio.<br><br>When solving the elasticity equations with a composite material one is often interested in the stresses that occur as the result of a given displacement or force. This is because these can be used to predict when the composite material will \\\"fail\\\", or break.<br><br>However, they are notoriously difficult to model due to their fine-scale structure (on the order of 0.1 mm) and complex anisotropy. The goal of this project is to increase the fidelity of the stresses computed with the  dune-composites module to predict failure more accurately. |
| - | - |
| Reference URLs | https://hal.archives-ouvertes.fr/hal-00612711/document |
| Anticipated Outcomes | High-order stress results |
| Requirements | Knowledge of C++ and templates a plus |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | FEM, stress recovery |
| Interview Required | No |

### AR-4: Higher-order Visualisation in Paraview

| Description | In numerical simulation of physical phenomena (e.g. earthquakes, tsunami waves) the output is often a velocity or displacement field. In order to fully understand these output fields, it is extremely important to visualise them well. Many modern numerical methods, such as Discontinusous Galerkin methods, output solutions of higher polynomial order. However, many visualisation tools only support linear polynomials. Very recently arbitrary-order Lagrange polynomials have been introduced in VTK and they are now supported in Paraview, which is an open source parallel visualisation tool built on VTK. Paraview is mainly used for the visualization of large scale (millions or billions of degrees of freedom) data sets. In this project you will extend the visualisation of simulation output into higher orders. |
| - | - |
| Reference URLs | https://www.kitware.com/high-order-using-gmsh-reader-plugin-in-paraview/ |
| Anticipated Outcomes | An output writer capable of using high-order Lagrange polynomials for an existing numerical solver |
| Requirements | Some knowledge of C++ is a plus |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Visualisation, Numerical Simulation, High-order |
| Interview Required | No |

### PR-1: Classification of typical plants for assessment of the health of a natural habitat

| Description | Habitat monitoring is usually performed by botanists and other specialists in their field work, searching for the presence or lack of typical plant species and other elements (such as vegetation cover) that might indicate the degradation of a habitat. This project will engage the selected student in a study on habitat monitoring and the development of algorithms for the detection of typical plants. the project will contribute to a European project, entitled Natural Intelligence. <br>it is expected that deep learning algorithms will be developed to categorise a currently digital corpus of living plants,  collected in four different habitats in Italy. <br>Although the project will be meant to make a contribution to the European project, out of the box idea might be applied to other corpora available in public domain. |
| - | - |
| Reference URLs | https://www.nih2020.eu |
| Anticipated Outcomes | - comprehensive review of existing literature on the subject<br>- definition of comparison criteria for the literature methods and creation of comparison tables<br>- selection of the most relevant algorithms<br>- comparison of the selected algorithms<br>- development of novel algorithm for classification<br>- expected conference publication |
| Requirements | - good knowledge of maths and stats<br>- good knowledge of image and video processing<br>- knowledge of some pattern recognition algorithms<br>- some knowledge of deep learning algorithms |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | image classification, pattern recognition, deep learning, health of natural habitat, botany |
| Interview Required | No |

### PR-2: Thorough Comparison of Deep Networks

| Description | Since the success of machine and deep learning, many neural architectures have been proposed in research. There are so many variations that it is hard to understand which one is the best for a given task. We are interested in running a thorough investigation in the most popular architectures, classify them for given tasks, validate them and test them, trying to understand how they can generalise.<br>The applications we are mainly interested in are those for image and video classification tasks. |
| - | - |
| Reference URLs | as an example https://www.nih2020.eu |
| Anticipated Outcomes | A thorough study on the latest deep architectures, with extensive testing on the publicly available large datasets. If the study leads to novel methods, we can submit a conference article. |
| Requirements | Good grasp of machine learning concepts, some knowledge of deep learning and some expertise in image and video analysis. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | image and video analysis, deep learning. |
| Interview Required | Yes |

### PR-3: Machine Learning for storage and summarisation of large data

| Description | We humans remember moments, concepts, events as a combination of perceived data. Our brain transforms data into information and then knowledge. We can store large corpora of information, reuse it and adapt our memory to store additional information.<br>We are interested in the process of how memory works in humans and in a study on the latest deep architectures that can be employed to store large quantities of information. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | A thorough study on the latest machine learning methods to memorise large quantities of data. If the study leads to novel methods, we can submit a conference article. |
| Requirements | Some expertise in image and video analysis and machine learning. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | memory, image and video analysis, pattern recognition |
| Interview Required | Yes |

### PR-4: How much information can be removed from an image while preserving what it wishes to convey?

| Description | Cameras on smart devices and semi or fully professional cameras are used on a daily basis. A photo is usually taken to capture an event, an object or a person etc. However, how much of the captured information is really essential to preserve what was meant to be captured?<br>This project will explore all recent deep architectures and machine learning methods that can reconstruct an image from portions of a photo. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | Selection of a large image dataset and the comparison of existing methods in deep learning used to reconstruct partial images, photos or paintings. The student will have to learn on the latest methods such as the standard and siamese masked auto encoder and others, implement them or make use of existing software. There is scope for a conference publication if novelty can come out of this project. |
| Requirements | knowledge of image processing and some of deep learning |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | Yes |

### HS-1: People Movement Trajectory Analysis and Prediction with Deep Learning

| Description | In this project, the student will research and implement relevant deep learning techniques for analysing people movement trajectories. Here, the movement of a person is considered as a time series of 2D position. Such data is usually captured by overhead cameras and extracted by pre-trained tracking networks [1]. The movement is affected by many factors such as the surrounding people and the environment. Deep learning architectures such as the convolutional neural network (CNN) and long short-term memory (LSTM) has shown to be effective in the modelling the spatial and temporal feature of the movement trajectories [2, 3]. More advanced architectures using graph convolutional neural networks (GCN) can incorporate the trajectories of nearby people to produce state-of-the-art results [4]. The student will adapt and improve a network to model the trajectory better, and perform experiments to evaluate the proposed system. The results in this project can inform real-world applications such as predicting people movement trajectories, detecting violations of social distancing under COVID-19 and identifying abnormal people behaviour. |
| - | - |
| Reference URLs | <br>[1] https://stanford.io/3o8yj90<br><br>[2] https://stanford.io/3eD8HOm<br><br>[3] https://arxiv.org/abs/1803.10892<br><br>[4] https://arxiv.org/pdf/2002.11927.pdf |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for trajectory analysis. There are opportunities for scientific publications with positive results. |
| Requirements | Background in computer vision and deep learning, experience in programming such as Python with PyTorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Deep learning, time series, computer vision, human behaviour analysis, crowd modelling |
| Interview Required | No |

### HS-2: Synthesizing 3D Human Motion for Games and Animation with Deep Learning

| Description | In this project, the student will research and implement relevant deep learning frameworks for synthesizing 3D human motion, such as the running and walking movement. 3D motion is represented by a set of 3D joint positions over time, and therefore spatial and temporal deep learning modules have shown to be effective in learning the features of the motion and synthesizing new ones [1]. The student will further explore methods of controlling the synthesis [2, 3] according to user inputs, such as providing the desired movement trajectory and the motion style. Public dataset such as the CMU motion database [4] provides a large amount of data for training the proposed system. The results of this project can be used in real-time computer games and high-quality computer animation. |
| - | - |
| Reference URLs | <br>[1] https://bit.ly/3eId0Ia<br><br>[2] https://bit.ly/3hktJTw<br><br>[3] https://bit.ly/3o9y5yi<br><br>[4] http://mocap.cs.cmu.edu/ |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for synthesizing 3D human motion. There are opportunities for scientific publications with positive results. |
| Requirements | Background in computer graphics and deep learning, experience in programming such as Python with Pytorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Computer graphics, computer animation, deep learning, human motion, synthesis |
| Interview Required | No |

### HS-3: Vision-based Drones/UAVs Tracking with Deep Learning

| Description | In this project, the student will research and implement relevant deep learning techniques for tracking drones (also known as unmanned aerial vehicles, UAVs). The effective detection and tracking of drones/UAVs have become more and more important for surveillance and security due to the rapidly increasing usage. Existing tracking frameworks work reasonably well on drones [1, 2], but there are rooms for improvement. The key challenges are that drones can be viewed from a much wider range of angles, and are usually small in the image space due to the far distance. The student will adapt existing tracking frameworks and propose new ideas to improve tracking accuracy. Existing dataset such as [3] can be used for training and testing. Our team has delivered a successful project [4] funded by the UK Catapult Network, and successful outcomes may be introduced to surveillance companies. |
| - | - |
| Reference URLs | <br>[1] https://arxiv.org/pdf/2103.13933.pdf<br><br>[2] https://arxiv.org/pdf/2104.06219.pdf<br><br>[3] https://wosdetc2020.wordpress.com/<br><br>[4] http://hubertshum.com/fnd_strig2020drones.htm |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for drones tracking. There are opportunities for scientific publications with positive results. |
| Requirements | Background in computer vision and deep learning, experience in programming such as Python with PyTorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Deep learning, CNN, computer vision, tracking, detection, re-identification |
| Interview Required | No |

### HS-4: Human Activity Recognition from Skeletal Data with Deep Learning

| Description | In this project, the student will research and implement relevant deep learning frameworks for recognising human activity, such as falling, walking and eating. Skeletal motion data, which is represented as joint positions of a human body, has become widely available thanks to the advancement of pose estimation networks [1]. As a result, human activity recognition can be performed effectively using skeletal data as an input. Approaches using recurrent convolutional neural networks to model the spatial and temporal features are shown to be effective [2], while the more advanced graph convolutional neural networks model the features even better [3]. The student will adapt and improve existing networks such that they can model human features better. Public datasets such as [4] will be used for network training and evaluations. The results can inform real-world applications such as in-home monitoring and security surveillance. |
| - | - |
| Reference URLs | <br>[1] https://arxiv.org/abs/1611.08050<br> <br>[2] https://bit.ly/3tEYV2A<br><br>[3] https://bit.ly/3hi6sSp<br><br>[4] https://bit.ly/3eDxHoy |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for identifying the nature of human activity. There are opportunities for scientific publications with positive results |
| Requirements | Background in computer vision and deep learning, experience in programming such as Python with PyTorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Computer vision, deep learning, activity recognition |
| Interview Required | No |

### HS-5: Recognising People in Artworks with Computer Vision and Deep Learning

| Description | In this project, the student will research and implement relevant deep learning techniques for recognising and analyzing people in artworks. Deep learning based computer vision has enabled computers to analyze images and recognize their content. This project focuses on adapting such techniques into artworks (e.g. paintings, drawings), which are non-photorealistic and geometrically different from the real-world counterpart [1]. A particular focus will be the human context, such as human postures, facial expression and emotion [2, 3]. Existing research shows that effective analysis of people context in artworks enables new understandings of art history that have not been seen before [4]. The student will choose a task of interest, adapt relevant networks with novel improvements, and evaluate the performance. |
| - | - |
| Reference URLs | <br>[1] https://arxiv.org/pdf/2104.06820.pdf<br><br>[2] https://arxiv.org/pdf/1611.08050.pdf<br><br>[3] https://arxiv.org/pdf/1604.02878.pdf<br><br>[4] https://bit.ly/3tGc7UR |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for human recognition and analysis on artworks. There are opportunities for scientific publications with positive results. |
| Requirements | Background in computer vision and deep learning, experience in programming such as Python with PyTorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Deep learning, CNN, computer vision, non-photorealistic, GAN |
| Interview Required | No |

### HS-6: Hand-object Interaction Detection in Egocentric Video with Deep Learning

| Description | In this project, the student will research and implement relevant deep learning techniques for modelling hand-object interaction through the detection of hand pose and hand gestures in the first-person view, i.e. egocentric video. Understanding and modelling how the hand interact with an object enable better recognition of high-level hand activities such as cooking and painting. Traditional hand-object interaction modelling directly models the interaction from the input images [1]. With the advancement of hand pose estimation networks, it becomes possible to model the complex shape of a hand with simple skeletal joints [2]. Such a skeletal representation allows more effective interaction detection [3]. The student will adapt and design neural networks to model hand-object interaction. Public dataset such as [4] can be used for training and testing the proposed system. The project can inform real-world applications such as augmented reality/virtual reality. |
| - | - |
| Reference URLs | <br>[1] https://bit.ly/3bjGWbG<br><br>[2] https://bit.ly/3uJoyAC<br><br>[3] https://bit.ly/3uK83UG<br><br>[4] https://epic-kitchens.github.io/2021 |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for hand-object interaction in egocentric video. There are opportunities for scientific publications with positive results. |
| Requirements | Background in computer vision and deep learning, experience in programming such as Python with PyTorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Deep learning, computer vision, hand gesture, object detection, interaction |
| Interview Required | No |

### HS-7: Deep Learning Based Machine Vision for Space Imagery

| Description | Machine vision and deep learning techniques offer immense potential for classifying and tracking objects in space using images captured by telescopes. In the context of space awareness applications, i.e. monitoring space objects, these technologies allows automatically analysis and interpretation the characteristics and trajectories of space objects. Considering the diverse range of these objects, such as stars, satellites, and even space debris, accurately classifying and tracking them is essential for ensuring space sustainability. This not only enhances our understanding of the space environment but also enables us to take proactive measures in managing and mitigating potential risks associated with space debris and other celestial bodies. It is therefore of interest to adapt existing image-based detection [1, 2] and tracking techniques [3, 4] onto telescope images, where objects are smaller but with different characteristics. |
| - | - |
| Reference URLs | [1] Redmon, J., Divvala, S., Girshick, R. and Farhadi, A., 2016. You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788).<br>[2] Ren, S., He, K., Girshick, R. and Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems, 28.<br>[3] Wojke, N., Bewley, A. and Paulus, D., 2017, September. Simple online and realtime tracking with a deep association metric. In 2017 IEEE international conference on image processing (ICIP) (pp. 3645-3649). IEEE.<br>[4] Bergmann, P., Meinhardt, T. and Leal-Taixe, L., 2019. Tracking without bells and whistles. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 941-951). |
| Anticipated Outcomes | The main outcome will be a piece of software that implements a deep learning network for space imagery classification, detection and/or tracking. There are opportunities for scientific publications with positive results. |
| Requirements | Background in computer vision and deep learning, experience in programming such as Python with PyTorch. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Deep learning, computer vision, classification, detection, tracking |
| Interview Required | No |

### CS-1: An Enhanced Tutor

| Description | This project will involve the use of AI to inform an 'enhanced' digital tutor. Educational systems generally focus on a closed corpus of information as set by a teacher, the result of which is that the learner is limited by the teacher's own knowledge. Open Hypermedia Systems, are systems that remove this artificial boundary, but lessons made using such a system can be extremely broad and can lose their focus. This project will involve you to creating an AI system to identify the semantics and meaningful content for a lesson. The training data identified will need to create a critical friend (the enhanced tutor)) for the student in that lesson. |
| - | - |
| Reference URLs | (1) Luckin, R., & Cukurova, M. (2019). Designing educational technologies in the age of AI: A learning sciences' driven approach. British Journal of Educational Technology, 50(6), 2824-2838. (2) SomyÃ¼rek, Sibel. (2015). The New Trends in Adaptive Educational Hypermedia Systems. International Review of Research in Open and Distance Learning. 16. 221-241. 10.19173/irrodl.v16i1.1946. |
| Anticipated Outcomes | A Proof of Concept for the enhanced tutor which can deliver (or support delivery of) a lesson in a given subject topic. The topic content needs to be gathered from an Open corpus of data. |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### CS-2: Developing a collaborative intelligence with the EThOS collection of the British Library - HCI focus

| Description | This project will examine the EThOS repository, which contains over 500,000 theses many containing unique, unreported research findings. For example: ageing generates 24,779 theses, migration generates 6857 theses and homelessness generates 279 theses. The project will build on extant software which utilises unsupervised machine learning models (such as Clustering and Natural Language Processing). The focus will be on visualisation of the results, via clustering and/ or textual thematic foci as well as other front end usability enhancements. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | The project will trial the development of a dashboard or hub which will visualise analysis using search strings and will more accurately draw together theses in accessible formats. |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### CS-3: VR Knowledge village

| Description | This project aims to utilise current VR (or AR) technologies to build an interactive and expansive visualisation of an individuals knowledge-scape. By collecting data from the learner and adopting gamification methodologies the goal is to use this information to procedurally generate an engaging representation of their knowledge base. This can then be interrogated for revision or expanded through targeting knowledge acquisition. The project can be expanded to consider more personal data as required to enhance engagement. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | A VR application that allows for a user to explore their own knowledge base in an engaging visual manner. |
| Requirements | Knowledge of VR programming and asset generation techniques (e.g. Unity and Blender) |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### CS-4: Tamagotchi: from egg to avatar

| Description | Novel interaction mechanisms & modalities are being enabled with the creation of more immersive and ubiquitous Augmented Reality interfaces. AR avatars are already being created for to support exploration of an augmented world. This project seeks to explore the current state of the art from a UX, HCI and affective computing point of view. Issues such as visualisation, personalisation (for example through the use of the Watson Personality Insights service), development, and security will need to be addressed. |
| - | - |
| Reference URLs | Yoon, B., Kim, H. I., Lee, G. A., Billinqhurst, M., & Woo, W. (2019, March). The Effect of Avatar Appearance on Social Presence in an Augmented Reality Remote Collaboration. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR) (pp. 547-556). IEEE. |
| Anticipated Outcomes | The output will be an extension of the research into best practice validated via the creation of an augmented â€˜petâ€™ that the user can interact with constantly. |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### CS-5: Cultural Artefacts in eLearning

| Description | This project will examine an extant system of adaptive interfaces which caters for cultural diversity in education, instead of presenting a homogeneous delivery for the whole student population. The project will utilise an eLearning system based on the framework for cultural adaptation, CAE (Cultural Artefacts in Education), grounded in Marcus & Gould's web model, as well as its source, Hofstede's indexes. This system will be expanded to implement the CAE-F ontology as well as expanding these cultural personalisation aspects using the Watson Personality Insights service. |
| - | - |
| Reference URLs | Scotton, J., Stewart, C., & Cristea, A. I. (2011). ADE: the adaptive display environment for adaptive hypermedia. In Proceedings of the ACM Hypertext 2011 International Conference, Eindhoven, The Netherlands (pp. 2269-2295). |
| Anticipated Outcomes | Updated and expanded eLearning system (ADE+CAE) |
| Requirements |  |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### IAS-1: Meta-heuristics for colouring graphs and colouring decentralized networks

| Description | Graph colouring is a fundamental problem in Computer Science and is often mentioned as an archetypal NP-hard problem. It has many applications including register allocation, timetabling, frequency assignment and scheduling. The importance of graph colouring means that there have been a wide range of meta-heuristic algorithms developed so as to quickly secure good, if not optimal, colourings of graphs. Meta-heuristic methodologies employed have included greedy approaches, tabu search, ant colony optimization, chaotic ant swarm, honey bee optimization, firefly algorithms and many others.<br><br>This theme can support two projects. <br><br>The first project concerns decentralized networks whereby any node of the underlying graph only has local knowledge of itself and (the colours of) its neighbours. Decentralized colouring has applications in wireless sensor networks, where each sensor node only has local network knowledge in relation to control, distributed resource management, wireless channel allocation and wakeup scheduling. A decentralized colouring algorithm, called SDGC, is developed in [1] which can operate either synchronously (where all nodes update their colours at the same time) or asynchronously (where nodes update their colours at different times). In [1], the algorithm SDGC is empirically compared with another distributed graph colouring algorithm called FrogSim from [2] on a range of benchmark data-sets. This project is to replicate the research in [1] and to possibly extend it.<br>The second project is to implement a range of meta-heuristic algorithms from the recent research literature and empirically compare them on the same platform. A starting point for a literature review is the recent survey on meta-heuristic approaches to graph colouring [3].<br><br> |
| - | - |
| Reference URLs | <br><br>S.V. Galán, Simple decentralized graph coloring, Computational Optimization and Applications 66 (2017) 163-185 (URL: https://doi.org/10.1007/s10589-016-9862-9)<br>H. Hernández and C. Blum, FrogSim: distributed graph coloring in wireless ad hoc networks, Telecommunication Systems 55 (2014) 211-223 (https://doi.org/10.1007/s11235-013-9776-0)<br>T. Mostafaie, F.M. Khiyabani and N.J. Navimipour, A systematic study on meta-heuristic approaches for solving the graph coloring problem, Computers and Operations Research 120 (2020) 104850 (https://doi.org/10.1016/j.cor.2019.104850)<br><br> |
| Anticipated Outcomes | <br>For the first project, the primary aim is to confirm (or dispute) the empirical performance claims in [1]. The research in [1] can be extended by implementing other colouring algorithms for decentralized networks or undertaking extended experimentation on more refined data-sets, with an added bonus being finding a new algorithm that improves upon the state-of-the-art.<br>This project is suitable for Level 3 or Level 4 students but possibly best suited to Level 3 students. It can support at most 1 student.<br>For the second project, the primary aim is to confirm (or dispute) empirical performance claims in the research literature as regards meta-heuristic approaches to graph colouring. This will involve implementing a suite of meta-heuristic graph colouring algorithms and experimenting with them on benchmark and self-generated data. The algorithms chosen should include those from a specific paper so that the results of that paper can be evaluated in full. An added bonus would be the implementation of other previously unimplemented meta-heuristic algorithms for the graph colouring problem along with a thorough empirical evaluation, with the ultimate success being the discovery of an implementation that out-performs the state-of-the-art.<br>This project is suitable for Level 3 or Level 4 students but possibly best suited to Level 4 students as there is more scope for implementing a range of algorithms, originality and breadth of experimentation, e.g., as described as an "added bonus" above. It can support at most 2 students so long as the algorithms implemented by these students are different.<br>A necessary precursor to this project is an extensive literature survey so as to highlight a range of graph colouring algorithms that might be implemented, so that the state-of-the-art can be best reflected.<br> |
| Requirements | There are no special requirements beyond a basic understanding of algorithmic graph theory and meta-heuristic algorithms (such as those studied in the Level 2 AI Search sub-module or the Level 3 Natural Computing Algorithms module). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | meta-heuristic algorithms; graph theory; graph colouring; distributed graph colouring |
| Interview Required | No |

### IAS-2: Meta-heuristics for computing dominating sets in graphs

| Description | A dominating set in a graph is a subset D of vertices such that each vertex in the graph is in D or has a neighbour in D. Dominating sets and their variants have applications in many areas including routing in wireless ad-hoc networks, multi-document summarisation or modelling and studying positive influence in social networks. Finding a minimum dominating set in a graph is NP-hard and so meta-heuristic methods are called for.<br><br>This project is to implement a range of meta-heuristic algorithms in order to solve the dominating set problem and to compare and evaluate them on benchmark and other data. References [1-3] give a selection of existing implementations and form the starting point for a literature review. |
| - | - |
| Reference URLs | <br>D. Chalupa, An order-based algorithm for minimum dominating set with application in graph mining, Information Sciences 426 (2018) 101-116 (https://doi.org/10.1016/j.ins.2017.10.033)<br>A. Potluri and A. Singh, Hybrid metaheuristic algorithms for minimum weight dominating set, Applied Soft Computing 13 (2013) 76-88 (https://doi.org/10.1016/j.asoc.2012.07.009)<br>L.A. Sanchis, Experimental analysis of heuristic algorithms for the dominating set problem, Algorithmica 33 (2002) 3-18 (https://doi.org/10.1007/s00453-001-0101-z)<br> |
| Anticipated Outcomes | The primary project aim is to confirm (or dispute) empirical performance claims in the research literature as regards meta-heuristic approaches to solving the dominating set problem (or some variant). This will involve implementing a suite of meta-heuristic dominating set algorithms and experimenting with them on benchmark and self-generated data. The algorithms chosen should include those from a specific paper so that the results of that paper can be evaluated in full. An added bonus would be the implementation of other previously unimplemented meta-heuristic algorithms for the dominating set problem along with a thorough empirical evaluation, with the ultimate success being the discovery of an implementation that out-performs the state-of-the-art. <br><br>This project is suitable for both Level 3 or Level 4 students but is possibly best suited to Level 4 students as there is more scope for implementing a range of algorithms, originality and breadth of experimentation, e.g., as described as an "added bonus" above. The project can support 2 students in total but so long as the algorithms implemented by these students are different.<br><br>A necessary precursor to this project is an extensive literature survey so as to highlight a range of dominating set algorithms that might be implemented, so that the state-of-the-art can be best reflected. |
| Requirements | There are no special requirements beyond a basic understanding of algorithmic graph theory and meta-heuristic algorithms (such as those studied in the Level 2 AI Search sub-module or the Level 3 Natural Computing Algorithms module). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | meta-heuristic algorithms; graph theory; dominating sets |
| Interview Required | No |

### IAS-3: Programming matter to shape-shift

| Description | A recent model of computation, forming part of a new research area known as programmable matter, has been developed whereby the computational goal is to transform a shape on a two-dimensional grid to another shape via a sequence of fundamental operations. In more detail, a shape is a placement of nodes in the cells of a two-dimensional grid and allowable fundamental moves include: rotations, whereby a node rotates 90 degrees clockwise or anti-clockwise around a node in an adjacent grid cell, so long as the cells rotated through and into are empty; and slides, whereby a node in one cell slides into an adjacent cell so long as both cells have nodes in adjacent cells so that these adjacent cells are themselves adjacent. The reference [3] contains full details of the progammable matter model. The basic model has been extended so as to allow additional line-push moves and also so that moves can be made in parallel (references [1] and [2] build upon [3]). Consequently, a computation is a sequence of moves transforming one shape into another and has the potential be visualized.<br><br>The primary aim of this project is to develop a simulator so that given two shapes A and B, the simulator will compute a sequence of moves that transform A into B and then show these moves in action via some visual representation. While the simulation should be relatively straightforward, computing the actual sequence of moves is more demanding. Deterministic methods in some models and for some shapes exist but things become more complicated in extended models and for more complex shapes; consequently, heuristic methods might be employable. A secondary aim of the project is to extend the models considered so far and develop both theoretical results for any new models and also the simulator so that computations in new models can be visualized. Extensions might be, for example, the introduction of a new fundamental move, the consideration of basic models within a three-dimensional grid or the consideration of basic models on a specific graph rather than on a two-dimensional grid. |
| - | - |
| Reference URLs | <br>A. Almethen, O. Michail and I. Potapov, Pushing lines helps: Efficient universal centralised transformations for programmable matter, Theoretical Computer Science 830-831 (2020) 43-59 (https://doi.org/10.1016/j.tcs.2020.04.026)<br>A. Almethen, O. Michail and I. Potapov, On efficient connectivity-preserving transformations in a grid, Theoretical Computer Science 898 (2022) 132-148 (https://doi.org/10.1016/j.tcs.2021.11.004)<br>O. Michail, G. Skretas and P.G. Spirakis, On the transformation capability of feasible mechanisms for programmable matter, Journal of Computer and System Sciences 102 (2019) 18-39 (https://doi.org/10.1016/j.jcss.2018.12.001)<br> |
| Anticipated Outcomes | As stated, it is expected that the basic outcome will be a simulator capable of simulating and visualizing shape-shifting computations. However, the underlying shape-shifting algorithms could be quite demanding to develop. The secondary aims, in terms of new theory, are even more demanding. Consequently, this project is only suitable for students who are ambitious and who have strong theoretical computer science skills. <br><br>The project is available to both Level 3 and Level 4 students but perhaps is best suited to a Level 4 student (and especially one who has done the Level 3 module Natural Computing Algorithms although this is not a necessary prerequisite). The project can support 1 student in total.<br> |
| Requirements | Strong theoretical and algorithmic skills are required. Note that the basic model above is studied in two lectures of the Level 3 module Natural Computing Algorithms (but not until the end of the first term). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | programmable matter; algorithms; theoretical computer science |
| Interview Required | Yes |

### IAS-4: Solving reconfiguration problems using meta-heuristic methods

| Description | A reconfiguration graph is, roughly speaking, a graph obtained from the feasible solutions to some problem on some fixed structure. For example, take a graph G and consider all the proper colourings of its vertices using 4 colours (so that two adjacent vertices have different colours). The corresponding reconfiguration graph has a vertex for every 4-colouring of G and there is an edge joining two 4-colourings if the colourings are identical except for 1 vertex. Alternatively, the reconfiguration graph of Rubik's cube has a vertex for every setting of Rubik's cube and there is an edge joining two settings if one can be obtained from the other by a single twist of the cube. The study of reconfiguration graphs that emerge in this way is currently an active topic of research.<br><br>Here are some typical results in relation to reconfiguration graphs. Consider the problem of deciding whether given two vertices in a reconfiguration graph (with respect to some problem), there is a path in the reconfiguration graph from one vertex to the other, i.e., the reachability problem. It has been proven that the reachability problem for reconfiguration graphs of 4-colourings of a graph is PSPACE-complete, whereas the reachability problem for reconfiguration graphs of 3-colourings of a graph is solvable in polynomial-time. Consider the problem of computing the diameter of some reconfiguration graph (if it is connected). It has been shown that in the 3-colouring reconfiguration graph of some graph G, the diameter of each connected component is O(\|V(G)\|2) but that in the 4-colouring reconfiguration graph of some graph G, the diameter of each connected component can be super-polynomial in \|V(G)\|.<br><br>This project is to investigate the use of meta-heuristic methods to answer questions as regards reconfiguration graphs. There exist similar concepts to reconfiguration graphs such as token swapping graphs and sorting networks which can form the basis for similar studies. All details of basic concepts and numerous recent results are given in [3] whereas [2] focusses more on sorting networks. A web survey [1] provides access to lots of papers on reconfiguration problems. |
| - | - |
| Reference URLs | <br>T. Ito and A. Suzuki, Web Survey on Combinatorial Reconfiguration (http://www.ecei.tohoku.ac.jp/alg/coresurvey)<br>D. Kim, Sorting on graphs by adjacent swaps using permutation groups, Computer Science Review 22 (2016) 89-105 (https://doi.org/10.1016/j.cosrev.2016.09.003)<br>N. Nishimura, Introduction to reconfiguration, Algorithms 11(4) (2018) article 52 (https://doi.org/10.3390/a11040052)<br> |
| Anticipated Outcomes | There is massive scope within this project as there are so many different basic problems to consider and also properties of reconfiguration graphs, token swapping networks and sorting networks to establish. Any chosen project should look to contribute useful information to those interested in this general research area, e.g., although we can have super-polynomial diameter 4-colouring reconfiguration graphs (as described above), can we obtain experimental evidence that shows that if we concern ourselves only with some restricted class of graphs then the diameter is much less? Also, in so far as I am aware, there has been no research undertaken so far on obtaining practical algorithms to solve hard problems in relation to reconfiguration graph problems, e.g., although, as stated above, the reachability problem for reconfiguration graphs of 4-colourings of a graph is PSPACE-complete, no-one has yet explored finding an efficient algorithm that provides solutions a lot of the time. As this project sits close to current research, it is only suitable for students who are ambitious and who have strong theoretical computer science skills.<br><br>The project is available to both Level 3 and Level 4 students but perhaps is best suited to a Level 4 student. The project can support 1 student in total.<br> |
| Requirements | Strong theoretical and algorithmic skills are required. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | meta-heuristic methods; reconfiguration problems; token swapping; sorting networks |
| Interview Required | Yes |

### IAS-5: Community detection in large-scale social networks

| Description | Social networks are often described using graphs where the nodes are individuals of the social network and the edges (possibly with weights) denote relationships between individuals. Given a social network, a fundamental task is to detect communities within the network; that is, meaningful sub-structures within the network. Often, each pair of individuals have a degree of similarity where there are various notions of similarity. One notion is the Jaccard index which for any two individuals x and y, is defined as the number of common neighbours of x and y divided by the number of nodes that are neighbours of either x and y. An aim is to find a partition of the nodes of the social network into disjoint communities so that some weight function involving node similarities is maximized or minimized.<br>This project is to undertake a comparative evaluation of community detection algorithms in the research literature. A starting point is the paper [1] which includes a genetic algorithm for community detection that is empirically compared with other algorithms. The paper [3] develops another (modified) genetic algorithm for community detection whereas [2] uses community detection algorithms to predict link evolution in social networks. |
| - | - |
| Reference URLs | <br>R.K. Behera, D. Naik, S.K. Rath and R. Dharavath, Genetic algorithm-based community detection in large-scale social networks, Neural Computing and Applications 32 (2020) 9649–9665 (https://doi.org/10.1007/s00521-019-04487-0)<br>A. Kumari, R.K. Behera, B. Sahoo and S.P. Sahoo, Prediction of link evolution using community detection in social network, Computing 104 (2022) 1077-1098 (https://doi.org/10.1007/s00607-021-01035-4)<br>H.K. Shakya, K. Singh, Y.S. More and B. Biswas, Opposition-based genetic algorithm for community detection in social networks, Proceedings of the National Academy of Sciences, India Section A: Physical Sciences 92 (2022) 251-263 (https://doi.org/10.1007/s40010-020-00716-7)<br> |
| Anticipated Outcomes | The primary project aim is to confirm (or dispute) empirical performance claims in the research literature as regards community detection algorithms for social networks. This will involve implementing a suite of community detection algorithms and experimenting with them on benchmark and self-generated data. The algorithms chosen should include those from a specific paper so that the results of that paper can be evaluated in full. An added bonus would be the implementation of other previously unimplemented community detection algorithms along with a thorough empirical evaluation, with the ultimate success being the discovery of an implementation that out-performs the state-of-the-art.<br>This project is suitable for Level 3 or Level 4 students but possibly best suited to Level 3 students. It can support at most 1 student in total.<br>A necessary precursor to this project is an extensive literature survey so as to highlight a range of community detection algorithms that might be implemented, so that the state-of-the-art can be best reflected. In this context, the paper [1] should be critically evaluated as it would appear that comparison is only undertaken with community detection algorithms from 2002-2011 which is possibly not the state-of-the-art. |
| Requirements | There are no special requirements beyond a basic understanding of algorithmic graph theory and meta-heuristic algorithms (such as those studied in the Level 2 AI Search sub-module or the Level 3 Natural Computing Algorithms module). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | social networks; community detection; similarity indices; meta-heuristic algorithms |
| Interview Required | No |

### IAS-6: Embedding virtual machines in data centre networks

| Description | Data centre providers rent out portions of their data centres to users. This involves embedding the users' virtual machines within the data centre network (DCN) so as to secure quality-of-service guarantees. Virtual machines often come in the form of virtual networks with a basic "star" graph forming a common such network (where a central "root" switch is connected directly to a number of "leaf" servers). The data centre provider wants to embed as many virtual networks as possible so as to optimize revenue but so that quality-of-service guarantees can be met. The basic virtualization problem can be abstracted as a graph embedding problem where the graphs have weights (reflecting numerical parameters of the underlying networks). Two illustrative existing virtualization methodologies are Oktopus [1] and SecondNet [2].<br>Server-centric DCNs have been proposed as a paradigm to support the next generation of DCNs as there are problems regarding, for example, scalability for the switch-centric DCNs that form the current paradigm of production DCNs. Unfortunately, Oktopus and SecondNet cater only for switch-centric DCNs. However, a virtualization methodology for server-centric DCNs has been sketched in [3]. This project would be to flesh out the sketch in [3] and develop a tool to enable virtualization in server-centric DCNs. |
| - | - |
| Reference URLs | <br>H. Ballani, P. Costa, T. Karagiannis and A. Rowstron, Towards predictable datacenter networks, Proc. of ACM SIGCOMM (2011) 242-253 (https://doi.org/10.1145/2018436.2018465)<br>C. Guo, G. Lu, H.J. Wang, S. Yang, C. Kong, P. Sun, W. Wu and Y. Zhang, SecondNet: a data center network virtualization architecture with bandwidth guarantees, Proc. of ACM Conf. on Emerging Networking Experimentsand Technology article no. 15 (12 pages), 2010 (https://doi.org/10.1145/1921168.1921188)<br>I.A. Stewart and A. Erickson, The influence of data center usage on symmetry in data center network design, Journal of Supercomputing 74 (2018) 2276-2313.(https://doi.org/10.1007/s11227-017-2217-1)<br> |
| Anticipated Outcomes | Outcomes might include: an implementation of the virtualization methodology in [3] for the DCNs HCN and BCN, as described in [3]; a more general tool which will allow the virtualization methodology of [3] to be applied to other DCNs; adaptions of Oktopus and SecondNet to server-centric DCNs; and experimentation with a more general tool so as to evaluate server-centric DCNs with respect to their capacity for virtualization. This will be a challenging project and will involve initially extending the description of the virtualization methodology in [3] prior to implementation; consequently, it is only available to students with strong algorithmic and graph theory skills. However, it is highly possible that a successful project might lead to publication; moreover, there is lots of scope to make a contribution.<br>This project is suitable for Level 4 students only and can support at most 1 student. |
| Requirements | As mentioned above, DCNs are abstracted as graphs and consequently basic knowledge of and interest in algorithmic graph theory is required, as well as good programming skills. |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | server-centric data centre networks, virtualization, graph embeddings |
| Interview Required | Yes |

### IAS-7: Solving the Travelling Salesperson Problem using meta-heuristics

| Description | In [1], a relatively new nature-inspired meta-heuristic algorithm known as the Komodo Mlipir Algorithm (KMA) from [2] was applied to solve the TSP. The KMA algorithm is inspired by the behaviour of Komodo dragons and the Javanese gait known as mlipir. The performance of the resulting implementation, referred to as DKA in [1], was compared with simulated annealing (SA), ant colony optimisation (ACO), artificial bee colony (ABC), hierarchic approach (HA), discrete state transition algorithm (DSTA), black hole algorithm (BH) and discrete jaya algorithm (DJAYA). The primary project aim is to replicate, and hopefully validate, the experimental results in [1]. |
| - | - |
| Reference URLs | <br>G.K. Jati, G. Kuwanto, T. Hashmi and H. Widjaja, Discrete komodo algorithm for traveling salesman problem, Applied Soft Computing 139 (2023) 110219 (https://doi.org/10.1016/j.asoc.2023.110219)<br>S. Suyanto, A.A. Ariyanto and A.F. Ariyanto, Komodo Mlipir Algorithm, Applied Soft Computing 114 (2022) 108043 (https://doi.org/10.1016/j.asoc.2021.108043)<br> |
| Anticipated Outcomes | The primary project aim is to confirm (or dispute) empirical performance claims in [1]. This will involve implementing a suite of TSP algorithms (as described above) and experimenting with them on benchmark and self-generated data. An added bonus would be the implementation of other meta-heuristic TSP algorithms along with a thorough empirical evaluation, with the ultimate success being the discovery of an implementation that out-performs the algorithm DKA from [1].<br>This project is suitable for Level 3 students. It can support at most 1 student.<br>Given the massive number of available meta-heuristic algorithms in the literature, the breadth of the experiments in [1] is shallow. An expected circumstance might be there exist better TSP algorithms already in the literature in comparison to the algorithm DKA. |
| Requirements | There are no special requirements beyond a basic understanding of algorithmic graph theory and meta-heuristic algorithms (such as those studied in the Level 2 AI Search sub-module or the Level 3 Natural Computing Algorithms module). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | meta-heuristic algorithms; graph theory; Travelling Salesperson Problem (TSP) |
| Interview Required | No |

### IAS-8: Applying meta-heuristic methods to solve hard problems

| Description | [This is a general theme under which individual projects can be developed with Professor Stewart. For some concrete versions of such projects, see other projects of Professor Stewart.]<br><br>Computationally hard problems, usually defined as those problems the solution of which is NP-hard, cannot be efficiently solved exactly unless P = NP. Many of them are, or involve, combinatorial optimization problems where we are looking to find the minimum or maximum value of some property, e.g., the graph colourability problem, the graph independent set problem, the travelling salesman problem, the knapsack problem, the longest path in a graph problem, and so on. In practice, we generally work with meta-heuristic algorithms that efficiently yield approximate but decent solutions and work pretty well a lot of the time.<br><br>There is a vaste range of meta-heuristic algorithms available many of which are inspired by nature, e.g., genetic algorithms, ant colony optimization, particle swarm algorithms, artificial bee colony algorithms, cuckoo search, firefly algorithms, ...: the list is very long (some of these algorithms are listed http://fcampelo.github.io/EC-Bestiary/). These meta-heuristic algorithms have been applied to solve many applied problems across computer science and engineering.<br><br>For a project within this theme, a student should find a (recent) paper in a journal or conference and meet with Professor Stewart to discuss a possible project based around the paper. At the least, the project would be to implement the algorithms within the paper and replicate the results obtained. An added bonus would be the implementation of a previously unimplemented algorithm that out-performs the state-of-the-art. However, the aims of any project will ultimately depend upon the paper and the context.<br><br>The above might sound straightforward but things are always more complicated than they sound. For example: sometimes involved theory needs to be comprehended so as to understand an algorithm; sometimes a paper might not be well written and might be vague (or even incomprehensible) as regards key issues; sometimes data-sets from the paper might not be readily available; and so on. But there is always plenty of scope to dig deep into a topic and work near the boundaries of current research.<br><br>For a project within this theme, a student should find a (relatively recent) paper in a journal or conference proceedings and meet with Professor Stewart to discuss a possible project around the paper. Professor Stewart can give guidance as to where such a paper might be found but some obvious starting points are the journals https://www.springer.com/journal/500?gclid=EAIaIQobChMIs4aA3-i__wIVRMTtCh1CHQBfEAAYASAAEgIgS_D_BwE and https://www.sciencedirect.com/journal/applied-soft-computing, in which applications of meta-heuristic algorithms often occur, and to a lesser extent the journals https://ieeeaccess.ieee.org/ and https://www.sciencedirect.com/journal/expert-systems-with-applications. Of course, suitable papers might be found in other journals and conference proceedings and https://scholar.google.co.uk/schhp?hl=en&as_sdt=0,5, https://www.sciencedirect.com/ and https://ieeexplore.ieee.org/Xplore/home.jsp are valuable aids. |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | The primary project aim is to confirm (or dispute) empirical performance claims in the research literature as regards some application(s) of meta-heuristic algorithms. This will involve implementing a suite of algorithms and experimenting with them on benchmark and self-generated data. The algorithms chosen should include those from a specific paper so that the results of that paper can be evaluated in full. An added bonus would be the implementation of other previously unimplemented meta-heuristic algorithms along with a thorough empirical evaluation, with the ultimate success being the discovery of an implementation that out-performs the state-of-the-art.<br>This project is suitable for Level 3 or Level 4 students and can support up to 5 students from each level; so, a total of 10 students.<br>A necessary precursor to the project is a proper literature survey so as to highlight a range of community detection algorithms that might be implemented, so that the state-of-the-art can be best reflected. |
| Requirements | There are no special requirements beyond a basic understanding of meta-heuristic algorithms (such as those studied in the Level 2 AI Search sub-module or the Level 3 Natural Computing Algorithms module). |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | meta-heuristic algorithms |
| Interview Required | Yes |

### DS-1: Named Entity Disambiguation using Knowledge Graphs

| Description | Named Entity Disambiguation is an important task in Natural Language Processing, associating strings in a document (e.g. 'London') with particular entities in a knowledge base (e.g. representing London (the city in the UK), vs London (the city in Ontario)). Graph-based approaches - often based on linking patterns extracted from large publicly available systems such as Wikipedia - have recently been shown to be effective in performing this task. This project would involve implementing and evaluating the procedures described in the papers referenced below, and/or extending these to include additional information not directly accounted for in knowledge graphs based purely on link structure, such as geographical and temporal information. |
| - | - |
| Reference URLs | https://aclweb.org/anthology/papers/K/K16/K16-1025/<br>https://www.aclweb.org/anthology/N15-1026 |
| Anticipated Outcomes | Implementation and evaluation of existing methods with possible further development. |
| Requirements | Interest in Natural Language Processing. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | NLP; NER; NED |
| Interview Required | No |

### DS-2: OCR Post-correction through Text Reuse Identification

| Description | In certain domains - such as historical written and printed works - Optical Character Recognition involves recognition of multiple documents whose contents are not identical, but nevertheless contain high degrees of overlap. This property can potentially be leveraged to greatly increase recognition accuracy as a post-correction task by identifying and aligning similar sections of text, then using these alignments to infer and correct probable errors. The goal of this project is to develop and evaluate the effectiveness of this approach. |
| - | - |
| Reference URLs | http://www.ccs.neu.edu/home/dasmith/infect-bighum-2013.pdf<br>http://www.ep.liu.se/ecp/133/010/ecp17133010.pdf |
| Anticipated Outcomes | Development and evaluation of techniques against a baseline, and a tool to perform unsupervised post-correction on arbitrary collections of OCR output. |
| Requirements | Interest in Natural Language Processing |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | NLP; OCR |
| Interview Required | No |

### DS-3: Interactive analysis and visualisation of TEI documents

| Description | In humanities computing, an XML format maintained by the Text Encoding Initiative (TEI) provides a standard mechanism for representing written materials - such as historical documents - together with a wide variety of associated metadata and semantic annotation. Due to the complexity of the standard and substantial degree of freedom in how texts are marked up in accordance with it, processing materials originating from arbitrary sources is non-trivial.<br><br>This project implements a web-based user interface for displaying and navigating arbitrary TEI encoded texts, and producing and appropriately visualising summary data relevant to the data present in the chosen texts. The interface may also provide editing functionality to modify or refactor TEI documents. |
| - | - |
| Reference URLs | https://teibyexample.org/<br>https://wiki.tei-c.org/index.php/Samples_of_TEI_texts<br>https://academic.oup.com/dsh/article/24/3/281/968658 |
| Anticipated Outcomes | Software to interactively present and analyze arbitary TEI texts. |
| Requirements | Familiarity with Javascript; interest in visualisation. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Text processing, digital humanities, visualization |
| Interview Required | No |

### DS-4: Using character compositionality to improve Chinese NER

| Description | Named Entity Recognition (NER) is an important task in natural language processing. In contrast to alphabetic languages like English, Chinese is written using a large number of distinct character types, many of which are composed of subcomponents which convey some degree of semantic content. In addition, written Chinese does not use spaces or other delimiters to explicitly indicate boundaries between words; together these factors present challenges and opportunities specific to Chinese NER.<br><br>This project involves implementing and evaluating approaches to the Chinese NER task, using conditional random fields and/or LSTM, incorporating information about character decomposition. |
| - | - |
| Reference URLs | https://arxiv.org/pdf/1910.11470.pdf<br>http://ir.ia.ac.cn/bitstream/173211/19944/1/13%E8%91%A3%E4%BC%A0%E6%B5%B7Character-Based%20LSTM-CRF%20with%20Radical-Level%20Features%20for%20Chinese%20Named%20Entity%20Recognition.pdf |
| Anticipated Outcomes | Implementation and evaluation of NER system using character compositionality. |
| Requirements | Machine learning and/or deep learning; interest in natural language processing. |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Chinese; NER; NLP |
| Interview Required | No |

### DS-5: Unsupervised authorship clustering

| Description | Unsupervised clustering of written materials by probable author has many applications, both historical (e.g. in premodern literature where authorship and authors are often unknown or disputed) and contemporary (e.g. connecting authors of multiple pieces of user-generated content, such as online reviews or social media posts).<br><br>This project will implement and evaluate multiple strategies for linking and clustering documents by authorship. It may involve reproducing and supplementiing the results of the paper by Kocher and Savoy (linked below), e.g. by evaluation on additional domains, using a wider range of natural languages than the two used in that paper, and/or developing and evaluating additional metrics of authorship similarity. |
| - | - |
| Reference URLs | https://academic.oup.com/dsh/article/34/1/189/5032370<br>https://petsymposium.org/2012/papers/hotpets12-6-yelp.pdf |
| Anticipated Outcomes | Implementing a system for evaluating a range of authorship clustering algorithms; evaluation of these across a range of corpora and natural languages. |
| Requirements | Familiarity with machine learning; interest in natural language processing |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | NLP, digital humanities, authorship |
| Interview Required | No |

### AT-1: Exploring and Simulating Network  Distributed Algorithms

| Description | Network Distributed Algorithms are algorithms run by individual nodes in a network purely by sending messages to each other (message passing). The network itself is naturally modelled by a graph where vertices are network nodes and edges are connections between the nodes. The aims of this project are:<br><br> 1)  Study some distributed algorithms of your choice (See below).<br> 2) Build a network simulator (by modelling the Network as a graph and simulating the message passing),<br>3)  Run experiments, measure, gather statistics, and gain (hopefully, surprising) insights.<br><br>Some Algorithms to concentrate on maybe from the following (the simulator should hopefully be able to run any distributed algorithm but it may take time to understand the algorithms if new to the field):<br><br>- Leader Election<br>- Amnesiac Flooding<br>- Self-Healing Algorithms (Needs capability to add/delete edges - models Peer-to-Peer Networks)<br>- Classic graph problems such as graph colouring, MIS  etc |
| - | - |
| Reference URLs | (See Dr. Trehan's DBLP for references: https://dblp.org/pid/68/3831.html) <br><br>Some examples:<br><br>Leader Election:<br>  - https://doi.org/10.1145/2699440<br>-   https://www.sciencedirect.com/science/article/pii/S0304397514001029<br>- https://www.semanticscholar.org/paper/Time-Optimal-Leader-Election-in-General-Networks-Peleg/849d99e6b712b76ba1ccab3d1285462f688720f9<br><br><br>Amnesiac Flooding:<br> - https://drops.dagstuhl.de/opus/volltexte/2020/11878/<br> - https://arxiv.org/abs/2009.05776<br><br>Self-Healing Algorithms:<br>    - https://arxiv.org/abs/0802.3267<br>   - https://link.springer.com/article/10.1007/s00446-012-0160-1 |
| Anticipated Outcomes | - Network Simulator  in any programming language (should handle millions of nodes)<br>- Demonstrated understanding of algorithms<br>- Experiments, analysis and insights |
| Requirements | - Background study of algorithms and their analysis<br>- Programming skills |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Algorithms, Distributed Algorithms, Algorithm Analysis, Programming, Simulation, Network Experiments |
| Interview Required | No |

### AT-2: Improving Project Allocations: Software or Theory for the Matching Problem

| Description | Project allocations involve solving a complex matching problem over a few different dimensions involving student shortlists, staff loading, program requirements etc.  <br><br>The student can develop the project over either solving the theoretical questions and improving the algorithm for multi-criteria matching and/or creating a software to aid creating an automatic project allocation system requiring less manual intervention (if there are unresolvable conflicts requiring manual intervention, an easy interface to deal with those). |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | 1) Survey of the problem and existing solutions <br> <br>2a) Software  <br>  and/or <br>2b) (Mathematical options) Algorithm and mathematical foundations of the multi-constraint matching problem. |
| Requirements | -  Knowledge of computer algorithms and complexity analysis <br>- Algorithm formal analysis and/or Programming skills |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Matching, Project Allocations, Algorithm analysis, Programming |
| Interview Required | No |

### AT-3: Designing and Testing Self-healing Distributed and/or Compact routing Algorithms

| Description | Self-healing network algorithms are distributed algorithms that deal with resilience i.e. they suggest responses (e.g. adding new connections) on component/node failures (malicious or accidental). <br> <br>Networks are usually modeled as graph and graph theory and such mathematical techniques are used to analyse the algorithms and provide guarantees. A number of self-healing algorithms are available from the publications at http://dblp.uni-trier.de/pers/hd/t/Trehan:Amitabh  <br> <br>A related topic is Compact routing, Compact routing  algorithms are algorithms that attempt to have routing on a network using low (less then O(n)) memory on nodes by using other (such as topological) information. This is a very important area of research. A good reference is http://dl.acm.org/citation.cfm?id=378581 <br>The authors combine both fields in http://dl.acm.org/citation.cfm?doid=2833312.2833328 <br><br>A student working on this project will understand some of these works and propose new solutions and/or develop software to simulate and test some of the existing algorithms seeking to answer unresolved questions. |
| - | - |
| Reference URLs | http://dl.acm.org/citation.cfm?id=378581 <br>http://dblp.uni-trier.de/pers/hd/t/Trehan:Amitabh<br>http://dl.acm.org/citation.cfm?doid=2833312.2833328 |
| Anticipated Outcomes | New algorithms and/or Simulation/software showing performance of algorithms over a comprehensive set of scenarios |
| Requirements | - Knowledge of algorithms/network/distributed algorithms <br>- Algorithms analysis and/or Programming skills |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Distributed Algorithms, Network Algorithms, Algorithms analysis, Simulation, Self-healing, Routing, Graphs |
| Interview Required | No |

### AT-4: Characterising Equilibria of the EU Grant Games

| Description | In game theory, the game achieves an equilibria when the players involved are satisfied that they cannot improve their gains by playing a different stategy than they have played. <br> <br>In the paper 'Composition Games for Distributed Systems: The EU Grant Games' published in AAAI 2013 (available at https://goo.gl/mOcFHi ), the authors set up a hypothetical game which will help find the best group of researchers from a network of researchers to which a grant may be given. The 'quality' of the equilibria shows some dependence on the topology of the network e.g. if the network is a line or a complete graph.<br><br> In this project, the student will develop methods to test the game on various topologies and attempt to derive links between the topology and equilibria quality (as described in the paper), or further the theoretical aspects by looking at open problems in the context. |
| - | - |
| Reference URLs | https://goo.gl/mOcFHi |
| Anticipated Outcomes | - Software and experimental results on EU grant games <br><br> and/or<br><br>- Extensions to the EU grant game with analysis |
| Requirements | - Ability and willingness to use and learn game theory. <br>-Programming/Analytical skills |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Game Theory, Networks, Graphs, Analysis, Programming |
| Interview Required | No |

### WT-1: Wireless Multicast at the MAC Layer

| Description | In computer networking, multicast is a resource-efficient transmission method to distribute data to a group of coexisting receivers. However, with current networking standards and protocols, it is not trivial to implement multicasts in wireless networks. This project is to investigate a potential solution that can effectively implement wireless multicasting transmissions at the MAC layer. You will look into networking algorithms, machine learning algorithms, etc. to work out this potential solution. You will also evaluate the potential solution via experiments (say simulations). |
| - | - |
| Reference URLs |  |
| Anticipated Outcomes | A potentially feasible wireless multicast; simulation evaluation of this multicast method. |
| Requirements | Computer systems, Networks and Systems, C/C++, Python |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords |  |
| Interview Required | No |

### TV-1: Near-Insensitivity of occupancy-based load distribution policies in multi-server homogeneous systems

| Description | In datacenters and many other computer systems, it is important to process jobs with minimum waiting times or higher probability of getting service when they cannot wait. The main challenge is how to distribute jobs to severs for processing to achieve good performance. An optimal policy is the Join-the-shortest-queue (JSQ) policy under which an incoming job is assigned to the sever with the least number of jobs. For systems with large number of servers, JSQ has high implementation cost, therefore some low-complexity randomized algorithms were proposed. In this project we will simulate a multi-server system under several load balancing policies that use occupancy details (or the number of waiting jobs) of servers and compare their performance. We will study two types of systems, the first model is the processor-sharing systems (these models process jobs with minimum response time requirements like Youtube or Video calls) and the second type are Erlang loss systems which model call centers and telephone lines. We will particularly investigate near-insensitivity property which means only the average service times influence the performance, but the type of service time distributions does not affect the performance. This property was observed earlier for some policies but there is no thorough investigation of occupancy based policies. The main objective of this project is to investigate validity of near-insensitivity property for several occupancy based policies which was observed in [1] and [2] for processor sharing systems and [3] for Erlang loss systems.<br><br>[1] Varun Gupta, Mor Harchol Balter, Karl Sigman, Ward Whitt,``Analysis of join-the-shortest-queue routing for web server farms,” Performance Evaluation, Volume 64, Issues 9–12, 2007, Pages 1062-1081.<br>[2] T. Vasantam, A. Mukhopadhyay and R. R. Mazumdar, "Mean-Field Analysis of Loss Models with Mixed-Erlang Distributions under Power-of-d Routing," 2017 29th International Teletraffic Congress (ITC 29), Genoa, Italy, 2017, pp. 250-258, doi: 10.23919/ITC.2017.8064362.<br>[3] Thirupathaiah Vasantam, Arpan Mukhopadhyay, and Ravi R. Mazumdar. 2019. The Mean-field Behavior of Processor Sharing Systems with General Job Lengths Under the SQ(d) Policy. SIGMETRICS Perform. Eval. Rev. 46, 3 (December 2018), 54–55. <br><br>This project is suitable for either for L3 or L4 students who are interested in applying some probability methods in this project. There is a potential to come-up with new algorithms and study their performance as well. |
| - | - |
| Reference URLs | 1) https://www.sciencedirect.com/science/article/pii/S0166531607000624<br>2) https://ieeexplore.ieee.org/document/8064362<br>3) https://dl.acm.org/doi/10.1145/3308897.3308924 |
| Anticipated Outcomes | The student is expected to implement some prior and new load balancing algorithms, and obtain numerical results to characterize their performance. |
| Requirements | Networks and Systems, Data Science |
| Project Type | CS Level 3: ✅<br>CS Level 4: ✅ |
| Keywords | Servers, Queues, JSQ, Delay, Erlang |
| Interview Required | No |

### TV-2: An optimal load distribution policy for heterogeneous service systems

| Description | In service systems with multiple servers, a key challenge is to distribute incoming jobs to servers so as to achieve minimum delays. This is even more challenging when servers are heterogeneous, that is, when servers differ in their capabilities. Recently in [1] a modified version of the Join-the-shortest -queue (JSQ) was proposed and it has been shown to be an optimal scheme. In this project we will obtain some numerical results to confirm the results of [1]. We will also try to come-up with new schemes and compare their performance with the performance of the policy proposed in [1].<br><br>[1] Sanidhay Bhambay, Arpan Mukhopadhyay, ``Asymptotic optimality of speed-aware JSQ for heterogeneous service systems,” Performance Evaluation, Volumes 157–158, 2022.<br><br>This project is suitable for L4 students. The student should have an interest to learn and apply some probability based techniques. |
| - | - |
| Reference URLs | https://www.sciencedirect.com/science/article/pii/S0166531622000281 |
| Anticipated Outcomes | The student is expected to numerically study the algorithm proposed in the reference. There is also scope for proposing new algorithms and study their performance as well. |
| Requirements | Networks and Systems, Data Science, Design of Algorithms and Data Structures |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | JSQ, Delay, Job, Queue, Probability |
| Interview Required | No |

### TV-3: Finding Optimal Entanglement Distribution Policies for Quantum Networks Using MDPs

| Description | In many applications of quantum internet a key requirement is to distribute shared entanglements among users connected to a quantum network. We can create entanglements for users in two steps the first step is to create elementary or primary entanglements between neighbors and then in the second step we merge these elementary entanglements using swapping operations to obtain desired entanglements. Recently in [1] optimal policies were designed based on Markov decision processes (MDPs). The main objective of this project is to understand the results of [1] and obtain numerical results presented in [1].<br><br>This project is suitable for an L4 student who has some background on quantum computing (who has already taken either MATH3391 or MATH3111) and MDPs.<br><br><br>[1] Iñesta, Á.G., Vardoyan, G., Scavuzzo, L. et al. ``Optimal entanglement distribution policies in homogeneous repeater chains with cutoffs.” npj Quantum Inf 9, 46 (2023). https://doi.org/10.1038/s41534-023-00713- |
| - | - |
| Reference URLs | https://arxiv.org/abs/2207.06533 |
| Anticipated Outcomes | The student is expected to implement the protocols of the reference and obtain numerical results of this paper |
| Requirements | MATH3391 or MATH3111, Reinforcement Learning |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Quantum, Entanglement, MDP, Switch, Swapping |
| Interview Required | No |

### TV-4: Achieving Distance Independent Entanglement Rates in Quantum Networks

| Description | In many applications of quantum internet a key requirement is to distribute shared entanglements among users connected to a quantum network. We can create entanglements for users in two steps the first step is to create elementary or primary entanglements between neighbors and then in the second step we merge these elementary entanglements using swapping operations to obtain desired entanglements. Recently in [1] it was shown that it is possible to obtain entanglement distribution rates that do not depend on the distance between the users. This is only true for some network topologies and entanglement distribution protocols. In general, if the distance between users increases then entanglement distribution rate decreases. The main objective of this project is to understand the results of [1] and obtain numerical results presented in [1].<br><br>This project is suitable for an L4 student who has some background on quantum computing (who has already taken either MATH3391 or MATH3111).<br><br><br>[1] Patil, A., Pant, M., Englund, D. et al. ``Entanglement generation in a quantum network at distance-independent rate.” npj Quantum Inf 8, 51 (2022). https://doi.org/10.1038/s41534-022-00536-0 |
| - | - |
| Reference URLs | https://www.nature.com/articles/s41534-022-00536-0 |
| Anticipated Outcomes | The student is expected to obtain numerical results of the reference. |
| Requirements | MATH3391 or MATH3111, Networks and Systems |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Quantum, Entanglement, Switch, Swapping,Optical |
| Interview Required | No |

### TV-5: Energy Efficient Counting Rule for Detecting Adversaries in Wireless Sensor Networks

| Description | Wireless sensors are small devices that can be used to detect abnormal events in a given region of interest. In general, sensors collect data from their surroundings and then they send their data to fusion centers that decide the presence or absence of the abnormal activities. To minimize the energy consumption and bandwidth requirements sensors make their own local decisions that will be informed to the fusion center. The count of the local decisions of sensors in favor of the presence of abnormal activities will decide the decision of the fusion center, this method was studied in [2]. In [1], a modified version of the counting rule was analyzed, this method reduces the number of messages transferred by the sensors. The main aim of this project is to understand the results of [2] and obtain numerical results presented in [2]. There is also scope for proposing new methods and studying their performance.<br><br>This project is suitable for an L3 student.<br><br><br><br>[1] N. Sriranga, K. G. Nagananda, R. S. Blum, A. Saucan and P. K. Varshney, "Energy-Efficient Decision Fusion for Distributed Detection in Wireless Sensor Networks," 2018 21st International Conference on Information Fusion (FUSION), Cambridge, UK, 2018, pp. 1541-1547, doi: 10.23919/ICIF.2018.8454976.<br>[2] R. Niu and P.K. Varshney, "Performance analysis of distributed detection in a random sensor field", IEEE Trans. Signal Process., vol. 56, no. 1, pp. 339-349, Jan. 2008. |
| - | - |
| Reference URLs | 1)https://ieeexplore.ieee.org/document/8454976<br>2)https://dl.acm.org/doi/abs/10.1109/tsp.2007.906770 |
| Anticipated Outcomes | The student is expected to obtain numerical results confirming the results of the reference [1]. |
| Requirements | Data Science, Networks and Systems |
| Project Type | CS Level 3: ✅<br>CS Level 4: ❌ |
| Keywords | Energy, Sensor, Detection, Adversary, Fusion |
| Interview Required | No |

### TV-6: Robustness of the Counting Rule for Detecting Adversaries in Wireless Sensor Networks

| Description | Wireless sensors are small devices that can be used to detect abnormal events in a given region of interest. In general, sensors collect data from their surroundings and then they send their data to fusion centers that decide the presence or absence of the abnormal activities. To minimize the energy consumption and bandwidth requirements sensors make their own local decisions that will be informed to the fusion center. The count of the local decisions of sensors in favor of the presence of abnormal activities will decide the decision of the fusion center, this method was studied in [2]. In [1], a modified version of the counting rule was analyzed, this method reduces the number of messages transferred by the sensors. In [3] the impact of the uncertainties in parameters on the performance of the counting rule was studied. The main aim of this project is to understand the results of [2] and obtain numerical results presented in [2]. It is also expected that improvements to the counting rule should be proposed, and its performance should be better than the existing counting rule when some parameters of the model are unknown.<br><br>This project is suitable for an L4 student.<br><br><br>[1] N. Sriranga, K. G. Nagananda, R. S. Blum, A. Saucan and P. K. Varshney, "Energy-Efficient Decision Fusion for Distributed Detection in Wireless Sensor Networks," 2018 21st International Conference on Information Fusion (FUSION), Cambridge, UK, 2018, pp. 1541-1547, doi: 10.23919/ICIF.2018.8454976.<br>[2] R. Niu and P.K. Varshney, "Performance analysis of distributed detection in a random sensor field", IEEE Trans. Signal Process., vol. 56, no. 1, pp. 339-349, Jan. 2008.<br>[3] A. Goel, A. Patel, K. G. Nagananda and P. K. Varshney, "Robustness of the Counting Rule for Distributed Detection in Wireless Sensor Networks," in IEEE Signal Processing Letters, vol. 25, no. 8, pp. 1191-1195, Aug. 2018, doi: 10.1109/LSP.2018.2850529. |
| - | - |
| Reference URLs | https://ieeexplore.ieee.org/document/8454976<br>https://dl.acm.org/doi/abs/10.1109/tsp.2007.906770<br>https://ieeexplore.ieee.org/document/8395351 |
| Anticipated Outcomes | The student is expected to obtain numerical results of the reference [3]. Also, the student should propose new methods that outperform the existing methods. |
| Requirements | Networks and Systems, Data Science, Design of Algorithms and Data Structures |
| Project Type | CS Level 3: ❌<br>CS Level 4: ✅ |
| Keywords | Detection, Sensor, Fusion, Robust, Energy |
| Interview Required | No |